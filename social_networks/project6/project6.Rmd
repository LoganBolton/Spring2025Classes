---
title: "Project 5"
output: pdf_document
author: "Logan Bolton"
date: "2025-03-30"
---

_Acknowledgement:_ This code was created through the repurposing of code found in the lecture notes and through collaboration with ChatGPT-4o and Gemini 2.5 Pro. AI tools were very helpful for me while fixing errors and determining the correct syntax to plot graphs.

```{r setup}
# knitr::opts_chunk$set(echo = TRUE)
library('igraph')
library(poweRlaw)
library(dplyr)
library(igraph)
```


# 1) Analysis of Random Graphs G(n, p)
Fix an integer n >= 10,000. For various values of the edge probability p such that pn is a constant, use computational experiments (plots and calculations) to verify the following theoretical properties of G(n, p):


### a) Mean degree c
- Verify that the mean degree c = p(n - 1).
- Plot c as a function of p.

```{r Mean Degree}

n <- 10000 # Number of vertices (n >= 10,000)

num_p_values <- 30 # Number of different p values to test
p_values <- seq(1/n, 10/n, length.out = num_p_values)

observed_mean_degrees <- numeric(length(p_values))
theoretical_mean_degrees <- numeric(length(p_values))

cat("Running simulation for n =", n, "...\n")
for (i in 1:length(p_values)) {
  p <- p_values[i]

  # Generate a G(n, p) random graph
  # Use directed=FALSE and loops=FALSE for the standard G(n,p) model
  g <- sample_gnp(n = n, p = p, directed = FALSE, loops = FALSE)

  # Calculate the observed mean degree
  # Mean degree = Sum of degrees / n = 2 * number_of_edges / n
  if (gorder(g) > 0) { # Check if the graph has vertices
      degrees <- degree(g)
      observed_mean_degrees[i] <- mean(degrees)
  } else {
      observed_mean_degrees[i] <- 0 # Mean degree is 0 for an empty graph
  }

  theoretical_mean_degrees[i] <- p * (n - 1)
}
cat("Simulation finished.\n\n")

# --- Verification ---
cat("--- Verification Summary ---\n")
differences <- observed_mean_degrees - theoretical_mean_degrees
relative_differences <- differences / theoretical_mean_degrees
# Handle cases where theoretical mean degree might be 0 (though not for p>0)
relative_differences[is.nan(relative_differences)] <- 0
relative_differences[is.infinite(relative_differences)] <- NA # Should not happen here

cat("Range of p values:", range(p_values), "\n")
cat("Range of theoretical mean degrees (c):", range(theoretical_mean_degrees), "\n")
cat("Range of observed mean degrees:", range(observed_mean_degrees), "\n")
cat("Mean absolute difference:", mean(abs(differences)), "\n")
cat("Max absolute difference:", max(abs(differences)), "\n")
cat("Mean absolute relative difference (%):", mean(abs(relative_differences), na.rm = TRUE) * 100, "%\n")
cat("Max absolute relative difference (%):", max(abs(relative_differences), na.rm = TRUE) * 100, "%\n")

# Check if observed values are close to theoretical ones (e.g., within 5%)
# Note: Due to randomness, a single run might occasionally exceed a tight tolerance.
tolerance <- 0.05
close_enough <- abs(relative_differences) < tolerance
cat(sprintf("Percentage of simulations where observed c is within %.1f%% of theoretical c: %.2f%%\n",
            tolerance * 100, mean(close_enough, na.rm=TRUE) * 100))


# --- Plotting ---
# Set plot parameters for better readability
par(mar = c(5, 5, 4, 2) + 0.1) # Adjust margins

plot(p_values, observed_mean_degrees,
     type = "p", # Points
     pch = 16,   # Solid circles
     cex = 0.8,  # Smaller points
     col = "blue",
     xlab = "Edge Probability (p)",
     ylab = "Mean Degree (c)",
     main = paste("Mean Degree of G(n, p) vs. p (n =", format(n, scientific = FALSE), ")"),
     ylim = range(c(0, observed_mean_degrees, theoretical_mean_degrees)), # Ensure y-axis starts near 0 and includes all points/lines
     cex.lab = 1.2, # Axis label size
     cex.axis = 1.1, # Axis tick size
     cex.main = 1.3) # Title size

# Add the theoretical line
lines(p_values, theoretical_mean_degrees,
      type = "l", # Line
      col = "red",
      lwd = 2) # Line width

# Add a legend
legend("topleft",
       legend = c("Observed Mean Degree (Simulation)", "Theoretical Mean Degree (p*(n-1))"),
       col = c("blue", "red"),
       pch = c(16, NA), # Point symbol for observed, none for line
       lty = c(NA, 1),  # Line type: none for observed, solid for theoretical
       lwd = c(NA, 2),  # Line width: none for observed, 2 for theoretical
       bg = "white")

grid()

```


### b) Degree Distribution pk
Show that pk follows a Poisson distribution pk = e^(-c) × c^k/k! by plotting the empirical degree distribution (histogram) and overlay the theoretical Poisson curve.

```{r}
n <- 10000      # Number of vertices (n >= 10,000)
target_c <- 5.0 # Choose a target *theoretical* mean degree c = p(n-1)

# Calculate the required edge probability p
if (n > 1) {
  p <- target_c / (n - 1)
} else {
  p <- 0 # Avoid division by zero if n=1
}

cat(sprintf("Parameters: n = %d, Target Mean Degree c = %.2f, p = %f\n", n, target_c, p))

# --- Generate G(n, p) Graph ---
cat("Generating G(n, p) graph...\n")
g <- sample_gnp(n = n, p = p, directed = FALSE, loops = FALSE)
cat("Graph generated.\n")

# --- Calculate Empirical Degree Distribution ---
cat("Calculating degree distribution...\n")
if (gorder(g) > 0) {
    degrees <- degree(g)
    observed_c <- mean(degrees) # Actual mean degree in this instance

    # Get counts for each degree
    degree_counts <- table(degrees)
    # Get the degree values that are present
    k_values <- as.numeric(names(degree_counts))
    # Calculate empirical probability pk = count(k) / n
    pk_empirical <- as.numeric(degree_counts) / n

} else {
    degrees <- numeric(0)
    observed_c <- 0
    k_values <- numeric(0)
    pk_empirical <- numeric(0)
    warning("Graph has no vertices.")
}

cat(sprintf("Observed Mean Degree in this sample: %.4f\n", observed_c))

# --- Calculate Theoretical Poisson Distribution ---
# Use the *target* theoretical mean 'c' for the Poisson lambda
# Define the range of k values (degrees) to consider for the theoretical plot
if (length(k_values) > 0) {
    k_range <- 0:max(k_values)
} else {
    k_range <- 0
}

# Calculate Poisson probabilities P(X=k) = exp(-c) * c^k / k!
pk_theoretical <- dpois(k_range, lambda = target_c)

cat("Theoretical Poisson probabilities calculated.\n")

# --- Plotting ---
cat("Generating plot...\n")

# Determine plot limits
if (length(pk_empirical) > 0 || length(pk_theoretical) > 0) {
    ylim_max <- max(c(pk_empirical, pk_theoretical), na.rm = TRUE) * 1.1 # Add 10% margin
    xlim_max <- max(k_range)
} else {
    ylim_max <- 0.1
    xlim_max <- 10
}


plot(k_values, pk_empirical,
     type = "p", # Points
     pch = 16,   # Solid circles
     col = "blue",
     cex = 0.9,
     xlab = "Degree (k)",
     ylab = "Probability (pk)",
     main = paste("Degree Distribution of G(n, p) vs. Poisson\n",
                  sprintf("n=%d, p=%.5f, Theoretical c=%.2f, Observed c=%.3f",
                          n, p, target_c, observed_c)),
     xlim = c(0, xlim_max),
     ylim = c(0, ylim_max),
     cex.lab = 1.2,
     cex.axis = 1.1,
     cex.main = 1.0) # Smaller main title if long

# Overlay the theoretical Poisson probabilities
points(k_range, pk_theoretical,
       type = "p",   # Points
       pch = 4,    # Crosses symbol
       col = "red",
       cex = 0.9)

# Optional: Add theoretical curve as lines instead of points
# lines(k_range, pk_theoretical, type = "l", col = "red", lwd = 1.5)


# Add a legend
legend("topright",
       legend = c("Empirical pk (Simulation)", paste0("Theoretical Poisson (c = ", target_c, ")")),
       col = c("blue", "red"),
       pch = c(16, 4), # Use pch values corresponding to the plots
       # lty = c(NA, 1), # Use lty if using lines() for theoretical
       bg="white")

# Add grid lines
grid()

cat("Plot generated.\n")
```

### c) Clustering Coefficients
Verify that both the local and global clustering coefficients of G(n, p) are equal to p.

```{r}
n <- 20000 # Number of vertices (n >= 10,000)

# Define a range of p values
# For clustering coefficient = p, the p values themselves are the theoretical values
# Use the same range as before for consistency
num_p_values <- 200
p_values <- seq(1/n, 10/n, length.out = num_p_values)
# Alternative: A direct small range like seq(0.0001, 0.001, length.out = 30)

# --- Storage for Results ---
avg_local_cc_observed <- numeric(length(p_values))
global_cc_observed <- numeric(length(p_values))

# --- Computational Experiment ---
cat("Running simulation for n =", n, "...\n")
for (i in 1:length(p_values)) {
  p <- p_values[i]

  # Generate a G(n, p) random graph
  g <- sample_gnp(n = n, p = p, directed = FALSE, loops = FALSE)

  # Calculate Average Local Clustering Coefficient
  # transitivity(..., type="local") gives NaN for nodes with degree < 2
  local_ccs <- transitivity(g, type = "local")
  # Average over nodes where it's defined (degree >= 2)
  avg_local_cc_observed[i] <- mean(local_ccs, na.rm = TRUE)
  # Handle cases where no node has degree >= 2 (results in NaN mean)
  if (is.nan(avg_local_cc_observed[i])) {
      avg_local_cc_observed[i] <- 0 # Assign 0 if undefined
  }


  # Calculate Global Clustering Coefficient (Transitivity)
  # This calculates 3 * triangles / connected_triples
  global_cc_observed[i] <- transitivity(g, type = "global")
   # Handle cases where global transitivity is NaN (no connected triples)
  if (is.nan(global_cc_observed[i])) {
       global_cc_observed[i] <- 0 # Assign 0 if undefined
  }

}
cat("Simulation finished.\n\n")

# --- Verification ---
cat("--- Verification Summary ---\n")

# Compare Average Local CC to p
diff_local <- avg_local_cc_observed - p_values
rel_diff_local <- diff_local / p_values
rel_diff_local[p_values == 0] <- 0 # Handle p=0 case if included
rel_diff_local[is.infinite(rel_diff_local)] <- NA

cat("Average Local Clustering Coefficient vs. p:\n")
cat("  Mean absolute difference:", mean(abs(diff_local)), "\n")
cat("  Max absolute difference:", max(abs(diff_local)), "\n")
cat("  Mean abs relative difference (%):", mean(abs(rel_diff_local), na.rm = TRUE) * 100, "%\n")
cat("  Max abs relative difference (%):", max(abs(rel_diff_local), na.rm = TRUE) * 100, "%\n")

# Compare Global CC to p
diff_global <- global_cc_observed - p_values
rel_diff_global <- diff_global / p_values
rel_diff_global[p_values == 0] <- 0 # Handle p=0 case if included
rel_diff_global[is.infinite(rel_diff_global)] <- NA

cat("\nGlobal Clustering Coefficient vs. p:\n")
cat("  Mean absolute difference:", mean(abs(diff_global)), "\n")
cat("  Max absolute difference:", max(abs(diff_global)), "\n")
cat("  Mean abs relative difference (%):", mean(abs(rel_diff_global), na.rm = TRUE) * 100, "%\n")
cat("  Max abs relative difference (%):", max(abs(rel_diff_global), na.rm = TRUE) * 100, "%\n")


# --- Plotting ---
par(mar = c(5, 5, 4, 2) + 0.1) # Adjust margins

# Determine plot range
y_max <- max(c(0, p_values, avg_local_cc_observed, global_cc_observed), na.rm = TRUE) * 1.1
x_max <- max(p_values) * 1.05

plot(p_values, avg_local_cc_observed,
     pch = 16,   # Solid circles
     cex=0.9,
     col = "blue",
     xlab = "Edge Probability (p)",
     ylab = "Clustering Coefficient",
     main = paste("Clustering Coefficients of G(n, p) vs. p (n =", format(n, scientific = FALSE), ")"),
     xlim = c(0, x_max),
     ylim = c(0, y_max),
     cex.lab = 1.2,
     cex.axis = 1.1,
     cex.main = 1.3)

# Add points for the global clustering coefficient
points(p_values, global_cc_observed,
       pch = 17,   # Triangles
       cex=0.9,
       col = "darkgreen")

# Add the theoretical line CC = p (which is y = x on this plot)
abline(a = 0, b = 1, col = "red", lwd = 2, lty = 2) # y = 0 + 1*x

# Add a legend
legend("topleft",
       legend = c("Avg. Local CC (Observed)", "Global CC (Observed)", "Theoretical CC = p"),
       col = c("blue", "darkgreen", "red"),
       pch = c(16, 17, NA), # Point symbols
       lty = c(NA, NA, 2),  # Line types (dashed for theoretical)
       lwd = c(NA, NA, 2),  # Line widths
       bg = "white")

# Add grid lines
grid()
```

### d) Giant Component Threshold
Confirm that the threshold probability for the emergence of a giant component is 1/(n-1).

```{r}
n <- 10000 # Number of vertices (n >= 10,000)
num_simulations_per_p <- 10 # Number of graphs to average over for each p value
num_alpha_points <- 40      # Number of points (alpha values) to plot

# Calculate the theoretical threshold probability
if (n > 1) {
  p_c <- 1 / (n - 1)
} else {
  p_c <- 1 # Or handle n=1 case appropriately
}

# Define a range of multipliers 'alpha' for p, centered around the threshold alpha=1
# We want p = alpha * p_c
alpha_values <- seq(0.1, 3.0, length.out = num_alpha_points)
p_values <- alpha_values * p_c

# --- Storage for Results ---
# Store the average relative size of the largest component for each alpha/p
avg_relative_largest_comp_size <- numeric(length(alpha_values))

# --- Computational Experiment ---
cat(sprintf("Running simulations for n=%d. Theoretical threshold p_c ≈ %.6f (alpha=1)\n", n, p_c))

for (i in 1:length(alpha_values)) {
  p <- p_values[i]
  alpha <- alpha_values[i]
  current_run_relative_sizes <- numeric(num_simulations_per_p)

  # Run multiple simulations for the current p value
  for (j in 1:num_simulations_per_p) {
    # Generate a G(n, p) random graph
    g <- sample_gnp(n = n, p = p, directed = FALSE, loops = FALSE)

    largest_comp_size <- 0 # Default size
    if (gorder(g) > 0) { # Check if graph is not empty
        comps <- components(g)
        # Check if components were found and csize is not NULL/empty
        if (!is.null(comps$csize) && length(comps$csize) > 0) {
            largest_comp_size <- max(comps$csize)
        } else {
             # If graph has nodes but components() doesn't return sizes
             # (unlikely for igraph), assume isolated nodes.
             # Or if the graph is truly empty (handled by gorder(g)>0 check).
             # If n>0 but no edges, largest component is size 1.
             if (gorder(g) > 0 && gsize(g) == 0) {
                 largest_comp_size <- 1
             } else {
                 largest_comp_size <- 0 # Should not happen normally
             }
        }
    }

    # Calculate relative size for this run
    current_run_relative_sizes[j] <- largest_comp_size / n

  } # End inner loop (simulations for one p)

  # Calculate the average relative size for this p value
  avg_relative_largest_comp_size[i] <- mean(current_run_relative_sizes, na.rm = TRUE)

} # End outer loop (over alpha/p values)
cat("Simulation finished.\n\n")


# --- Plotting ---
par(mar = c(5, 5, 4, 2) + 0.1) # Adjust margins

plot(alpha_values, avg_relative_largest_comp_size,
     type = "b", # Plot both points and lines
     pch = 16,
     cex = 0.8,
     col = "blue",
     xlab = expression("p / 1/(n-1)"), # Label using alpha = p/pc
     ylab = "Relative Size of Largest Component",
     main = paste("Giant Component Emergence in G(n, p) (n =", format(n, scientific = FALSE), ")"),
     ylim = c(0, 1.0), # Relative size is between 0 and 1
     cex.lab = 1.2,
     cex.axis = 1.1,
     cex.main = 1.2)

# Add a vertical line at the theoretical threshold (alpha = 1)
abline(v = 1, col = "red", lwd = 2, lty = 2) # lty=2 for dashed line

grid()
```

### e) Fraction S of Vertices in the Giant Component
Show that the fraction S of vertices in the giant component satisfies: 1 - S = e^(-cS) by comparing the empirical value of S with the theoretical prediction (using numerical methods if needed).

```{r}

```

### f) Small Components
- Verify that small components are trees.
- Show that the average size of small components is: R = 2/(2 - c + cS)

```{r}

```

### g) Fraction of Vertices in Small Components
Verify that the fraction of vertices in small components follows (e^(-sc)*(sc)^(s-1))/s!

```{r}

```

### h) Diameter
Show that the diameter of G(n, p) follows: diameter = A + ln(n)/ln(c) where A is a constant.

```{r}

```

# 2) Empirical Analysis of Real-World Network
Analyze the ca-GrQc dataset from https://snap.stanford.edu/data/ca-GrQc.html in the Stanford Large Network Dataset Collection.

```{r load_dataset}
txt_file <- "/Users/log/Github/Spring2025Classes/social_networks/project6/ca-GrQc.txt"

edges <- read.table(txt_file, skip = 4, header = FALSE)
colnames(edges) <- c("FromNodeId", "ToNodeId")
g <- graph_from_data_frame(edges, directed = FALSE)
g <- simplify(g, remove.multiple = TRUE, remove.loops = TRUE)

print(paste("Number of nodes:", vcount(g)))
print(paste("Number of edges:", ecount(g)))
```

### a) Construct a graph G based on the data set
Analyze some basic network properties of G including order, size, density, connectivity (if G is not connected, find the number of components of G and the fraction of vertices in the largest component), and clustering coefficient.

```{r}

```

### b) Generate a configuration model G*
Generate a configuration model G* that has the same degree sequence as that of G's.

```{r}

```

### c) Analyze model properties
Analyze some basic network properties of G*.

```{r}

```

### d) Compare networks
Ident

```{r}

```
fy similarities and differences between G and G*.

