[
  {
    "graph_id": 0,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      3,
      3,
      4,
      6
    ],
    "target": [
      1,
      3,
      4,
      0,
      0,
      2,
      5,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->E\nB->A\nC->A\nD->C\nD->F\nE->D\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_0.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_0_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_0_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_0_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_0_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_0_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_0_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_0_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_0_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_0_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 1,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      4,
      5,
      6
    ],
    "target": [
      2,
      0,
      5,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nE->F\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_1.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_1_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_1_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_1_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_1_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_1_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 2,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      5,
      0,
      0,
      0,
      0,
      2,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nC->A\nD->A\nE->A\nF->A\nF->C\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_2.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_2_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_2_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 3,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      4,
      4,
      0,
      5,
      3,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->E\nC->A\nC->F\nE->D\nF->A\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_3.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_3_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_3_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_3_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_3_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_3_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_3_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_3_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_3_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_3_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 4,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      1,
      2,
      5,
      2,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nC->F\nD->B\nD->C\nE->F\nF->C\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_4.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_4_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_4_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_4_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_4_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_4_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_4_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_4_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_4_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 5,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      5,
      6,
      6
    ],
    "target": [
      4,
      4,
      5,
      1,
      5,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nC->E\nC->F\nD->B\nD->F\nF->B\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_5.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_5_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_5_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_5_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_5_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_5_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_5_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_5_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_5_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 6,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      6
    ],
    "target": [
      2,
      4,
      3,
      3,
      5,
      0,
      2,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->D\nC->D\nC->F\nD->A\nE->C\nE->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_6.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_6_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_6_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_6_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_6_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_6_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_6_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_6_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_6_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_6_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 7,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      5,
      5
    ],
    "target": [
      3,
      4,
      0,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nD->A\nF->A\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_7.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_7_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_7_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_7_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_7_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_7_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 8,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      1,
      2,
      4,
      5,
      0,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nC->E\nC->F\nD->A\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_8.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_8_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_8_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_8_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_8_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_8_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_8_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_8_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 9,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      6
    ],
    "target": [
      3,
      4,
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nD->A\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_9.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_9_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_9_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_9_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_9_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 10,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      0,
      3,
      5,
      3,
      0,
      4,
      1,
      5,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nB->F\nC->D\nD->A\nD->E\nE->B\nE->F\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_10.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_10_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_10_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 11,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      0,
      1,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "E->C\nE->D\nF->A\nF->B\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_11.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_11_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_11_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_11_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_11_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_11_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_11_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_11_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 12,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      4,
      4
    ],
    "target": [
      2,
      0,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nC->E\nE->A\nE->D\n",
    "averaged_attention_matrix_path": "averaged_id_12.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_12_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_12_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_12_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_12_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_12_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 13,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      0,
      3,
      0,
      2,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nD->E\nE->A\nE->D\nF->A\nF->C\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_13.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_13_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_13_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_13_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_13_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_13_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_13_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_13_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_13_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 14,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      4,
      5,
      6
    ],
    "target": [
      0,
      2,
      5,
      3,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nD->F\nE->D\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_14.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_14_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_14_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_14_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_14_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_14_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_14_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 15,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      5,
      0,
      3,
      1,
      4,
      1,
      1,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->D\nC->B\nD->E\nE->B\nF->B\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_15.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_15_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_15_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 16,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      3,
      5,
      3,
      2,
      5,
      3,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->D\nB->F\nC->D\nD->C\nD->F\nE->D\nG->C\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_16.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_16_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_16_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 17,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      2,
      4,
      6,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      3,
      4,
      1,
      3,
      5,
      5,
      0,
      1,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nB->E\nC->B\nC->D\nC->F\nE->F\nG->A\nG->B\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_17.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_17_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_17_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 18,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      6
    ],
    "target": [
      1,
      0,
      3,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nB->D\nD->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_18.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_18_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_18_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_18_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_18_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_18_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 19,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      5,
      1,
      4,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->D\nC->F\nD->A\nE->F\nF->B\nF->E\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_19.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_19_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_19_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_19_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_19_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_19_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_19_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_19_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_19_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 20,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      0,
      5,
      1,
      2,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nE->B\nE->C\nG->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_20.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_20_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_20_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_20_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_20_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_20_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_20_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_20_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 21,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      4,
      4,
      4,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      3,
      1,
      2,
      5,
      1,
      4,
      0,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->B\nC->D\nE->B\nE->C\nE->F\nF->B\nF->E\nG->A\nG->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_21.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_21_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_21_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 22,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      0,
      1,
      0,
      3,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nC->A\nD->B\nE->A\nE->D\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_22.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_22_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_22_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_22_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_22_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_22_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_22_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_22_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_22_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 23,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      2,
      0,
      2,
      5,
      0,
      1,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nC->A\nE->C\nE->F\nF->A\nF->B\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_23.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_23_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_23_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_23_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_23_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_23_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_23_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_23_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_23_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_23_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 24,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      4,
      4,
      4,
      5
    ],
    "target": [
      5,
      2,
      0,
      1,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->F\nD->C\nE->A\nE->B\nE->F\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_24.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_24_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_24_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_24_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_24_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_24_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_24_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 25,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      3,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      4,
      0,
      1,
      2,
      4,
      5,
      1,
      0,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "C->B\nC->E\nD->A\nD->B\nD->C\nD->E\nD->F\nE->B\nF->A\nF->D\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_25.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_25_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_25_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 26,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      3,
      4,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->F\nC->A\nC->D\nD->E\nF->B\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_26.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_26_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_26_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_26_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_26_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_26_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_26_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_26_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 27,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      1,
      3,
      0,
      4,
      0,
      5,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nC->B\nC->D\nD->A\nD->E\nE->A\nE->F\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_27.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_27_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_27_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 28,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      4,
      5,
      5,
      5
    ],
    "target": [
      2,
      3,
      0,
      5,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nD->A\nE->F\nF->B\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_28.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_28_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_28_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_28_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_28_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_28_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_28_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_28_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 29,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      5,
      0,
      4,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nC->A\nD->F\nF->A\nF->E\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_29.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_29_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_29_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_29_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_29_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_29_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_29_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_29_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 30,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      0,
      4,
      5,
      0,
      5,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nC->E\nD->F\nE->A\nE->F\nF->B\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_30.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_30_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_30_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_30_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_30_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_30_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_30_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_30_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_30_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_30_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 31,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->D\nC->E\nD->A\nF->D\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_31.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_31_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_31_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_31_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_31_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_31_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_31_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 32,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      3,
      5,
      5
    ],
    "target": [
      1,
      2,
      4,
      3,
      4,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nB->D\nC->E\nD->B\nF->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_32.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_32_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_32_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_32_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_32_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_32_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_32_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_32_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_32_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 33,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      3,
      4,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      3,
      4,
      0,
      1,
      3,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->D\nD->E\nE->A\nE->B\nE->D\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_33.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_33_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_33_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 34,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      5
    ],
    "target": [
      1,
      2,
      2,
      4,
      3,
      4,
      5,
      2,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->C\nB->E\nC->D\nC->E\nC->F\nD->C\nD->F\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_34.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_34_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_34_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 35,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      5
    ],
    "target": [
      0,
      1,
      4,
      1,
      2,
      5,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nC->B\nD->E\nE->B\nE->C\nE->F\nF->A\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_35.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_35_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_35_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_35_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_35_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_35_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_35_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_35_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_35_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 36,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      0,
      3,
      2,
      3,
      5,
      3,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nC->A\nC->D\nE->C\nE->D\nE->F\nF->D\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_36.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_36_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_36_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 37,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      4
    ],
    "target": [
      1,
      4,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nD->A\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_37.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_37_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_37_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_37_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_37_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 38,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      1,
      1,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      5
    ],
    "target": [
      3,
      0,
      2,
      3,
      4,
      5,
      0,
      1,
      2,
      2,
      5,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->C\nB->D\nB->E\nB->F\nD->A\nD->B\nD->C\nE->C\nE->F\nF->C\nF->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_38.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_38_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_38_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 39,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      0,
      5,
      3,
      0,
      2,
      4,
      5,
      1,
      3,
      1,
      4,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->F\nC->D\nD->A\nD->C\nD->E\nD->F\nE->B\nE->D\nF->B\nF->E\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_39.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_39_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_39_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 40,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      5,
      5,
      4,
      1,
      2,
      2,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nB->E\nB->F\nC->F\nD->E\nE->B\nE->C\nF->C\nF->D\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_40.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_40_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_40_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 41,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      4,
      5,
      6
    ],
    "target": [
      1,
      4,
      3,
      4,
      0,
      1,
      4,
      3,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->D\nB->E\nC->A\nC->B\nC->E\nE->D\nF->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_41.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_41_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_41_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 42,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      2,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      4,
      0,
      1,
      4,
      5,
      2,
      3,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->E\nC->A\nC->B\nC->E\nC->F\nD->C\nE->D\nF->B\nF->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_42.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_42_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_42_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 43,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      2,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      4,
      0,
      3,
      2,
      5,
      0,
      2,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nC->A\nC->D\nD->C\nD->F\nE->A\nE->C\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_43.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_43_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_43_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 44,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      3,
      4,
      4,
      0,
      2,
      3,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nC->E\nD->E\nE->A\nE->C\nE->D\nF->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_44.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_44_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_44_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 45,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      5,
      4,
      5,
      2,
      4,
      3,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nC->E\nC->F\nD->C\nD->E\nE->D\nF->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_45.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_45_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_45_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_45_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_45_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_45_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_45_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_45_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_45_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_45_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 46,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      0,
      2,
      4,
      2,
      0,
      5,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nB->C\nB->E\nD->C\nE->A\nE->F\nF->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_46.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_46_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_46_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 47,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      3,
      0,
      4,
      5,
      2,
      0,
      2,
      5,
      0,
      4,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nC->A\nC->E\nC->F\nD->C\nE->A\nE->C\nE->F\nF->A\nF->E\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_47.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_47_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_47_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 48,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      3,
      4,
      4,
      5,
      5
    ],
    "target": [
      2,
      5,
      2,
      5,
      1,
      5,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nD->C\nD->F\nE->B\nE->F\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_48.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_48_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_48_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_48_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_48_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_48_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_48_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_48_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_48_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 49,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      1,
      4,
      0,
      1,
      2,
      4,
      0,
      2,
      0,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nC->B\nC->E\nD->A\nD->B\nD->C\nD->E\nE->A\nE->C\nF->A\nG->B\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_49.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_49_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_49_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 50,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      4,
      4,
      1,
      0,
      1,
      2,
      5,
      0,
      1,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->E\nC->B\nD->A\nD->B\nD->C\nD->F\nE->A\nE->B\nF->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_50.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_50_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_50_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 51,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      3,
      5,
      5,
      4,
      5,
      2,
      0,
      2,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nC->F\nD->E\nD->F\nE->C\nF->A\nF->C\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_51.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_51_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_51_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 52,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      0,
      3,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->F\nD->A\nF->A\nF->D\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_52.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_52_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_52_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_52_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_52_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_52_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_52_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 53,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      6,
      6
    ],
    "target": [
      4,
      5,
      4,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->E\nD->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_53.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_53_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_53_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_53_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_53_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_53_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_53_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 54,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      5,
      1,
      4,
      1,
      4,
      3,
      5,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->F\nC->B\nC->E\nD->B\nD->E\nE->D\nE->F\nF->B\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_54.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_54_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_54_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 55,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      5,
      5
    ],
    "target": [
      0,
      3,
      0,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nD->A\nD->B\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_55.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_55_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_55_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_55_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_55_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_55_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_55_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 56,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      0,
      3,
      0,
      1,
      2,
      1,
      4,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nC->A\nC->D\nD->A\nD->B\nD->C\nE->B\nF->E\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_56.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_56_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_56_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 57,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      4,
      0,
      2,
      4,
      1,
      5,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->E\nC->A\nD->C\nD->E\nE->B\nE->F\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_57.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_57_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_57_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_57_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_57_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_57_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_57_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_57_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_57_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 58,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      6
    ],
    "target": [
      3,
      1,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->D\nD->B\nD->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_58.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_58_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_58_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_58_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_58_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 59,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      5,
      5
    ],
    "target": [
      4,
      4,
      1,
      5,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nC->E\nD->B\nD->F\nE->A\nF->B\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_59.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_59_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_59_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_59_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_59_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_59_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_59_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_59_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 60,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      2,
      5,
      0,
      2,
      3,
      4,
      5,
      1,
      4,
      5,
      1,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->A\nB->C\nB->D\nB->E\nC->F\nD->B\nD->E\nD->F\nE->B\nE->F\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_60.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_60_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_60_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 61,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      3,
      2,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "D->B\nD->C\nE->D\nF->C\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_61.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_61_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_61_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_61_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_61_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_61_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_61_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 62,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      0,
      2,
      2,
      0,
      4,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nC->A\nD->C\nE->C\nF->A\nF->E\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_62.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_62_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_62_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 63,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      5,
      3,
      1,
      3,
      1,
      3,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nA->F\nB->D\nD->B\nE->D\nF->B\nF->D\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_63.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_63_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_63_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 64,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      2,
      3,
      4,
      0,
      1,
      2,
      1,
      3,
      4,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->C\nB->D\nB->E\nD->A\nD->B\nE->C\nF->B\nF->D\nF->E\nG->A\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_64.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_64_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_64_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 65,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      4,
      6
    ],
    "target": [
      3,
      4,
      5,
      2,
      3,
      5,
      1,
      2,
      4,
      5,
      2,
      3,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nA->F\nB->C\nB->D\nC->F\nD->B\nD->C\nD->E\nD->F\nE->C\nE->D\nE->F\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_65.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_65_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_65_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 66,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      5,
      4,
      2,
      4,
      0,
      1,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->F\nC->E\nD->C\nD->E\nE->A\nE->B\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_66.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_66_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_66_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_66_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_66_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_66_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_66_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_66_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 67,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      2,
      3,
      4,
      5,
      1,
      2,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->C\nB->D\nD->E\nD->F\nE->B\nE->C\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_67.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_67_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_67_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 68,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      4
    ],
    "target": [
      4,
      2,
      5,
      0,
      1,
      2,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nC->F\nD->A\nD->B\nD->C\nE->A\nE->B\nE->D\n",
    "averaged_attention_matrix_path": "averaged_id_68.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_68_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_68_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_68_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_68_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_68_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_68_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_68_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_68_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_68_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 69,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      3,
      4,
      0,
      1,
      4,
      1,
      5,
      4,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nC->E\nD->A\nD->B\nD->E\nE->B\nE->F\nF->E\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_69.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_69_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_69_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 70,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      2,
      0,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nD->A\nD->C\nE->A\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_70.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_70_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_70_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_70_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_70_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_70_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_70_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 71,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      3,
      3,
      4,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      0,
      4,
      0,
      3,
      5,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nC->F\nD->A\nD->E\nE->A\nE->D\nE->F\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_71.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_71_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_71_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 72,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      3,
      3,
      5,
      4,
      0,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->F\nC->D\nE->D\nE->F\nF->E\nG->A\nG->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_72.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_72_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_72_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 73,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      4,
      5,
      5,
      5,
      5,
      0,
      3,
      0,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->F\nC->F\nD->F\nE->A\nE->D\nF->A\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_73.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_73_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_73_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 74,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      3,
      5,
      6
    ],
    "target": [
      2,
      1,
      3,
      2,
      5,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nC->B\nC->D\nD->C\nD->F\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_74.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_74_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_74_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_74_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_74_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_74_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_74_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_74_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 75,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      2,
      1,
      5,
      2,
      2,
      2,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nC->B\nC->F\nD->C\nE->C\nF->C\nF->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_75.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_75_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_75_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 76,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nC->D\nC->F\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_76.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_76_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_76_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_76_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_76_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_76_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_76_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_76_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 77,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      4,
      4,
      5,
      6
    ],
    "target": [
      5,
      2,
      5,
      0,
      1,
      3,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nB->F\nC->A\nE->B\nE->D\nF->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_77.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_77_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_77_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_77_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_77_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_77_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_77_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_77_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_77_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 78,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      3,
      3,
      3,
      5,
      6
    ],
    "target": [
      1,
      3,
      4,
      0,
      2,
      5,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->E\nD->A\nD->C\nD->F\nF->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_78.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_78_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_78_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_78_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_78_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_78_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_78_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_78_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_78_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 79,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      1,
      0,
      2,
      0,
      3,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->F\nC->B\nD->A\nE->C\nF->A\nF->D\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_79.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_79_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_79_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_79_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_79_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_79_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_79_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_79_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_79_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_79_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 80,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      6
    ],
    "target": [
      4,
      4,
      5,
      0,
      1,
      0,
      4,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nB->F\nC->A\nC->B\nD->A\nD->E\nE->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_80.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_80_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_80_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_80_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_80_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_80_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_80_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_80_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_80_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_80_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 81,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      3,
      5,
      5
    ],
    "target": [
      2,
      3,
      4,
      3,
      4,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nC->D\nD->E\nF->B\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_81.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_81_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_81_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_81_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_81_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_81_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_81_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_81_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 82,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      5
    ],
    "target": [
      4,
      5,
      1,
      3,
      5,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->E\nB->F\nC->B\nC->D\nC->F\nD->C\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_82.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_82_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_82_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_82_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_82_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_82_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_82_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_82_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 83,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      4,
      4
    ],
    "target": [
      5,
      0,
      2,
      4,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->C\nB->E\nE->B\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_83.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_83_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_83_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_83_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_83_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_83_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_83_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 84,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      1,
      2,
      3,
      0,
      0,
      3,
      5,
      5,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nB->A\nC->A\nC->D\nC->F\nD->F\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_84.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_84_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_84_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 85,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      5
    ],
    "target": [
      4,
      1,
      3,
      4,
      0,
      1,
      2,
      5,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nC->B\nC->D\nC->E\nD->A\nE->B\nE->C\nE->F\nF->B\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_85.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_85_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_85_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 86,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      1,
      4,
      1,
      1,
      2,
      2,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->D\nC->B\nC->E\nD->B\nE->B\nE->C\nF->C\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_86.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_86_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_86_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_86_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_86_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_86_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_86_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_86_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_86_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_86_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 87,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      4,
      6
    ],
    "target": [
      4,
      5,
      0,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->A\nE->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_87.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_87_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_87_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_87_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_87_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_87_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 88,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      0,
      3,
      3,
      4,
      1,
      5,
      3,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nC->D\nC->E\nD->B\nD->F\nE->D\nF->A\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_88.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_88_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_88_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 89,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      0,
      2,
      0,
      4,
      3,
      5,
      3,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->C\nD->A\nD->E\nE->D\nE->F\nF->D\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_89.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_89_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_89_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 90,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      4,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      3,
      5,
      1,
      2,
      3,
      0,
      2,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->D\nC->F\nE->B\nE->C\nE->D\nF->A\nF->C\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_90.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_90_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_90_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 91,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      2,
      2,
      5,
      1,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->D\nC->E\nD->C\nE->C\nE->F\nF->B\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_91.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_91_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_91_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_91_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_91_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_91_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_91_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_91_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_91_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 92,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      0,
      3,
      1,
      4,
      5,
      2,
      5,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nB->E\nC->A\nC->D\nD->B\nD->E\nD->F\nE->C\nE->F\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_92.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_92_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_92_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 93,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      4,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      5,
      4,
      0,
      1,
      3,
      3,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nA->F\nB->E\nE->A\nE->B\nE->D\nF->D\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_93.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_93_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_93_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 94,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      3,
      4,
      5,
      0,
      3,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nB->E\nC->F\nF->A\nF->D\nG->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_94.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_94_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_94_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_94_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_94_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_94_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_94_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_94_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_94_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_94_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 95,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      4,
      4,
      6
    ],
    "target": [
      5,
      0,
      3,
      4,
      2,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->D\nB->E\nE->C\nE->D\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_95.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_95_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_95_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_95_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_95_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_95_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_95_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_95_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 96,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      4,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      0,
      5,
      2,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nB->E\nC->A\nC->F\nE->C\nG->A\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_96.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_96_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_96_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_96_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_96_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_96_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_96_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_96_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_96_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_96_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 97,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      4
    ],
    "target": [
      3,
      2,
      3,
      0,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nC->D\nD->A\nE->A\nE->D\n",
    "averaged_attention_matrix_path": "averaged_id_97.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_97_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_97_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_97_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_97_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_97_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_97_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 98,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      2,
      2,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      0,
      5,
      0,
      1,
      4,
      5,
      1,
      3,
      1,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->F\nC->A\nC->B\nC->E\nC->F\nD->B\nE->D\nF->B\nG->A\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_98.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_98_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_98_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 99,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      3,
      5,
      5,
      0,
      1,
      1,
      4,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nC->D\nC->F\nD->F\nE->A\nE->B\nF->B\nF->E\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_99.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_99_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_99_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 100,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      2,
      3,
      3,
      3,
      4,
      4
    ],
    "target": [
      3,
      5,
      0,
      2,
      4,
      1,
      3,
      4,
      5,
      0,
      1,
      5,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nB->C\nB->E\nC->B\nC->D\nC->E\nC->F\nD->A\nD->B\nD->F\nE->C\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_100.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_100_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_100_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 101,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      3,
      6
    ],
    "target": [
      1,
      3,
      4,
      1,
      4,
      5,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nC->D\nC->E\nD->B\nD->E\nD->F\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_101.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_101_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_101_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_101_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_101_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_101_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_101_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_101_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 102,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      4,
      1,
      4,
      1,
      2,
      5,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->E\nC->B\nC->E\nE->B\nE->C\nE->F\nF->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_102.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_102_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_102_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 103,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      1,
      1,
      2,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->B\nD->F\nE->B\nF->B\nF->C\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_103.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_103_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_103_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_103_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_103_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_103_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_103_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_103_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 104,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      1,
      2,
      3,
      0,
      2,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nD->B\nD->C\nE->D\nF->A\nF->C\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_104.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_104_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_104_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_104_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_104_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_104_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_104_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_104_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_104_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_104_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 105,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      4,
      5,
      0,
      0,
      5,
      2,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->E\nC->F\nD->A\nE->A\nE->F\nF->C\nG->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_105.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_105_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_105_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 106,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      4,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      5,
      3,
      1,
      0,
      2,
      5,
      4,
      0,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nD->B\nE->A\nE->C\nE->F\nF->E\nG->A\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_106.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_106_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_106_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 107,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      1,
      4,
      0,
      5,
      3,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nC->E\nC->F\nD->B\nD->E\nE->A\nE->F\nF->D\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_107.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_107_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_107_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 108,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      1,
      0,
      1,
      1,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->D\nB->E\nC->B\nD->A\nE->B\nF->B\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_108.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_108_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_108_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_108_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_108_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_108_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_108_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_108_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_108_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 109,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      4,
      5,
      6
    ],
    "target": [
      1,
      4,
      0,
      2,
      5,
      3,
      5,
      5,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nB->C\nB->F\nC->D\nC->F\nE->F\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_109.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_109_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_109_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 110,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      4,
      5,
      0,
      5,
      0,
      4,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nB->F\nD->A\nD->F\nF->A\nF->E\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_110.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_110_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_110_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 111,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      4,
      5,
      2,
      4,
      0,
      4,
      5,
      5,
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nA->F\nB->C\nC->E\nD->A\nD->E\nD->F\nE->F\nF->A\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_111.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_111_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_111_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 112,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      2,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      4,
      0,
      3,
      4,
      0,
      0,
      3,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->E\nC->A\nC->D\nC->E\nE->A\nF->A\nF->D\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_112.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_112_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_112_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 113,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      0,
      3,
      0,
      4,
      0,
      5,
      2,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nB->D\nC->A\nC->E\nE->A\nE->F\nF->C\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_113.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_113_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_113_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 114,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      5
    ],
    "target": [
      2,
      0,
      3,
      4,
      0,
      1,
      1,
      2,
      4,
      0,
      2,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->D\nB->E\nC->A\nC->B\nD->B\nD->C\nD->E\nE->A\nE->C\nF->A\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_114.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_114_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_114_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 115,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      4
    ],
    "target": [
      1,
      2,
      4,
      5,
      3,
      4,
      0,
      3,
      5,
      0,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nA->F\nB->D\nB->E\nC->A\nC->D\nC->F\nD->A\nD->E\nE->D\n",
    "averaged_attention_matrix_path": "averaged_id_115.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_115_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_115_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 116,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      5,
      0,
      3,
      4,
      1,
      4,
      5,
      1,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->A\nB->D\nC->E\nD->B\nD->E\nD->F\nE->B\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_116.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_116_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_116_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 117,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      0,
      5,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nC->A\nC->F\nE->A\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_117.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_117_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_117_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_117_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_117_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_117_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_117_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_117_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 118,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      5,
      3,
      4,
      5,
      2,
      5,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->F\nC->D\nC->E\nD->F\nE->C\nE->F\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_118.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_118_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_118_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_118_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_118_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_118_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_118_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_118_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_118_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_118_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 119,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      5,
      1,
      2,
      3,
      0,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nC->D\nC->F\nD->F\nE->B\nE->C\nE->D\nF->A\nG->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_119.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_119_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_119_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 120,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      3,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      5,
      2,
      4,
      5,
      5,
      1,
      2,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nA->F\nB->C\nB->E\nB->F\nD->F\nF->B\nF->C\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_120.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_120_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_120_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 121,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      0,
      2,
      4,
      0,
      1,
      3,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->D\nC->A\nD->C\nD->E\nE->A\nF->B\nF->D\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_121.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_121_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_121_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_121_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_121_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_121_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_121_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_121_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_121_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_121_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 122,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      5,
      4,
      5,
      0,
      0,
      2,
      1,
      3,
      0,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->E\nB->F\nC->A\nD->A\nD->C\nE->B\nE->D\nF->A\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_122.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_122_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_122_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 123,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      3,
      4,
      6,
      6
    ],
    "target": [
      5,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "D->F\nE->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_123.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_123_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_123_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_123_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_123_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 124,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      4,
      5,
      0,
      5,
      0,
      2,
      5,
      2,
      4,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->A\nC->E\nC->F\nD->A\nD->F\nE->A\nE->C\nE->F\nF->C\nF->E\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_124.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_124_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_124_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 125,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      4,
      0,
      1,
      3,
      4,
      5,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->E\nC->A\nC->B\nC->D\nD->E\nD->F\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_125.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_125_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_125_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 126,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      1,
      1,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nD->B\nF->B\nF->C\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_126.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_126_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_126_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_126_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_126_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_126_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_126_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_126_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 127,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      1,
      3,
      3,
      3,
      5
    ],
    "target": [
      0,
      2,
      3,
      5,
      0,
      2,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->D\nB->F\nD->A\nD->C\nD->F\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_127.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_127_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_127_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_127_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_127_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_127_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_127_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_127_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_127_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 128,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      6,
      6
    ],
    "target": [
      3,
      4,
      3,
      0,
      5,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->D\nC->A\nC->F\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_128.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_128_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_128_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_128_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_128_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_128_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_128_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_128_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 129,
    "max_nodes": 7,
    "num_nodes": 3,
    "num_edges": 2,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      6
    ],
    "target": [
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->F\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_129.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_129_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_129_1.npy"
    ],
    "num_averaged_samples": 2
  },
  {
    "graph_id": 130,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      5,
      5,
      2,
      4,
      3,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nB->F\nC->F\nD->C\nD->E\nF->D\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_130.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_130_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_130_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 131,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      4,
      4,
      5,
      5,
      5
    ],
    "target": [
      1,
      2,
      3,
      1,
      0,
      2,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->D\nC->B\nE->A\nE->C\nF->A\nF->B\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_131.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_131_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_131_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_131_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_131_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_131_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_131_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_131_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_131_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_131_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 132,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      3,
      5,
      1,
      2,
      4,
      5,
      3,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->D\nC->F\nD->B\nD->C\nD->E\nE->F\nF->D\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_132.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_132_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_132_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 133,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      4,
      4,
      0,
      1,
      4,
      0,
      1,
      4,
      5,
      0,
      5,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nB->E\nC->A\nC->B\nC->E\nD->A\nD->B\nD->E\nD->F\nE->A\nE->F\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_133.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_133_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_133_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 134,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      3,
      4,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      0,
      2,
      3,
      5,
      0,
      1,
      5,
      3,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->C\nB->D\nD->F\nE->A\nE->B\nE->F\nF->D\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_134.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_134_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_134_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 135,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      3,
      5,
      0,
      5,
      4,
      1,
      2,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nB->F\nC->A\nC->F\nD->E\nE->B\nE->C\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_135.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_135_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_135_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 136,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      4,
      0,
      2,
      0,
      2,
      5,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nB->A\nB->C\nE->A\nE->C\nE->F\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_136.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_136_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_136_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 137,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      2,
      6
    ],
    "target": [
      1,
      5,
      0,
      1,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nC->A\nC->B\nC->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_137.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_137_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_137_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_137_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_137_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_137_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_137_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 138,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      2,
      5,
      3,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->D\nC->E\nD->A\nD->C\nD->F\nE->D\nF->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_138.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_138_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_138_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_138_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_138_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_138_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_138_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_138_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_138_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_138_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 139,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      2,
      6
    ],
    "target": [
      3,
      5,
      0,
      0,
      1,
      3,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nC->A\nC->B\nC->D\nC->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_139.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_139_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_139_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_139_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_139_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_139_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_139_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_139_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_139_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 140,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      3,
      4,
      4
    ],
    "target": [
      5,
      0,
      1,
      4,
      5,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->F\nC->A\nC->B\nD->E\nD->F\nE->B\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_140.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_140_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_140_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_140_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_140_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_140_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_140_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_140_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 141,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      6,
      6
    ],
    "target": [
      4,
      4,
      0,
      1,
      5,
      0,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nC->A\nD->B\nD->F\nE->A\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_141.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_141_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_141_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_141_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_141_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_141_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_141_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_141_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_141_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 142,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      4,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nB->E\nD->B\nE->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_142.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_142_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_142_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_142_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_142_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_142_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_142_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_142_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 143,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      0,
      4,
      0,
      1,
      5,
      2,
      0,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "C->A\nC->E\nD->A\nD->B\nD->F\nE->C\nF->A\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_143.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_143_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_143_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_143_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_143_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_143_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_143_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_143_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_143_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_143_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 144,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      5
    ],
    "target": [
      1,
      2,
      0,
      1,
      5,
      1,
      1,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nC->B\nC->F\nD->B\nE->B\nF->B\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_144.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_144_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_144_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_144_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_144_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_144_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_144_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_144_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_144_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_144_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 145,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      0,
      1,
      4,
      5,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nC->A\nC->B\nD->E\nE->F\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_145.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_145_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_145_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_145_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_145_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_145_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_145_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_145_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 146,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      4,
      5,
      0,
      3,
      0,
      2,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nC->E\nC->F\nE->A\nE->D\nF->A\nF->C\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_146.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_146_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_146_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 147,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      2,
      0,
      5,
      5,
      1,
      3,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->C\nC->A\nC->F\nE->F\nF->B\nF->D\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_147.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_147_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_147_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 148,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      1,
      5,
      2,
      0,
      5,
      1,
      2,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nC->B\nC->F\nD->C\nE->A\nE->F\nF->B\nF->C\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_148.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_148_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_148_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 149,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      3,
      3,
      6
    ],
    "target": [
      3,
      2,
      5,
      1,
      2,
      4,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nB->F\nD->B\nD->C\nD->E\nD->F\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_149.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_149_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_149_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_149_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_149_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_149_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_149_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_149_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_149_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 150,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      4,
      4,
      4,
      6
    ],
    "target": [
      0,
      1,
      0,
      1,
      1,
      2,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->A\nC->B\nD->A\nD->B\nE->B\nE->C\nE->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_150.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_150_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_150_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_150_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_150_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_150_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_150_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_150_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_150_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 151,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      2,
      5,
      3,
      5,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nC->D\nD->C\nD->F\nE->D\nE->F\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_151.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_151_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_151_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_151_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_151_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_151_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_151_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_151_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_151_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 152,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      2,
      5,
      5,
      1,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->A\nB->C\nD->F\nE->F\nF->B\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_152.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_152_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_152_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_152_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_152_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_152_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_152_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_152_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_152_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_152_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 153,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      0,
      4,
      5,
      1,
      5,
      0,
      2,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->F\nC->A\nC->E\nC->F\nD->B\nD->F\nE->A\nE->C\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_153.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_153_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_153_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 154,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      4,
      5,
      5,
      4,
      0,
      2,
      3,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->F\nC->E\nD->A\nE->C\nE->D\nF->B\nF->C\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_154.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_154_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_154_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 155,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      2,
      4,
      4,
      2,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->C\nB->E\nD->E\nF->C\nF->E\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_155.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_155_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_155_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_155_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_155_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_155_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_155_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_155_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_155_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_155_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 156,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      4,
      6
    ],
    "target": [
      3,
      3,
      4,
      0,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nB->E\nC->A\nC->B\nE->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_156.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_156_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_156_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_156_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_156_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_156_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_156_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_156_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 157,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      4,
      6
    ],
    "target": [
      3,
      0,
      3,
      1,
      4,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->D\nD->B\nD->E\nE->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_157.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_157_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_157_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_157_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_157_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_157_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_157_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_157_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 158,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      5
    ],
    "target": [
      2,
      2,
      5,
      0,
      2,
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nC->F\nD->A\nD->C\nE->A\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_158.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_158_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_158_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_158_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_158_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_158_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_158_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_158_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 159,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      5,
      6
    ],
    "target": [
      5,
      0,
      2,
      4,
      4,
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->C\nC->E\nD->E\nF->A\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_159.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_159_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_159_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_159_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_159_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_159_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_159_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_159_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 160,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      5,
      0,
      4,
      2,
      2,
      3,
      0,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->F\nC->A\nC->E\nD->C\nE->C\nE->D\nF->A\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_160.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_160_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_160_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 161,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      0,
      3,
      3,
      4,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nB->A\nE->D\nF->D\nF->E\nG->A\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_161.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_161_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_161_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 162,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      2,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      1,
      3,
      4,
      2,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->A\nC->B\nC->D\nC->E\nF->C\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_162.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_162_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_162_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 163,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      4,
      0,
      1,
      4,
      0,
      4,
      1,
      3,
      1,
      2,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nC->B\nC->E\nD->A\nD->E\nE->B\nE->D\nF->B\nF->C\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_163.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_163_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_163_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 164,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      6
    ],
    "target": [
      3,
      2,
      3,
      0,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nB->D\nD->A\nD->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_164.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_164_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_164_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_164_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_164_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_164_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_164_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 165,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      1,
      2,
      5,
      0,
      4,
      5,
      4,
      5,
      3,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->A\nB->E\nC->F\nD->E\nD->F\nE->D\nE->F\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_165.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_165_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_165_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 166,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      2,
      5,
      6
    ],
    "target": [
      3,
      4,
      1,
      4,
      5,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nC->B\nC->E\nC->F\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_166.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_166_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_166_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_166_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_166_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_166_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_166_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_166_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 167,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      5
    ],
    "target": [
      2,
      3,
      4,
      4,
      5,
      1,
      5,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->E\nC->E\nC->F\nD->B\nD->F\nE->C\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_167.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_167_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_167_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_167_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_167_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_167_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_167_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_167_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_167_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_167_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 168,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      0,
      3,
      1,
      2,
      1,
      2,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nC->A\nC->D\nD->B\nD->C\nF->B\nF->C\nG->B\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_168.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_168_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_168_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 169,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      6,
      6
    ],
    "target": [
      1,
      4,
      3,
      0,
      5,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->D\nC->A\nE->F\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_169.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_169_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_169_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_169_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_169_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_169_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_169_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_169_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 170,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3
    ],
    "target": [
      5,
      4,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->F\nC->E\nD->C\nD->F\n",
    "averaged_attention_matrix_path": "averaged_id_170.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_170_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_170_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_170_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_170_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 171,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      4,
      4,
      6
    ],
    "target": [
      2,
      5,
      0,
      5,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nC->A\nC->F\nE->B\nE->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_171.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_171_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_171_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_171_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_171_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_171_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_171_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_171_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 172,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      5,
      4,
      5,
      0,
      1,
      5,
      2,
      3,
      5,
      2,
      4,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->F\nC->E\nC->F\nD->A\nD->B\nD->F\nE->C\nE->D\nE->F\nF->C\nF->E\nG->A\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_172.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_172_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_172_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 173,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      2,
      0,
      1,
      5,
      1,
      0,
      1,
      2,
      4,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nC->A\nC->B\nC->F\nD->B\nE->A\nE->B\nF->C\nF->E\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_173.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_173_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_173_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 174,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      3,
      4,
      5,
      5
    ],
    "target": [
      3,
      4,
      5,
      3,
      5,
      4,
      5,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nA->F\nB->D\nB->F\nD->E\nE->F\nF->B\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_174.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_174_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_174_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_174_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_174_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_174_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_174_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_174_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_174_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_174_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 175,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      2,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      5,
      4,
      0,
      3,
      4,
      5,
      4,
      2,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->E\nC->A\nC->D\nC->E\nC->F\nD->E\nE->C\nG->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_175.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_175_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_175_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 176,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      4,
      1,
      2,
      3,
      0,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nC->B\nE->C\nE->D\nF->A\nF->D\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_176.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_176_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_176_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_176_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_176_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_176_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_176_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_176_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_176_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_176_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 177,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      1,
      2,
      0,
      3,
      5,
      0,
      2,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->D\nC->B\nD->C\nE->A\nE->D\nE->F\nF->A\nF->C\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_177.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_177_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_177_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 178,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      3,
      4,
      5,
      0,
      0,
      3,
      0,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->D\nB->E\nC->F\nD->A\nE->A\nF->D\nG->A\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_178.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_178_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_178_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 179,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      3,
      4,
      4,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      3,
      4,
      1,
      4,
      1,
      2,
      3,
      5,
      1,
      2,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nB->E\nC->B\nD->E\nE->B\nE->C\nE->D\nE->F\nF->B\nF->C\nG->A\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_179.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_179_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_179_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 180,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      4,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      2,
      5,
      5,
      0,
      1,
      2,
      2,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->C\nB->F\nD->F\nE->A\nE->B\nE->C\nF->C\nG->A\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_180.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_180_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_180_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 181,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      4,
      5,
      1,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nC->F\nE->B\nE->D\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_181.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_181_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_181_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_181_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_181_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_181_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_181_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_181_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 182,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      6,
      6
    ],
    "target": [
      2,
      4,
      0,
      2,
      3,
      3,
      5,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nB->C\nB->D\nC->D\nC->F\nD->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_182.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_182_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_182_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 183,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      5,
      1,
      2,
      0,
      1,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->B\nC->F\nD->B\nD->C\nE->A\nF->B\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_183.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_183_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_183_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_183_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_183_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_183_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_183_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_183_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_183_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_183_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 184,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      6
    ],
    "target": [
      5,
      3,
      4,
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nB->E\nC->F\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_184.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_184_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_184_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_184_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_184_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_184_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 185,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      1,
      0,
      2,
      4,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nD->B\nE->A\nF->C\nF->E\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_185.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_185_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_185_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_185_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_185_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_185_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_185_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_185_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 186,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      4,
      3,
      5,
      3,
      5,
      4,
      1,
      5,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->D\nB->F\nC->D\nC->F\nD->E\nE->B\nE->F\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_186.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_186_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_186_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 187,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      4,
      5,
      5,
      1,
      5,
      4,
      3,
      0,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->F\nC->B\nC->F\nD->E\nF->D\nG->A\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_187.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_187_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_187_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 188,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      4,
      6
    ],
    "target": [
      0,
      4,
      1,
      5,
      3,
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->E\nC->B\nD->F\nE->D\nE->F\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_188.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_188_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_188_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_188_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_188_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_188_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_188_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_188_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 189,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      4,
      0,
      2,
      1,
      2,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nD->C\nD->E\nE->A\nE->C\nF->B\nF->C\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_189.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_189_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_189_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 190,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      4,
      1,
      2,
      5,
      0,
      3,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nC->E\nD->B\nD->C\nD->F\nE->A\nE->D\nF->A\nF->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_190.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_190_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_190_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 191,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      4,
      4,
      5,
      1,
      5,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nC->E\nC->F\nD->B\nE->F\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_191.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_191_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_191_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_191_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_191_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_191_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_191_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_191_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 192,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      0,
      2,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nE->C\nF->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_192.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_192_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_192_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_192_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_192_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_192_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_192_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_192_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 193,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      5,
      5,
      5,
      4,
      1,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->F\nC->F\nD->E\nE->B\nE->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_193.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_193_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_193_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_193_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_193_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_193_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_193_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_193_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_193_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 194,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      4,
      5,
      0,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->D\nB->F\nC->A\nD->E\nE->F\nF->A\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_194.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_194_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_194_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_194_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_194_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_194_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_194_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_194_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_194_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 195,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      0,
      2,
      0,
      5,
      0,
      1,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nD->A\nD->F\nE->A\nE->B\nE->C\nF->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_195.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_195_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_195_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_195_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_195_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_195_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_195_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_195_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_195_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_195_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 196,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      2,
      5,
      4,
      4,
      5,
      0,
      1,
      3,
      1,
      2,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->C\nB->F\nC->E\nD->E\nD->F\nE->A\nE->B\nE->D\nF->B\nF->C\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_196.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_196_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_196_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 197,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      5,
      5
    ],
    "target": [
      4,
      4,
      0,
      5,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nC->E\nD->A\nD->F\nE->B\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_197.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_197_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_197_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_197_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_197_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_197_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_197_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_197_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 198,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      2,
      0,
      2,
      5,
      2,
      5,
      3,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->C\nD->A\nD->C\nD->F\nE->C\nE->F\nF->D\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_198.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_198_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_198_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 199,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      5,
      1,
      0,
      2,
      4,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nB->F\nC->B\nE->A\nE->C\nF->E\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_199.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_199_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_199_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_199_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_199_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_199_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_199_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_199_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_199_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 200,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      2,
      3,
      5,
      1,
      3,
      0,
      5,
      0,
      4,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->D\nB->F\nC->B\nC->D\nE->A\nE->F\nF->A\nF->E\nG->A\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_200.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_200_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_200_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 201,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      5,
      6,
      6
    ],
    "target": [
      4,
      2,
      3,
      0,
      4,
      5,
      3,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->D\nC->A\nC->E\nD->F\nF->D\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_201.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_201_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_201_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_201_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_201_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_201_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_201_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_201_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_201_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_201_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 202,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      4,
      3,
      4,
      1,
      4,
      5,
      1,
      4,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->D\nB->E\nC->B\nD->E\nE->F\nF->B\nF->E\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_202.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_202_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_202_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 203,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      4,
      5,
      1,
      1,
      4,
      3,
      0,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nA->F\nC->B\nD->B\nD->E\nE->D\nF->A\nF->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_203.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_203_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_203_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 204,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      4,
      0,
      0,
      3,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->E\nB->F\nD->E\nE->A\nF->A\nF->D\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_204.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_204_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_204_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_204_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_204_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_204_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_204_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_204_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_204_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_204_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 205,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      2,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      0,
      2,
      3,
      1,
      3,
      4,
      5,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->A\nB->C\nB->D\nC->B\nC->D\nC->E\nC->F\nF->C\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_205.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_205_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_205_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 206,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      0,
      0,
      1,
      2,
      0,
      1,
      3,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->A\nC->A\nC->B\nD->C\nE->A\nE->B\nF->D\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_206.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_206_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_206_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 207,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3
    ],
    "target": [
      0,
      3,
      1,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nC->B\nC->F\nD->E\n",
    "averaged_attention_matrix_path": "averaged_id_207.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_207_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_207_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_207_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_207_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_207_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 208,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      5,
      4,
      1,
      2,
      2,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nB->F\nC->A\nC->F\nD->E\nE->B\nE->C\nF->C\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_208.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_208_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_208_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 209,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      4,
      4,
      1,
      3,
      0,
      2,
      5,
      2,
      3,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nC->B\nC->D\nD->A\nD->C\nD->F\nE->C\nE->D\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_209.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_209_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_209_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 210,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      2,
      3,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      0,
      5,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nA->F\nC->A\nC->F\nD->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_210.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_210_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_210_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_210_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_210_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_210_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_210_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_210_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_210_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 211,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      5
    ],
    "target": [
      2,
      3,
      3,
      0,
      2,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->D\nC->A\nD->C\nE->F\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_211.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_211_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_211_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_211_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_211_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_211_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_211_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_211_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 212,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      3,
      4,
      0,
      0,
      1,
      2,
      1,
      5,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->A\nD->A\nD->B\nD->C\nE->B\nE->F\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_212.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_212_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_212_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_212_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_212_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_212_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_212_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_212_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_212_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_212_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 213,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      4,
      5,
      6
    ],
    "target": [
      4,
      2,
      0,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->E\nD->C\nE->A\nF->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_213.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_213_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_213_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_213_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_213_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_213_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 214,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nC->E\nE->F\nF->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_214.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_214_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_214_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_214_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_214_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_214_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_214_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 215,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      5,
      6
    ],
    "target": [
      4,
      5,
      1,
      4,
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->E\nB->F\nC->B\nD->E\nF->A\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_215.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_215_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_215_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_215_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_215_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_215_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_215_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 216,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      3,
      2,
      0,
      0,
      1,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nC->A\nD->A\nD->B\nE->A\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_216.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_216_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_216_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_216_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_216_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_216_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_216_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_216_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_216_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 217,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      4,
      0,
      5,
      3,
      5,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->D\nC->E\nD->A\nD->F\nE->D\nE->F\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_217.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_217_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_217_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_217_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_217_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_217_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_217_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_217_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_217_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 218,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      2,
      4,
      0,
      5,
      0,
      1,
      2,
      0,
      2,
      4,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->C\nB->E\nC->A\nC->F\nD->A\nD->B\nD->C\nF->A\nF->C\nF->E\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_218.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_218_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_218_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 219,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      4,
      4,
      6
    ],
    "target": [
      3,
      1,
      0,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nC->B\nE->A\nE->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_219.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_219_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_219_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_219_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_219_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_219_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 220,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      2,
      3,
      3,
      3,
      4,
      5
    ],
    "target": [
      2,
      3,
      4,
      1,
      3,
      0,
      2,
      4,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nC->B\nC->D\nD->A\nD->C\nD->E\nE->F\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_220.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_220_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_220_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 221,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      4,
      5
    ],
    "target": [
      3,
      5,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->D\nC->F\nE->F\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_221.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_221_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_221_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_221_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_221_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 222,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      5
    ],
    "target": [
      1,
      0,
      2,
      3,
      5,
      0,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nB->C\nC->D\nC->F\nD->A\nE->F\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_222.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_222_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_222_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_222_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_222_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_222_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_222_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_222_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_222_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 223,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      5,
      0,
      2,
      5,
      0,
      2,
      5,
      0,
      3,
      0,
      1,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nA->F\nB->A\nB->C\nB->F\nC->A\nD->C\nD->F\nE->A\nE->D\nF->A\nF->B\nF->D\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_223.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_223_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_223_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 224,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      4,
      6,
      6,
      6
    ],
    "target": [
      2,
      0,
      4,
      4,
      5,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->E\nC->E\nE->F\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_224.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_224_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_224_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_224_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_224_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_224_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_224_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_224_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_224_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 225,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 16,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      3,
      4,
      5,
      0,
      0,
      4,
      0,
      1,
      3,
      1,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nB->D\nB->E\nB->F\nC->A\nD->A\nD->E\nE->A\nE->B\nE->D\nF->B\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_225.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_225_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_225_15.npy"
    ],
    "num_averaged_samples": 16
  },
  {
    "graph_id": 226,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      2,
      1,
      3,
      5,
      1,
      4,
      3,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->C\nC->B\nC->D\nC->F\nD->B\nD->E\nF->D\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_226.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_226_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_226_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 227,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      2,
      3,
      3,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      0,
      4,
      0,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->D\nC->E\nC->F\nD->A\nD->E\nF->A\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_227.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_227_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_227_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_227_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_227_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_227_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_227_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_227_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_227_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 228,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      0,
      4,
      0,
      0,
      2,
      4,
      0,
      5,
      0,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->E\nC->A\nD->A\nD->C\nD->E\nE->A\nE->F\nF->A\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_228.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_228_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_228_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 229,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      2,
      3,
      5,
      2,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->D\nB->F\nE->C\nE->D\nE->F\nF->C\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_229.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_229_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_229_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 230,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      3,
      3,
      4,
      0,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nC->D\nC->E\nD->A\nE->C\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_230.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_230_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_230_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_230_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_230_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_230_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_230_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_230_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 231,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      1,
      5,
      1,
      0,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nC->B\nC->F\nD->B\nE->A\nF->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_231.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_231_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_231_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_231_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_231_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_231_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_231_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_231_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 232,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      2,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      1,
      4,
      5,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nC->B\nC->E\nC->F\nE->A\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_232.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_232_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_232_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_232_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_232_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_232_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_232_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_232_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_232_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 233,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      2,
      4
    ],
    "target": [
      1,
      2,
      3,
      4,
      5,
      0,
      5,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nA->E\nA->F\nB->A\nB->F\nC->F\nE->B\n",
    "averaged_attention_matrix_path": "averaged_id_233.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_233_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_233_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_233_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_233_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_233_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_233_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_233_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_233_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_233_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 234,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      1,
      3,
      1,
      2,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nC->B\nC->D\nD->B\nF->C\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_234.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_234_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_234_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_234_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_234_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_234_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_234_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_234_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_234_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 235,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      2,
      4,
      6
    ],
    "target": [
      0,
      2,
      0,
      1,
      4,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nC->A\nC->B\nC->E\nE->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_235.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_235_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_235_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_235_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_235_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_235_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_235_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_235_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 236,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      4,
      6
    ],
    "target": [
      4,
      5,
      2,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nD->C\nE->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_236.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_236_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_236_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_236_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_236_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_236_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 237,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      0,
      4,
      3,
      5,
      0,
      2,
      4,
      0,
      1,
      2,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->E\nC->D\nC->F\nD->A\nD->C\nD->E\nE->A\nF->B\nF->C\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_237.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_237_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_237_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 238,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      6
    ],
    "target": [
      1,
      1,
      2,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nC->B\nD->C\nD->E\nE->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_238.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_238_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_238_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_238_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_238_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_238_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_238_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 239,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      4,
      4,
      4,
      4,
      4
    ],
    "target": [
      2,
      0,
      5,
      0,
      1,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nC->F\nE->A\nE->B\nE->C\nE->D\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_239.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_239_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_239_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_239_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_239_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_239_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_239_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_239_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_239_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 240,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      6
    ],
    "target": [
      1,
      3,
      0,
      4,
      4,
      0,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->A\nB->E\nC->E\nD->A\nE->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_240.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_240_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_240_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_240_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_240_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_240_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_240_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_240_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_240_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 241,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      2,
      0,
      1,
      4,
      0,
      2,
      2,
      3,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->C\nC->A\nC->B\nC->E\nD->A\nD->C\nE->C\nE->D\nF->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_241.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_241_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_241_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 242,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      3,
      1,
      4,
      1,
      2,
      0,
      2,
      3,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nC->D\nD->B\nD->E\nE->B\nE->C\nF->A\nF->C\nF->D\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_242.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_242_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_242_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 243,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      4,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      4,
      1,
      2,
      5,
      5,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nB->E\nC->E\nD->B\nD->C\nD->F\nE->F\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_243.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_243_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_243_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 244,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      4,
      0,
      5,
      1,
      5,
      2,
      3,
      4,
      1,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nD->A\nD->F\nE->B\nE->F\nF->C\nF->D\nF->E\nG->B\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_244.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_244_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_244_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 245,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      4,
      4
    ],
    "target": [
      3,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->D\nC->E\nE->A\nE->B\n",
    "averaged_attention_matrix_path": "averaged_id_245.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_245_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_245_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_245_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_245_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 246,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      3,
      4,
      4,
      4,
      4,
      5,
      5,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      1,
      2,
      3,
      5,
      0,
      1,
      2,
      4,
      0,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "D->C\nE->B\nE->C\nE->D\nE->F\nF->A\nF->B\nF->C\nF->E\nG->A\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_246.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_246_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_246_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 247,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      0,
      2,
      4,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->A\nD->C\nD->E\nE->A\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_247.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_247_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_247_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_247_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_247_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_247_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_247_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 248,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      4,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      3,
      5,
      5,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nB->F\nC->D\nC->F\nE->F\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_248.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_248_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_248_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_248_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_248_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_248_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_248_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_248_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_248_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 249,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      2,
      4,
      5,
      5,
      5
    ],
    "target": [
      1,
      0,
      1,
      3,
      3,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nC->A\nC->B\nC->D\nE->D\nF->B\nF->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_249.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_249_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_249_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_249_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_249_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_249_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_249_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_249_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_249_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 250,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      0,
      0,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nE->A\nF->A\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_250.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_250_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_250_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_250_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_250_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_250_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_250_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 251,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      1,
      5,
      0,
      4,
      5,
      0,
      3,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nC->B\nC->F\nD->A\nD->E\nD->F\nE->A\nE->D\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_251.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_251_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_251_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 252,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      2,
      5,
      6
    ],
    "target": [
      0,
      3,
      5,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->A\nC->D\nC->F\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_252.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_252_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_252_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_252_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_252_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_252_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 253,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      3,
      0,
      1,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nD->E\nD->F\nE->D\nF->A\nF->B\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_253.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_253_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_253_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_253_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_253_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_253_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_253_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_253_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_253_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 254,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      5,
      2,
      3,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nE->C\nE->D\nG->A\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_254.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_254_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_254_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_254_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_254_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_254_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_254_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 255,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      1,
      3,
      4,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nC->D\nC->F\nD->B\nF->D\nF->E\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_255.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_255_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_255_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_255_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_255_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_255_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_255_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_255_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_255_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_255_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 256,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      1,
      5,
      4,
      1,
      2,
      1,
      1,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->F\nC->E\nD->B\nD->C\nE->B\nF->B\nF->C\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_256.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_256_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_256_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 257,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      4,
      6,
      6
    ],
    "target": [
      3,
      4,
      4,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->D\nB->E\nD->E\nE->C\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_257.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_257_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_257_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_257_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_257_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_257_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_257_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 258,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      5,
      2,
      4,
      5,
      4,
      5,
      5,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nB->E\nB->F\nC->E\nD->F\nE->F\nF->B\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_258.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_258_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_258_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 259,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      4,
      4,
      4,
      6,
      6
    ],
    "target": [
      4,
      3,
      0,
      1,
      3,
      5,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nC->A\nE->B\nE->D\nE->F\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_259.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_259_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_259_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_259_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_259_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_259_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_259_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_259_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_259_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 260,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      3,
      5,
      5,
      6
    ],
    "target": [
      0,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "D->A\nF->B\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_260.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_260_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_260_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_260_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_260_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 261,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      5,
      5,
      1,
      0,
      1,
      1,
      5,
      3,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->F\nC->B\nD->A\nD->B\nE->B\nE->F\nF->D\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_261.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_261_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_261_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 262,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      6
    ],
    "target": [
      2,
      3,
      5,
      0,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nB->F\nD->A\nD->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_262.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_262_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_262_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_262_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_262_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_262_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_262_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 263,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      4,
      6
    ],
    "target": [
      3,
      4,
      1,
      3,
      0,
      2,
      0,
      2,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nB->E\nC->B\nC->D\nD->A\nD->C\nE->A\nE->C\nE->D\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_263.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_263_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_263_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 264,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      4,
      4,
      5
    ],
    "target": [
      4,
      0,
      4,
      2,
      1,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->E\nD->C\nE->B\nE->D\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_264.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_264_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_264_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_264_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_264_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_264_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_264_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_264_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 265,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      2,
      2,
      2,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nD->C\nE->C\nF->E\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_265.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_265_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_265_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_265_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_265_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_265_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_265_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_265_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 266,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      0,
      1,
      4,
      5,
      0,
      5,
      2,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nB->F\nC->A\nD->B\nD->E\nD->F\nE->A\nE->F\nG->C\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_266.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_266_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_266_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 267,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      3,
      3,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      2,
      1,
      2,
      4,
      4,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->A\nB->C\nD->B\nD->C\nD->E\nF->E\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_267.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_267_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_267_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 268,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      0,
      5,
      1,
      2,
      4,
      2,
      1,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nC->A\nC->F\nD->B\nD->C\nD->E\nE->C\nF->B\nF->E\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_268.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_268_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_268_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 269,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      2,
      5,
      4,
      3,
      0,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nC->F\nD->E\nE->D\nF->A\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_269.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_269_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_269_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_269_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_269_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_269_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_269_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_269_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_269_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_269_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 270,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      5,
      4,
      4,
      0,
      4,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nC->E\nD->E\nE->A\nF->E\nG->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_270.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_270_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_270_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_270_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_270_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_270_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_270_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_270_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_270_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_270_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 271,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      3,
      4,
      4,
      0,
      1,
      5,
      1,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nC->E\nD->A\nD->B\nD->F\nE->B\nE->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_271.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_271_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_271_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_271_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_271_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_271_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_271_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_271_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_271_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_271_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 272,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      4,
      3,
      4,
      0,
      4,
      5,
      5,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->D\nC->E\nD->A\nD->E\nD->F\nE->F\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_272.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_272_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_272_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 273,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      4,
      4,
      6,
      6,
      6,
      6
    ],
    "target": [
      0,
      5,
      0,
      1,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nE->A\nE->B\nG->B\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_273.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_273_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_273_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_273_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_273_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_273_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_273_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_273_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_273_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 274,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      5,
      0,
      0,
      5,
      5,
      0,
      2,
      3,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->A\nC->A\nD->F\nE->F\nF->A\nF->C\nF->D\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_274.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_274_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_274_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 275,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      3,
      3,
      4,
      5,
      1,
      0,
      0,
      2,
      0,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nB->E\nB->F\nC->B\nD->A\nE->A\nF->C\nG->A\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_275.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_275_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_275_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 276,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      3,
      0,
      5,
      0,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nE->A\nE->F\nF->A\nF->B\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_276.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_276_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_276_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_276_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_276_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_276_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_276_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_276_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 277,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5
    ],
    "target": [
      1,
      3,
      2,
      3,
      0,
      3,
      1,
      2,
      5,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->C\nB->D\nC->A\nC->D\nD->B\nD->C\nE->F\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_277.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_277_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_277_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 278,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      0,
      0,
      1,
      1,
      0,
      1,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nC->A\nD->A\nD->B\nE->B\nF->A\nF->B\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_278.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_278_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_278_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_278_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_278_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_278_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_278_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_278_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_278_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 279,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      4
    ],
    "target": [
      4,
      1,
      0,
      1,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->E\nC->B\nD->A\nD->B\nE->B\nE->C\n",
    "averaged_attention_matrix_path": "averaged_id_279.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_279_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_279_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_279_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_279_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_279_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_279_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 280,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      0,
      2,
      0,
      5,
      1,
      5,
      0,
      5,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->F\nB->A\nB->C\nC->A\nC->F\nD->B\nD->F\nE->A\nE->F\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_280.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_280_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_280_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 281,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      5,
      0,
      3,
      5,
      4,
      0,
      2,
      2,
      3,
      4,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->D\nB->F\nD->E\nE->A\nE->C\nF->C\nF->D\nF->E\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_281.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_281_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_281_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 282,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      5,
      5,
      0,
      3,
      5,
      1,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nA->F\nC->F\nE->A\nE->D\nE->F\nF->B\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_282.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_282_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_282_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 283,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      0,
      5,
      1,
      3,
      2,
      4,
      3,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nC->B\nC->D\nD->C\nD->E\nE->D\nF->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_283.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_283_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_283_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_283_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_283_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_283_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_283_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_283_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_283_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_283_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 284,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      2,
      3,
      4,
      0,
      0,
      1,
      1,
      1,
      3,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->A\nB->C\nB->D\nB->E\nC->A\nD->A\nD->B\nE->B\nF->B\nF->D\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_284.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_284_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_284_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 285,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      4
    ],
    "target": [
      4,
      2,
      3,
      5,
      2,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nC->D\nC->F\nD->C\nE->A\nE->B\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_285.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_285_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_285_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_285_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_285_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_285_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_285_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_285_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_285_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 286,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      0,
      1,
      3,
      1,
      2,
      4,
      5,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nC->B\nC->D\nD->B\nD->C\nD->E\nE->F\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_286.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_286_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_286_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 287,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      5,
      5
    ],
    "target": [
      4,
      3,
      1,
      1,
      5,
      5,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nC->B\nD->B\nD->F\nE->F\nF->B\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_287.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_287_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_287_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_287_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_287_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_287_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_287_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_287_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_287_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 288,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      4,
      5
    ],
    "target": [
      0,
      1,
      2,
      4,
      1,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->A\nC->B\nD->C\nD->E\nE->B\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_288.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_288_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_288_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_288_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_288_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_288_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_288_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 289,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      2,
      5,
      1,
      2,
      1,
      3,
      3,
      4,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->C\nC->F\nD->B\nD->C\nE->B\nE->D\nF->D\nF->E\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_289.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_289_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_289_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 290,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      0,
      2,
      3,
      0,
      1,
      2,
      1,
      4,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nB->C\nB->D\nE->A\nE->B\nE->C\nF->B\nF->E\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_290.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_290_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_290_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 291,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      6
    ],
    "target": [
      4,
      5,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nC->B\nD->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_291.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_291_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_291_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_291_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_291_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_291_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 292,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      3,
      4,
      5
    ],
    "target": [
      2,
      5,
      2,
      3,
      2,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->C\nB->D\nD->C\nD->E\nE->A\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_292.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_292_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_292_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_292_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_292_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_292_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_292_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_292_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_292_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 293,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      5,
      3,
      4,
      5,
      0,
      1,
      5,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nB->E\nB->F\nC->A\nC->B\nD->F\nE->B\nF->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_293.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_293_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_293_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 294,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      0,
      2,
      3,
      3,
      2,
      4,
      3,
      5,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->A\nB->C\nB->D\nC->D\nD->C\nD->E\nE->D\nE->F\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_294.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_294_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_294_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 295,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      5,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->D\nB->F\nF->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_295.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_295_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_295_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_295_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_295_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_295_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_295_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 296,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      0,
      3,
      5,
      5,
      2,
      5,
      2,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nC->D\nC->F\nD->F\nE->C\nE->F\nF->C\nG->A\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_296.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_296_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_296_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 297,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      3,
      3,
      5
    ],
    "target": [
      3,
      2,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nD->C\nD->E\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_297.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_297_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_297_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_297_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_297_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 298,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      4,
      0,
      3,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nC->F\nD->E\nE->A\nF->D\nG->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_298.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_298_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_298_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_298_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_298_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_298_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_298_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_298_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_298_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_298_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 299,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      1,
      1,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nC->B\nE->B\nF->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_299.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_299_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_299_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_299_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_299_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_299_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_299_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 300,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      4,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      4,
      5,
      1,
      0,
      1,
      3,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nB->E\nB->F\nC->B\nE->A\nE->B\nE->D\nG->A\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_300.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_300_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_300_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 301,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      5,
      4,
      3,
      5,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->F\nD->E\nE->D\nE->F\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_301.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_301_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_301_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_301_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_301_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_301_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_301_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_301_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_301_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_301_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 302,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      0,
      2,
      0,
      3,
      1,
      4,
      5,
      3,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nB->C\nC->A\nC->D\nD->B\nD->E\nD->F\nE->D\nF->C\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_302.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_302_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_302_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 303,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      2,
      4,
      0,
      2,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->C\nB->E\nD->A\nD->C\nF->B\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_303.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_303_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_303_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_303_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_303_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_303_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_303_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_303_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_303_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_303_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 304,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      4,
      4,
      6
    ],
    "target": [
      3,
      5,
      0,
      5,
      5,
      1,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nB->F\nD->F\nE->B\nE->F\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_304.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_304_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_304_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_304_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_304_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_304_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_304_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_304_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_304_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 305,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      3,
      0,
      5,
      1,
      1,
      0,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->A\nD->F\nE->B\nF->B\nG->A\nG->C\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_305.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_305_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_305_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 306,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      2,
      1,
      2,
      5,
      1,
      5,
      3,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nC->B\nD->C\nD->F\nE->B\nE->F\nF->D\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_306.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_306_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_306_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 307,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      5,
      2,
      4,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->F\nC->F\nD->C\nD->E\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_307.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_307_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_307_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_307_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_307_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_307_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_307_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_307_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_307_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 308,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      0,
      2,
      5,
      0,
      1,
      5,
      0,
      5,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->C\nB->F\nC->A\nC->B\nC->F\nD->A\nE->F\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_308.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_308_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_308_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 309,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      5,
      3,
      4,
      5,
      2,
      4,
      5,
      4,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->F\nB->F\nC->D\nC->E\nC->F\nD->C\nD->E\nE->F\nF->E\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_309.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_309_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_309_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 310,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      3,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      1,
      5,
      1,
      4,
      0,
      5,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nD->B\nD->E\nE->A\nE->F\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_310.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_310_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_310_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_310_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_310_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_310_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_310_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_310_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_310_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_310_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 311,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      4,
      5,
      0,
      4,
      0,
      1,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->F\nC->E\nC->F\nD->A\nD->E\nF->A\nF->B\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_311.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_311_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_311_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 312,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      4,
      4,
      5
    ],
    "target": [
      3,
      4,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->E\nE->A\nE->B\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_312.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_312_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_312_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_312_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_312_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_312_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 313,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      3,
      3,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      1,
      4,
      1,
      2,
      5,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nC->B\nC->E\nD->B\nD->C\nD->F\nF->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_313.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_313_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_313_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 314,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      2,
      5,
      0,
      1,
      4,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->C\nC->F\nD->A\nD->B\nF->E\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_314.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_314_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_314_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_314_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_314_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_314_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_314_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_314_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_314_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_314_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 315,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      4,
      4,
      6
    ],
    "target": [
      2,
      5,
      0,
      4,
      5,
      1,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nC->A\nC->E\nD->F\nE->B\nE->F\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_315.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_315_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_315_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_315_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_315_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_315_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_315_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_315_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_315_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 316,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      4,
      5,
      5,
      4,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nC->F\nD->E\nE->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_316.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_316_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_316_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_316_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_316_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_316_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_316_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_316_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 317,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      4,
      4,
      4
    ],
    "target": [
      5,
      3,
      5,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nC->F\nE->B\nE->C\nE->D\n",
    "averaged_attention_matrix_path": "averaged_id_317.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_317_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_317_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_317_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_317_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_317_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_317_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 318,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      0,
      5,
      1,
      3,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nC->D\nE->A\nE->F\nF->B\nF->D\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_318.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_318_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_318_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_318_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_318_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_318_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_318_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_318_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_318_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 319,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      1,
      3,
      4,
      6,
      6
    ],
    "target": [
      1,
      4,
      2,
      3,
      4,
      5,
      2,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->C\nB->D\nB->E\nB->F\nD->C\nE->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_319.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_319_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_319_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 320,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      4,
      5,
      2,
      4,
      1,
      1,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->F\nC->E\nC->F\nD->C\nD->E\nE->B\nF->B\nF->C\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_320.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_320_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_320_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 321,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      4,
      5,
      5
    ],
    "target": [
      2,
      0,
      4,
      1,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->E\nD->B\nE->A\nF->B\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_321.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_321_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_321_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_321_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_321_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_321_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_321_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_321_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 322,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      4,
      5,
      0,
      0,
      2,
      0,
      2,
      0,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->A\nB->E\nB->F\nC->A\nD->A\nD->C\nE->A\nE->C\nF->A\nF->D\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_322.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_322_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_322_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 323,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      1,
      0,
      2,
      0,
      1,
      4,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nC->B\nD->A\nD->C\nE->A\nF->B\nF->E\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_323.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_323_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_323_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_323_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_323_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_323_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_323_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_323_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_323_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_323_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 324,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      5,
      0,
      4,
      1,
      5,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nD->E\nE->B\nE->F\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_324.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_324_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_324_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_324_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_324_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_324_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_324_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_324_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_324_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 325,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      3,
      4,
      4,
      5,
      5,
      5
    ],
    "target": [
      5,
      0,
      4,
      5,
      1,
      2,
      3,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->E\nB->F\nD->B\nE->C\nE->D\nF->B\nF->C\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_325.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_325_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_325_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 326,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      2,
      4,
      2,
      4,
      1,
      3,
      1,
      3,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->C\nB->E\nC->B\nC->D\nD->B\nE->D\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_326.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_326_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_326_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 327,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      2,
      3,
      4,
      4,
      5
    ],
    "target": [
      2,
      3,
      5,
      0,
      1,
      3,
      4,
      4,
      2,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->F\nC->A\nC->B\nC->D\nC->E\nD->E\nE->C\nE->D\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_327.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_327_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_327_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 328,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      3,
      0,
      4,
      3,
      4,
      5,
      1,
      0,
      1,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->E\nC->D\nD->E\nD->F\nE->B\nF->A\nF->B\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_328.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_328_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_328_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 329,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      6,
      6
    ],
    "target": [
      2,
      5,
      5,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->F\nC->A\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_329.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_329_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_329_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_329_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_329_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_329_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_329_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 330,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      4,
      5,
      0,
      5,
      1,
      5,
      3,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->F\nC->A\nC->F\nD->B\nD->F\nE->D\nE->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_330.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_330_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_330_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_330_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_330_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_330_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_330_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_330_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_330_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_330_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 331,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      5,
      0,
      2,
      1,
      2,
      3,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nC->A\nD->C\nE->B\nE->C\nE->D\nF->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_331.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_331_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_331_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_331_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_331_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_331_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_331_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_331_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_331_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 332,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      4,
      6
    ],
    "target": [
      3,
      5,
      2,
      3,
      3,
      4,
      5,
      4,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->C\nB->D\nC->D\nC->E\nC->F\nD->E\nE->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_332.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_332_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_332_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 333,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      5,
      2,
      4,
      5,
      3,
      5,
      0,
      1,
      2,
      1,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nB->E\nB->F\nC->D\nC->F\nD->A\nD->B\nD->C\nE->B\nE->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_333.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_333_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_333_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 334,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      3,
      5,
      0,
      2,
      5,
      4,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->D\nB->F\nD->A\nE->C\nE->F\nF->E\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_334.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_334_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_334_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 335,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      4,
      5,
      5,
      6
    ],
    "target": [
      0,
      2,
      3,
      1,
      2,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->D\nC->B\nE->C\nF->B\nF->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_335.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_335_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_335_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_335_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_335_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_335_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_335_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_335_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_335_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 336,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      5,
      4,
      5,
      1,
      1,
      2,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->F\nC->E\nD->F\nE->B\nF->B\nF->C\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_336.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_336_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_336_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 337,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      0,
      3,
      0,
      0,
      2,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->A\nB->D\nC->A\nF->A\nF->C\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_337.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_337_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_337_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_337_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_337_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_337_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_337_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_337_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_337_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_337_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 338,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      4,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      1,
      4,
      5,
      0,
      1,
      2,
      2,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nC->B\nC->E\nC->F\nE->A\nE->B\nF->C\nG->C\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_338.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_338_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_338_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 339,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      6,
      6
    ],
    "target": [
      4,
      3,
      5,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->E\nC->D\nE->F\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_339.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_339_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_339_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_339_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_339_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_339_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 340,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      2,
      5,
      3,
      2,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->C\nC->F\nE->D\nF->C\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_340.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_340_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_340_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_340_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_340_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_340_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_340_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_340_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_340_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 341,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      3,
      0,
      0,
      1,
      3,
      1,
      2,
      4,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->A\nB->D\nC->A\nD->A\nD->B\nE->D\nF->B\nF->C\nF->E\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_341.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_341_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_341_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 342,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      4,
      1,
      0,
      2,
      4,
      1,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nC->B\nD->A\nD->C\nD->E\nE->B\nE->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_342.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_342_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_342_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 343,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      6
    ],
    "target": [
      1,
      2,
      3,
      0,
      3,
      3,
      4,
      1,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nB->A\nB->D\nC->D\nC->E\nD->B\nD->E\nE->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_343.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_343_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_343_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 344,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      3,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      5,
      0,
      1,
      2,
      5,
      2,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nB->F\nD->A\nD->B\nD->C\nD->F\nE->C\nG->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_344.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_344_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_344_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 345,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      4,
      4,
      4,
      6,
      6
    ],
    "target": [
      2,
      1,
      3,
      4,
      0,
      1,
      2,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nC->B\nC->D\nC->E\nE->A\nE->B\nE->C\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_345.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_345_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_345_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_345_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_345_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_345_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_345_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_345_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_345_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_345_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 346,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3
    ],
    "target": [
      1,
      3,
      3,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->D\nD->C\nD->F\n",
    "averaged_attention_matrix_path": "averaged_id_346.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_346_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_346_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_346_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_346_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_346_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 347,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      3,
      6,
      6
    ],
    "target": [
      5,
      3,
      0,
      4,
      5,
      2,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nC->A\nC->E\nC->F\nD->C\nD->E\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_347.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_347_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_347_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_347_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_347_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_347_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_347_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_347_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_347_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_347_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 348,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      1,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nB->F\nE->B\nF->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_348.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_348_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_348_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_348_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_348_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_348_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_348_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_348_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 349,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      1,
      2,
      1,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nD->E\nE->B\nE->C\nF->B\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_349.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_349_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_349_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_349_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_349_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_349_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_349_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_349_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_349_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_349_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 350,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      5,
      6,
      6
    ],
    "target": [
      5,
      3,
      5,
      5,
      0,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nB->F\nD->F\nF->A\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_350.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_350_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_350_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_350_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_350_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_350_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_350_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_350_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 351,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      3,
      5,
      2,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->F\nC->D\nC->F\nE->C\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_351.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_351_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_351_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_351_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_351_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_351_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_351_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_351_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_351_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 352,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      2,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      4,
      5,
      2,
      1,
      0,
      1,
      2,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->E\nA->F\nB->C\nC->B\nE->A\nE->B\nE->C\nF->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_352.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_352_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_352_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 353,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      1,
      3,
      3,
      4,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      0,
      3,
      4,
      5,
      1,
      5,
      1,
      2,
      3,
      5,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->D\nB->E\nB->F\nD->B\nD->F\nE->B\nE->C\nE->D\nE->F\nF->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_353.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_353_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_353_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 354,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      5,
      5,
      4,
      3,
      5,
      1,
      2,
      4,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->D\nB->F\nC->F\nD->E\nE->D\nE->F\nF->B\nF->C\nF->E\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_354.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_354_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_354_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 355,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      5,
      6
    ],
    "target": [
      1,
      4,
      3,
      5,
      0,
      0,
      4,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->D\nB->F\nC->A\nD->A\nD->E\nF->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_355.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_355_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_355_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_355_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_355_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_355_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_355_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_355_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_355_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_355_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 356,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      4,
      1,
      2,
      4,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->E\nE->B\nF->C\nF->E\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_356.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_356_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_356_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_356_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_356_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_356_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_356_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_356_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_356_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 357,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      5,
      3,
      1,
      3,
      0,
      5,
      1,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nC->B\nC->D\nE->A\nE->F\nF->B\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_357.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_357_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_357_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_357_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_357_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_357_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_357_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_357_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_357_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_357_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 358,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      4,
      5,
      5
    ],
    "target": [
      2,
      4,
      0,
      2,
      3,
      5,
      1,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nB->C\nC->D\nC->F\nE->B\nF->A\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_358.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_358_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_358_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_358_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_358_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_358_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_358_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_358_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_358_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_358_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 359,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      5,
      0,
      4,
      5,
      0,
      3,
      4,
      2,
      5,
      3,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->A\nB->E\nB->F\nC->A\nC->D\nC->E\nD->C\nD->F\nE->D\nF->A\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_359.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_359_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_359_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 360,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      5,
      4,
      5,
      0,
      1,
      2,
      3,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->F\nC->E\nC->F\nD->A\nD->B\nE->C\nF->D\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_360.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_360_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_360_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 361,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      4,
      2,
      1,
      2,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->E\nE->C\nF->B\nF->C\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_361.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_361_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_361_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_361_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_361_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_361_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_361_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_361_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_361_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 362,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      3,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      5,
      4,
      1,
      4,
      5,
      1,
      0,
      1,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->F\nB->E\nD->B\nD->E\nD->F\nE->B\nF->A\nF->B\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_362.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_362_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_362_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 363,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      5,
      3,
      5,
      1,
      2,
      2,
      0,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nB->F\nC->D\nC->F\nD->B\nD->C\nE->C\nF->A\nG->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_363.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_363_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_363_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 364,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      1,
      4,
      0,
      3,
      0,
      3,
      5,
      0,
      2,
      3,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nB->D\nC->A\nC->D\nC->F\nD->A\nD->C\nF->D\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_364.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_364_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_364_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 365,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      2,
      0,
      4,
      1,
      2,
      4,
      5,
      0,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->C\nC->A\nC->E\nD->B\nD->C\nD->E\nD->F\nF->A\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_365.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_365_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_365_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 366,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      4,
      5,
      5
    ],
    "target": [
      2,
      4,
      1,
      5,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nC->B\nD->F\nE->B\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_366.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_366_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_366_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_366_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_366_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_366_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_366_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_366_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 367,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      4,
      4,
      5
    ],
    "target": [
      1,
      5,
      1,
      1,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nC->B\nE->B\nE->D\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_367.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_367_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_367_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_367_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_367_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_367_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_367_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 368,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      5,
      6
    ],
    "target": [
      2,
      0,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nC->A\nD->E\nF->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_368.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_368_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_368_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_368_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_368_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_368_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 369,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      3,
      0,
      3,
      5,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->A\nB->D\nD->A\nE->D\nE->F\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_369.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_369_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_369_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_369_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_369_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_369_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_369_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_369_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_369_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_369_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 370,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      0,
      4,
      1,
      0,
      0,
      1,
      0,
      2,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->A\nB->E\nC->B\nD->A\nE->A\nE->B\nF->A\nF->C\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_370.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_370_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_370_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 371,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      5,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      4,
      1,
      4,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->D\nB->F\nC->E\nD->B\nD->E\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_371.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_371_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_371_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_371_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_371_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_371_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_371_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_371_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_371_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_371_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 372,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      5,
      5
    ],
    "target": [
      3,
      5,
      4,
      1,
      4,
      5,
      5,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->E\nC->B\nC->E\nC->F\nD->F\nF->A\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_372.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_372_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_372_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_372_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_372_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_372_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_372_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_372_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_372_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_372_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 373,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      1,
      3,
      0,
      4,
      5,
      0,
      3,
      1,
      2,
      3,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->A\nB->E\nB->F\nC->A\nC->D\nE->B\nF->C\nF->D\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_373.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_373_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_373_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 374,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      5,
      2,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nC->A\nD->F\nF->C\nG->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_374.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_374_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_374_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_374_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_374_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_374_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_374_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_374_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_374_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 375,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      5,
      1,
      5,
      1,
      1,
      0,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->F\nC->B\nC->F\nD->B\nE->B\nF->A\nF->D\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_375.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_375_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_375_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 376,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      5
    ],
    "target": [
      3,
      4,
      1,
      5,
      0,
      4,
      5,
      3,
      5,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->E\nC->B\nC->F\nD->A\nD->E\nD->F\nE->D\nE->F\nF->C\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_376.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_376_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_376_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 377,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      5,
      6
    ],
    "target": [
      2,
      0,
      4,
      1,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->E\nD->B\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_377.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_377_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_377_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_377_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_377_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_377_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_377_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 378,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      3,
      4,
      5,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nC->D\nD->E\nE->F\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_378.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_378_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_378_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_378_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_378_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_378_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_378_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_378_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 379,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      4,
      5,
      6
    ],
    "target": [
      4,
      2,
      0,
      3,
      5,
      0,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nC->A\nC->D\nC->F\nE->A\nF->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_379.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_379_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_379_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_379_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_379_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_379_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_379_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_379_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_379_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 380,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      2,
      0,
      2,
      5,
      0,
      1,
      0,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nD->A\nD->C\nD->F\nE->A\nE->B\nF->A\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_380.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_380_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_380_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 381,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      4,
      5,
      5
    ],
    "target": [
      0,
      0,
      1,
      3,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->A\nC->A\nE->B\nE->D\nF->A\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_381.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_381_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_381_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_381_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_381_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_381_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_381_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 382,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      4,
      4,
      4,
      5,
      5
    ],
    "target": [
      1,
      2,
      5,
      3,
      5,
      5,
      0,
      3,
      5,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->D\nB->F\nC->F\nE->A\nE->D\nE->F\nF->C\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_382.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_382_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_382_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 383,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      1,
      4,
      0,
      3,
      0,
      4,
      4,
      5,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nB->D\nC->A\nC->E\nD->E\nE->F\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_383.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_383_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_383_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 384,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      3,
      4,
      5,
      0,
      2,
      3,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nC->D\nC->E\nC->F\nE->A\nE->C\nF->D\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_384.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_384_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_384_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 385,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      6
    ],
    "target": [
      2,
      3,
      1,
      5,
      2,
      4,
      5,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nC->B\nC->F\nD->C\nD->E\nD->F\nE->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_385.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_385_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_385_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_385_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_385_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_385_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_385_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_385_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_385_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_385_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 386,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      4,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      1,
      2,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->F\nC->A\nD->B\nD->C\nE->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_386.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_386_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_386_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_386_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_386_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_386_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_386_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_386_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_386_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 387,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      6,
      6
    ],
    "target": [
      5,
      3,
      4,
      1,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nC->E\nD->B\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_387.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_387_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_387_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_387_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_387_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_387_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_387_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 388,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      4,
      1,
      0,
      2,
      5,
      0,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->E\nC->B\nD->A\nD->C\nD->F\nE->A\nE->B\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_388.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_388_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_388_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 389,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      5,
      6
    ],
    "target": [
      3,
      4,
      0,
      3,
      4,
      5,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->A\nC->D\nD->E\nD->F\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_389.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_389_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_389_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_389_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_389_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_389_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_389_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_389_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_389_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 390,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      0,
      5,
      0,
      1,
      1,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nB->F\nC->A\nC->B\nE->B\nE->C\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_390.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_390_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_390_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 391,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      3,
      5,
      3,
      0,
      4,
      5,
      2,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->F\nC->D\nD->A\nD->E\nE->F\nF->C\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_391.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_391_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_391_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 392,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      0,
      5,
      5,
      2,
      3,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->F\nD->A\nD->F\nE->F\nF->C\nF->D\nF->E\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_392.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_392_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_392_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 393,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      0,
      2,
      5,
      0,
      5,
      0,
      3,
      0,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->C\nC->F\nD->A\nE->F\nF->A\nF->D\nG->A\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_393.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_393_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_393_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 394,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      4,
      4,
      4,
      6,
      6
    ],
    "target": [
      4,
      1,
      1,
      0,
      1,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nC->B\nD->B\nE->A\nE->B\nE->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_394.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_394_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_394_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_394_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_394_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_394_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_394_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_394_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_394_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 395,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      5,
      2,
      4,
      1,
      2,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->F\nD->C\nD->E\nE->B\nE->C\nF->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_395.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_395_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_395_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 396,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      1,
      3,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      0,
      2,
      4,
      5,
      2,
      1,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nB->C\nB->E\nB->F\nD->C\nF->B\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_396.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_396_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_396_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 397,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      5,
      5
    ],
    "target": [
      3,
      1,
      0,
      4,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nC->B\nD->A\nD->E\nF->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_397.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_397_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_397_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_397_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_397_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_397_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_397_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 398,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      3,
      6
    ],
    "target": [
      1,
      2,
      4,
      5,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nA->F\nD->F\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_398.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_398_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_398_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_398_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_398_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_398_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_398_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 399,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      2,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->D\nC->A\nE->C\nE->D\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_399.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_399_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_399_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_399_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_399_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_399_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_399_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 400,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      1,
      0,
      3,
      4,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nC->B\nF->A\nF->D\nF->E\nG->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_400.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_400_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_400_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_400_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_400_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_400_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_400_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_400_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_400_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 401,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      3,
      5,
      0,
      4,
      4,
      5,
      0,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->F\nC->A\nC->E\nD->E\nD->F\nF->A\nG->A\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_401.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_401_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_401_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 402,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      3,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      4,
      2,
      1,
      2,
      5,
      1,
      2,
      3,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->C\nD->B\nD->C\nD->F\nE->B\nF->C\nF->D\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_402.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_402_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_402_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 403,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      3,
      4,
      1,
      2,
      1,
      2,
      3,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->D\nB->E\nC->B\nD->C\nE->B\nE->C\nE->D\nF->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_403.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_403_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_403_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 404,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      4,
      2,
      1,
      4,
      4,
      5,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nB->C\nC->B\nC->E\nD->E\nD->F\nE->A\nF->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_404.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_404_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_404_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 405,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      5,
      5
    ],
    "target": [
      4,
      2,
      4,
      0,
      0,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->E\nC->A\nD->A\nD->B\nF->B\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_405.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_405_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_405_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_405_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_405_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_405_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_405_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_405_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_405_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 406,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 16,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      4,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      4,
      5,
      0,
      4,
      5,
      2,
      5,
      1,
      2,
      3,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->A\nB->E\nB->F\nC->A\nC->E\nC->F\nD->C\nD->F\nE->B\nE->C\nE->D\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_406.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_406_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_406_15.npy"
    ],
    "num_averaged_samples": 16
  },
  {
    "graph_id": 407,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      5,
      3,
      4,
      0,
      3,
      4,
      0,
      3,
      1,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nB->E\nC->A\nC->D\nD->E\nE->A\nE->D\nF->B\nF->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_407.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_407_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_407_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 408,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      4,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      4,
      3,
      4,
      0,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->E\nC->D\nC->E\nE->A\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_408.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_408_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_408_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_408_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_408_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_408_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_408_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_408_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_408_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_408_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 409,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      5,
      4,
      0,
      1,
      3,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->F\nC->E\nD->A\nD->B\nE->D\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_409.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_409_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_409_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_409_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_409_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_409_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_409_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_409_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_409_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 410,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      0,
      2,
      0,
      1,
      0,
      0,
      0,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->C\nC->A\nC->B\nD->A\nE->A\nF->A\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_410.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_410_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_410_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 411,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      0,
      4,
      0,
      2,
      4,
      1,
      3,
      5,
      3,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nC->A\nC->E\nD->A\nD->C\nD->E\nE->B\nE->D\nE->F\nF->D\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_411.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_411_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_411_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 412,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      5,
      2,
      4,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nC->E\nD->F\nE->F\nF->C\nF->E\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_412.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_412_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_412_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_412_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_412_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_412_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_412_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_412_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_412_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 413,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      6
    ],
    "target": [
      1,
      4,
      0,
      5,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nB->F\nD->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_413.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_413_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_413_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_413_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_413_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_413_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_413_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 414,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      2,
      4,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      4,
      5,
      0,
      0,
      0,
      1,
      2,
      0,
      1,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nA->F\nB->A\nC->A\nE->A\nE->B\nE->C\nF->A\nF->B\nG->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_414.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_414_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_414_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 415,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      5,
      6
    ],
    "target": [
      4,
      1,
      5,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->E\nC->B\nC->F\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_415.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_415_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_415_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_415_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_415_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_415_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 416,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      4,
      1,
      3,
      5,
      5,
      2,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->E\nC->B\nC->D\nD->F\nE->F\nF->C\nF->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_416.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_416_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_416_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 417,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      5
    ],
    "target": [
      4,
      5,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nC->F\nD->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_417.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_417_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_417_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_417_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_417_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 418,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      4,
      1,
      3,
      4,
      1,
      2,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->E\nC->B\nC->D\nD->E\nE->B\nE->C\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_418.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_418_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_418_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_418_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_418_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_418_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_418_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_418_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_418_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_418_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 419,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      1,
      3,
      4,
      4,
      5
    ],
    "target": [
      2,
      4,
      5,
      0,
      2,
      3,
      5,
      0,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->A\nB->C\nB->D\nD->F\nE->A\nE->C\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_419.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_419_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_419_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 420,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      4,
      0,
      4,
      5,
      3,
      5,
      1,
      5,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->E\nB->F\nC->D\nD->F\nE->B\nE->F\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_420.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_420_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_420_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 421,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      4,
      4,
      5,
      5
    ],
    "target": [
      1,
      2,
      4,
      5,
      2,
      3,
      3,
      5,
      2,
      3,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nA->F\nB->C\nB->D\nC->D\nC->F\nE->C\nE->D\nF->A\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_421.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_421_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_421_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 422,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      5,
      0,
      4,
      1,
      4,
      1,
      2,
      2,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->A\nB->E\nC->B\nC->E\nD->B\nD->C\nE->C\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_422.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_422_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_422_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 423,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      5,
      1,
      5,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nB->F\nE->B\nE->F\nF->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_423.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_423_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_423_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_423_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_423_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_423_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_423_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_423_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_423_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_423_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 424,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      1,
      1,
      5,
      3,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->F\nC->B\nE->B\nE->F\nF->D\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_424.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_424_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_424_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_424_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_424_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_424_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_424_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_424_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 425,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      0,
      1,
      4,
      0,
      5,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->F\nD->A\nD->B\nD->E\nE->A\nE->F\nF->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_425.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_425_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_425_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 426,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 3,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      6
    ],
    "target": [
      3,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nC->F\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_426.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_426_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_426_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_426_2.npy"
    ],
    "num_averaged_samples": 3
  },
  {
    "graph_id": 427,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      4,
      5
    ],
    "target": [
      2,
      4,
      2,
      4,
      2,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->C\nB->E\nD->C\nE->A\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_427.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_427_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_427_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_427_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_427_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_427_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_427_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_427_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 428,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      5,
      0,
      1,
      2,
      3,
      5,
      0,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nC->A\nC->B\nD->C\nE->D\nE->F\nF->A\nF->D\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_428.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_428_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_428_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 429,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 20,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      0,
      2,
      4,
      0,
      1,
      4,
      1,
      2,
      4,
      1,
      1,
      2,
      4,
      1,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->F\nB->A\nB->C\nB->E\nC->A\nC->B\nC->E\nD->B\nD->C\nD->E\nE->B\nF->B\nF->C\nF->E\nG->B\nG->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_429.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_429_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_15.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_16.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_17.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_18.npy",
      "attention_matrices/no_args_7_1b/avg_attn_429_19.npy"
    ],
    "num_averaged_samples": 20
  },
  {
    "graph_id": 430,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      6
    ],
    "target": [
      4,
      2,
      4,
      1,
      4,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->E\nC->B\nD->E\nE->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_430.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_430_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_430_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_430_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_430_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_430_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_430_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_430_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 431,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      0,
      5,
      1,
      0,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->A\nC->F\nD->B\nE->A\nE->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_431.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_431_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_431_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_431_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_431_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_431_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_431_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_431_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 432,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5
    ],
    "target": [
      0,
      2,
      3,
      5,
      1,
      1,
      4,
      1,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->D\nB->F\nC->B\nD->B\nD->E\nE->B\nE->C\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_432.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_432_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_432_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 433,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      5
    ],
    "target": [
      1,
      4,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nB->E\nD->B\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_433.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_433_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_433_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_433_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_433_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 434,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      5,
      3,
      5,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "D->F\nE->D\nE->F\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_434.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_434_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_434_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_434_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_434_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_434_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 435,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      4,
      3,
      5,
      0,
      3,
      5,
      4,
      1,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nB->F\nC->A\nC->D\nC->F\nD->E\nE->B\nG->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_435.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_435_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_435_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 436,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      5,
      5,
      6
    ],
    "target": [
      2,
      5,
      5,
      2,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nD->F\nF->C\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_436.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_436_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_436_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_436_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_436_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_436_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_436_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 437,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      4,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      3,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nA->F\nB->D\nE->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_437.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_437_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_437_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_437_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_437_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_437_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_437_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_437_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 438,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      1,
      1,
      4,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nE->B\nF->B\nF->E\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_438.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_438_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_438_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_438_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_438_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_438_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_438_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_438_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 439,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      5,
      0,
      3,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->A\nB->F\nC->A\nC->D\nD->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_439.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_439_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_439_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_439_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_439_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_439_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_439_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_439_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_439_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_439_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 440,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      4,
      1,
      5,
      5,
      3,
      4,
      0,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nC->B\nD->F\nE->F\nF->D\nF->E\nG->A\nG->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_440.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_440_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_440_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 441,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      5,
      0,
      1,
      0,
      2,
      3,
      4,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nC->A\nD->B\nE->A\nE->C\nF->D\nF->E\nG->A\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_441.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_441_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_441_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 442,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      4,
      5,
      0,
      1,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->E\nB->F\nD->A\nD->B\nF->A\nF->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_442.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_442_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_442_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_442_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_442_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_442_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_442_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_442_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 443,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      5,
      1,
      1,
      5,
      1,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->F\nD->B\nE->B\nE->F\nF->B\nF->D\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_443.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_443_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_443_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 444,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      4,
      6
    ],
    "target": [
      1,
      4,
      2,
      0,
      1,
      3,
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->C\nC->A\nC->B\nC->D\nE->A\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_444.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_444_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_444_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_444_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_444_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_444_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_444_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_444_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_444_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 445,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      5,
      5,
      6
    ],
    "target": [
      2,
      0,
      1,
      5,
      0,
      2,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nC->B\nC->F\nD->A\nF->C\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_445.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_445_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_445_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_445_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_445_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_445_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_445_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_445_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_445_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 446,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      1,
      2,
      2,
      0,
      1,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nC->B\nD->C\nE->C\nF->A\nF->B\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_446.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_446_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_446_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_446_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_446_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_446_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_446_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_446_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_446_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_446_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 447,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      1,
      4,
      2,
      5,
      2,
      0,
      3,
      4,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nC->B\nC->E\nD->C\nD->F\nE->C\nF->A\nF->D\nF->E\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_447.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_447_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_447_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 448,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      0,
      5,
      4,
      3,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nC->F\nD->E\nE->D\nF->A\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_448.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_448_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_448_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_448_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_448_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_448_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_448_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_448_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_448_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 449,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      3,
      4,
      1,
      1,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nC->D\nC->E\nE->B\nF->B\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_449.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_449_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_449_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_449_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_449_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_449_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_449_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_449_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_449_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 450,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      0,
      0,
      5,
      1,
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nC->A\nD->A\nD->F\nE->B\nF->A\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_450.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_450_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_450_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_450_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_450_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_450_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_450_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_450_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_450_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 451,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      6
    ],
    "target": [
      4,
      5,
      2,
      4,
      1,
      5,
      1,
      1,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->C\nB->E\nC->B\nC->F\nD->B\nE->B\nE->F\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_451.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_451_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_451_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 452,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      0,
      5,
      4,
      5,
      0,
      4,
      0,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nC->E\nC->F\nD->A\nD->E\nE->A\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_452.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_452_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_452_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_452_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_452_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_452_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_452_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_452_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_452_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_452_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 453,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      0,
      2,
      4,
      5,
      0,
      1,
      1,
      1,
      2,
      0,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->E\nB->F\nC->A\nC->B\nD->B\nE->B\nE->C\nF->A\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_453.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_453_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_453_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 454,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      3,
      0,
      5,
      0,
      4,
      2,
      5,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->F\nC->A\nD->E\nE->C\nE->F\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_454.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_454_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_454_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_454_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_454_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_454_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_454_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_454_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_454_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_454_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 455,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      5,
      5
    ],
    "target": [
      2,
      4,
      0,
      2,
      3,
      4,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nB->C\nC->D\nD->E\nE->A\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_455.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_455_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_455_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_455_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_455_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_455_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_455_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_455_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_455_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_455_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 456,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5
    ],
    "target": [
      3,
      5,
      1,
      5,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->D\nB->F\nC->B\nD->F\nE->D\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_456.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_456_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_456_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_456_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_456_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_456_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_456_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 457,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      5,
      3,
      4,
      5,
      1,
      4,
      1,
      3,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->F\nB->D\nB->E\nB->F\nC->B\nD->E\nE->B\nE->D\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_457.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_457_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_457_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 458,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      4,
      5,
      4,
      2,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nA->F\nB->E\nB->F\nC->E\nD->C\nD->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_458.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_458_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_458_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 459,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      5,
      2,
      5,
      1,
      5,
      0,
      4,
      5,
      1,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nB->F\nC->B\nC->F\nD->A\nD->E\nD->F\nE->B\nE->C\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_459.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_459_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_459_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 460,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      1,
      3,
      1,
      2,
      3,
      2,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nC->B\nC->D\nE->B\nE->C\nE->D\nF->C\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_460.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_460_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_460_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 461,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      5,
      0,
      1,
      1,
      0,
      1,
      2,
      1,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nC->A\nC->B\nD->B\nE->A\nE->B\nE->C\nF->B\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_461.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_461_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_461_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 462,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      4,
      5,
      1,
      2,
      2,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nC->E\nC->F\nD->B\nD->C\nE->C\nE->F\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_462.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_462_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_462_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_462_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_462_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_462_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_462_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_462_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_462_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 463,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      1,
      0,
      1,
      3,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nE->B\nF->A\nF->B\nF->D\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_463.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_463_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_463_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_463_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_463_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_463_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_463_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_463_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_463_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 464,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      0,
      4,
      0,
      3,
      0,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nC->A\nC->E\nE->A\nE->D\nF->A\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_464.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_464_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_464_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_464_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_464_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_464_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_464_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_464_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_464_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_464_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 465,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      4,
      4,
      1,
      4,
      1,
      3,
      0,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nC->B\nC->E\nD->B\nE->D\nF->A\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_465.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_465_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_465_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_465_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_465_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_465_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_465_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_465_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_465_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_465_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 466,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      3,
      0,
      1,
      4,
      1,
      5,
      3,
      4,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nC->D\nD->A\nD->B\nD->E\nE->B\nE->F\nF->D\nF->E\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_466.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_466_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_466_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 467,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      4,
      5,
      2,
      0,
      0,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->C\nD->A\nE->A\nE->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_467.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_467_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_467_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_467_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_467_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_467_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_467_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_467_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_467_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 468,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      4,
      5
    ],
    "target": [
      5,
      2,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nC->A\nE->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_468.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_468_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_468_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_468_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_468_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_468_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 469,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      4,
      4,
      6
    ],
    "target": [
      4,
      3,
      0,
      0,
      0,
      2,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nC->A\nD->A\nE->A\nE->C\nE->F\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_469.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_469_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_469_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_469_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_469_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_469_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_469_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_469_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_469_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 470,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      0,
      4,
      5,
      1,
      3,
      0,
      1,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nD->A\nD->E\nD->F\nE->B\nE->D\nF->A\nF->B\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_470.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_470_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_470_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 471,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      1,
      5,
      3,
      5,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nC->B\nD->F\nE->D\nE->F\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_471.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_471_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_471_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_471_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_471_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_471_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_471_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_471_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 472,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      4,
      4
    ],
    "target": [
      4,
      5,
      0,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nB->F\nC->A\nE->A\nE->B\n",
    "averaged_attention_matrix_path": "averaged_id_472.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_472_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_472_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_472_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_472_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_472_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 473,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      3,
      3,
      1,
      1,
      5,
      2,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nC->B\nD->B\nD->F\nF->C\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_473.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_473_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_473_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_473_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_473_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_473_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_473_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_473_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_473_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 474,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      0,
      0,
      4,
      3,
      1,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nC->A\nD->A\nD->E\nE->D\nF->B\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_474.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_474_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_474_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_474_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_474_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_474_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_474_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_474_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_474_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 475,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      1,
      1,
      2,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->F\nC->B\nE->B\nE->C\nF->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_475.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_475_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_475_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_475_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_475_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_475_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_475_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_475_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 476,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      4,
      4,
      5
    ],
    "target": [
      3,
      5,
      3,
      0,
      1,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->D\nB->F\nC->D\nE->A\nE->B\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_476.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_476_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_476_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_476_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_476_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_476_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_476_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 477,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      5,
      6
    ],
    "target": [
      3,
      0,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->D\nC->A\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_477.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_477_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_477_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_477_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_477_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 478,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      0,
      5,
      2,
      2,
      3,
      0,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nD->C\nE->C\nE->D\nF->A\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_478.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_478_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_478_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_478_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_478_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_478_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_478_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_478_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_478_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 479,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      1,
      2,
      1,
      2,
      3,
      3,
      4,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nC->B\nD->C\nE->B\nE->C\nE->D\nF->D\nF->E\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_479.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_479_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_479_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 480,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      4,
      6
    ],
    "target": [
      3,
      4,
      0,
      5,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->D\nB->E\nC->A\nC->F\nE->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_480.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_480_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_480_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_480_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_480_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_480_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_480_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 481,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      4,
      5,
      3,
      4,
      0,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->E\nB->F\nC->D\nC->E\nE->A\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_481.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_481_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_481_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_481_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_481_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_481_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_481_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_481_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_481_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_481_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 482,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      4,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      1,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->A\nD->B\nE->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_482.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_482_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_482_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_482_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_482_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_482_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_482_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_482_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 483,
    "max_nodes": 7,
    "num_nodes": 3,
    "num_edges": 2,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2
    ],
    "target": [
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->A\nC->A\n",
    "averaged_attention_matrix_path": "averaged_id_483.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_483_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_483_1.npy"
    ],
    "num_averaged_samples": 2
  },
  {
    "graph_id": 484,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      4,
      6
    ],
    "target": [
      1,
      2,
      3,
      1,
      4,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->D\nD->B\nD->E\nE->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_484.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_484_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_484_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_484_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_484_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_484_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_484_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_484_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 485,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      4,
      6
    ],
    "target": [
      3,
      2,
      4,
      5,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nB->E\nC->F\nE->F\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_485.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_485_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_485_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_485_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_485_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_485_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_485_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 486,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      5,
      3,
      5,
      0,
      5,
      0,
      3,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->F\nB->D\nB->F\nE->A\nE->F\nF->A\nF->D\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_486.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_486_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_486_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 487,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      2,
      4,
      2,
      5,
      1,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->C\nB->E\nD->C\nD->F\nE->B\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_487.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_487_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_487_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_487_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_487_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_487_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_487_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_487_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_487_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_487_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 488,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      2,
      4,
      5,
      1,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nB->F\nD->C\nD->E\nE->F\nF->B\nF->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_488.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_488_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_488_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 489,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      4,
      0,
      1,
      3,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nB->A\nC->B\nC->D\nF->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_489.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_489_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_489_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_489_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_489_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_489_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_489_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_489_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_489_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_489_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 490,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      5,
      5,
      6
    ],
    "target": [
      1,
      5,
      2,
      3,
      5,
      1,
      5,
      0,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->C\nB->D\nB->F\nC->B\nC->F\nF->A\nF->D\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_490.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_490_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_490_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 491,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      4,
      6,
      6
    ],
    "target": [
      1,
      4,
      2,
      5,
      5,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->C\nB->F\nD->F\nE->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_491.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_491_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_491_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_491_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_491_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_491_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_491_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_491_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_491_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 492,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      3,
      5,
      2,
      1,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nC->F\nD->C\nF->B\nF->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_492.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_492_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_492_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_492_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_492_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_492_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_492_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_492_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_492_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 493,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      5,
      6,
      6
    ],
    "target": [
      0,
      5,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->A\nC->F\nF->E\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_493.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_493_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_493_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_493_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_493_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_493_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 494,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      3,
      5,
      1,
      3,
      4,
      5,
      0,
      2,
      3,
      0,
      3,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nB->F\nC->B\nC->D\nC->E\nC->F\nD->A\nE->C\nE->D\nF->A\nF->D\nG->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_494.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_494_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_494_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 495,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      5,
      1,
      4,
      0,
      5,
      0,
      5,
      2,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nB->F\nC->B\nC->E\nD->A\nD->F\nE->A\nE->F\nF->C\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_495.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_495_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_495_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 496,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      4,
      4
    ],
    "target": [
      5,
      0,
      4,
      0,
      5,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->E\nC->A\nC->F\nE->C\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_496.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_496_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_496_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_496_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_496_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_496_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_496_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_496_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 497,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      4,
      4,
      2,
      5,
      3,
      2,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->E\nD->C\nD->F\nE->D\nF->C\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_497.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_497_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_497_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 498,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      2,
      0,
      4,
      0,
      1,
      4,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->C\nD->A\nD->E\nE->A\nF->B\nF->E\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_498.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_498_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_498_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 499,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      1,
      0,
      4,
      5,
      1,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nC->E\nD->F\nE->B\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_499.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_499_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_499_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_499_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_499_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_499_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_499_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_499_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 500,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      4,
      5,
      2,
      3,
      1,
      4,
      3,
      0,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nA->F\nB->C\nB->D\nD->B\nD->E\nE->D\nF->A\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_500.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_500_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_500_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 501,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      3,
      4,
      4,
      1,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nC->E\nD->E\nE->B\nF->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_501.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_501_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_501_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_501_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_501_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_501_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_501_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_501_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_501_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 502,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      3,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      0,
      1,
      5,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "D->A\nD->B\nD->F\nF->A\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_502.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_502_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_502_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_502_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_502_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_502_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_502_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 503,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      3,
      5,
      0,
      2,
      0,
      3,
      4,
      0,
      4,
      1,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nB->C\nC->A\nC->D\nC->E\nD->A\nD->E\nE->B\nE->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_503.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_503_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_503_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 504,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      0,
      2,
      4,
      0,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nC->A\nD->C\nD->E\nE->A\nE->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_504.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_504_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_504_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_504_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_504_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_504_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_504_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_504_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 505,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      5,
      5
    ],
    "target": [
      5,
      2,
      5,
      0,
      1,
      4,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nB->F\nC->A\nD->B\nD->E\nF->A\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_505.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_505_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_505_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_505_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_505_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_505_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_505_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_505_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_505_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 506,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      1,
      3,
      0,
      2,
      5,
      0,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->B\nC->D\nD->A\nD->C\nD->F\nF->A\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_506.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_506_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_506_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_506_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_506_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_506_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_506_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_506_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_506_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 507,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      0,
      3,
      0,
      2,
      5,
      2,
      3,
      2,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->E\nC->A\nC->D\nD->A\nD->C\nD->F\nE->C\nE->D\nF->C\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_507.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_507_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_507_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 508,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      6,
      6,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      1,
      4,
      5,
      4,
      1,
      0,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nC->B\nC->E\nC->F\nD->E\nE->B\nG->A\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_508.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_508_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_508_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 509,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      3,
      4,
      0,
      3,
      5,
      0,
      3,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nC->D\nD->E\nE->A\nE->D\nE->F\nF->A\nF->D\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_509.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_509_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_509_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 510,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      1,
      2,
      0,
      0,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nC->B\nD->C\nF->A\nG->A\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_510.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_510_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_510_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_510_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_510_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_510_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_510_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_510_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_510_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_510_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 511,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      5,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      0,
      1,
      4,
      4,
      1,
      2,
      3,
      4,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->D\nC->A\nC->B\nC->E\nD->E\nF->B\nF->C\nF->D\nF->E\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_511.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_511_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_511_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 512,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      2,
      3,
      3,
      3,
      3,
      4,
      5
    ],
    "target": [
      5,
      0,
      1,
      3,
      0,
      1,
      4,
      5,
      5,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->F\nC->A\nC->B\nC->D\nD->A\nD->B\nD->E\nD->F\nE->F\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_512.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_512_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_512_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 513,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      3,
      4,
      5
    ],
    "target": [
      3,
      2,
      4,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nD->C\nD->E\nE->F\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_513.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_513_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_513_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_513_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_513_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_513_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 514,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      3,
      4
    ],
    "target": [
      0,
      2,
      4,
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->E\nD->F\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_514.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_514_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_514_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_514_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_514_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_514_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 515,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      4,
      3,
      1,
      5,
      0,
      3,
      1,
      2,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->E\nC->D\nD->B\nD->F\nE->A\nE->D\nF->B\nF->C\nG->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_515.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_515_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_515_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 516,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      4,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      3,
      1,
      2,
      0,
      1,
      2,
      5,
      3,
      4,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->A\nC->D\nD->B\nD->C\nE->A\nE->B\nE->C\nE->F\nF->D\nF->E\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_516.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_516_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_516_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 517,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      6
    ],
    "target": [
      1,
      2,
      0,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nB->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_517.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_517_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_517_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_517_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_517_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_517_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 518,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      5,
      3,
      5,
      1,
      4,
      1,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->F\nC->D\nC->F\nD->B\nD->E\nF->B\nF->D\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_518.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_518_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_518_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_518_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_518_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_518_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_518_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_518_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_518_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 519,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      3,
      4,
      5,
      1,
      1,
      3,
      5,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nA->E\nB->F\nC->B\nD->B\nE->D\nE->F\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_519.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_519_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_519_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 520,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      3,
      2,
      1,
      3,
      2,
      5,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nC->B\nC->D\nD->C\nE->F\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_520.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_520_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_520_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_520_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_520_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_520_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_520_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_520_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_520_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 521,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      4,
      5,
      3,
      0,
      3,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nD->E\nD->F\nE->D\nF->A\nF->D\nG->A\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_521.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_521_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_521_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 522,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      4,
      5,
      0,
      2,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->E\nB->F\nC->A\nF->C\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_522.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_522_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_522_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_522_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_522_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_522_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_522_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_522_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_522_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 523,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      2,
      0,
      0,
      0,
      5,
      1,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nC->A\nD->A\nD->F\nE->B\nE->C\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_523.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_523_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_523_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_523_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_523_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_523_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_523_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_523_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_523_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 524,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      2,
      2,
      3,
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nD->C\nE->D\nE->F\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_524.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_524_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_524_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_524_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_524_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_524_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_524_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 525,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      3,
      2,
      1,
      5,
      2,
      4,
      1,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nC->B\nC->F\nD->C\nD->E\nE->B\nE->F\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_525.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_525_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_525_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_525_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_525_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_525_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_525_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_525_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_525_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_525_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 526,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      3,
      1,
      0,
      5,
      1,
      3,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nC->B\nD->A\nD->F\nE->B\nF->D\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_526.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_526_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_526_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_526_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_526_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_526_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_526_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_526_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_526_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_526_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 527,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      2,
      0,
      0,
      2,
      3,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->C\nC->A\nE->A\nF->C\nF->D\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_527.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_527_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_527_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_527_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_527_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_527_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_527_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_527_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_527_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_527_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 528,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      0,
      5,
      0,
      0,
      2,
      1,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->F\nC->A\nD->A\nD->C\nE->B\nF->A\nF->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_528.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_528_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_528_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 529,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      0,
      3,
      0,
      1,
      0,
      1,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nC->D\nD->A\nD->B\nE->A\nE->B\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_529.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_529_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_529_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 530,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      4,
      5,
      5
    ],
    "target": [
      4,
      0,
      3,
      5,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->E\nC->A\nE->D\nE->F\nF->B\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_530.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_530_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_530_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_530_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_530_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_530_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_530_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 531,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      4,
      2,
      3,
      5,
      1,
      4,
      4,
      5,
      2,
      3,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->D\nB->F\nC->B\nC->E\nD->E\nD->F\nE->C\nE->D\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_531.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_531_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_531_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 532,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      2,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      1,
      1,
      2,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nB->F\nC->A\nC->B\nF->B\nF->C\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_532.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_532_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_532_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_532_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_532_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_532_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_532_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_532_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_532_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_532_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 533,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      5,
      5
    ],
    "target": [
      5,
      3,
      1,
      1,
      4,
      5,
      1,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nC->B\nD->B\nD->E\nD->F\nE->B\nF->B\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_533.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_533_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_533_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_533_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_533_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_533_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_533_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_533_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_533_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_533_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 534,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      0,
      5,
      5,
      1,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nB->F\nD->F\nF->B\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_534.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_534_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_534_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_534_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_534_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_534_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_534_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_534_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_534_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 535,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      4,
      0,
      5,
      5,
      0,
      1,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nC->A\nD->F\nE->F\nF->A\nF->B\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_535.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_535_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_535_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_535_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_535_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_535_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_535_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_535_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_535_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 536,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      6,
      6
    ],
    "target": [
      2,
      4,
      4,
      0,
      4,
      0,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->E\nC->A\nC->E\nD->A\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_536.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_536_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_536_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_536_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_536_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_536_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_536_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_536_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_536_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 537,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 18,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      2,
      3,
      3,
      3,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      3,
      4,
      0,
      3,
      4,
      5,
      1,
      2,
      4,
      5,
      0,
      0,
      1,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->D\nB->E\nC->A\nC->D\nC->E\nC->F\nD->B\nD->C\nD->E\nD->F\nE->A\nF->A\nF->B\nG->A\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_537.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_537_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_15.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_16.npy",
      "attention_matrices/no_args_7_1b/avg_attn_537_17.npy"
    ],
    "num_averaged_samples": 18
  },
  {
    "graph_id": 538,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      0,
      5,
      0,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nC->A\nC->F\nE->A\nF->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_538.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_538_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_538_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_538_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_538_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_538_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_538_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_538_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 539,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      4,
      4,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      1,
      0,
      1,
      2,
      3,
      0,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nD->B\nE->A\nE->B\nE->C\nF->D\nG->A\nG->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_539.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_539_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_539_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 540,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      4,
      4,
      6,
      6
    ],
    "target": [
      3,
      0,
      0,
      5,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nC->A\nE->A\nE->F\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_540.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_540_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_540_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_540_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_540_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_540_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_540_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 541,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      3,
      3,
      0,
      0,
      0,
      3,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->D\nC->A\nD->A\nE->A\nE->D\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_541.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_541_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_541_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_541_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_541_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_541_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_541_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_541_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_541_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_541_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 542,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      5,
      3,
      2,
      4,
      1,
      3,
      3,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->F\nC->D\nD->C\nD->E\nE->B\nE->D\nF->D\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_542.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_542_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_542_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 543,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      0,
      4,
      1,
      5,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->D\nB->F\nC->A\nC->E\nD->B\nD->F\nE->C\nE->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_543.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_543_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_543_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 544,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      0,
      1,
      1,
      5,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nD->A\nD->B\nE->B\nE->F\nF->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_544.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_544_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_544_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_544_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_544_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_544_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_544_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_544_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_544_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 545,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      5,
      5,
      6,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      4,
      3,
      4,
      4,
      0,
      2,
      0,
      1,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->D\nB->E\nD->E\nF->A\nF->C\nG->A\nG->B\nG->C\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_545.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_545_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_545_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 546,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      3,
      4,
      1,
      4,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->D\nB->E\nC->B\nC->E\nF->B\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_546.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_546_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_546_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_546_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_546_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_546_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_546_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_546_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_546_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_546_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 547,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      0,
      1,
      5,
      0,
      0,
      1,
      3,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nC->A\nC->B\nC->F\nD->A\nE->A\nE->B\nF->D\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_547.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_547_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_547_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 548,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      4,
      4,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      5,
      0,
      2,
      2,
      1,
      5,
      1,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->A\nB->C\nD->C\nE->B\nE->F\nG->B\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_548.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_548_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_548_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 549,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      3,
      3,
      4,
      0,
      1,
      3,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->D\nC->D\nD->E\nE->A\nE->B\nE->D\nF->E\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_549.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_549_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_549_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 550,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      4,
      5,
      3,
      1,
      4,
      2,
      4,
      2,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->D\nC->B\nC->E\nD->C\nD->E\nE->C\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_550.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_550_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_550_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 551,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      5,
      0,
      3,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nB->F\nC->A\nD->F\nE->A\nE->D\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_551.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_551_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_551_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_551_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_551_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_551_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_551_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_551_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_551_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_551_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 552,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      0,
      1,
      3,
      5,
      2,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nC->B\nC->D\nC->F\nD->C\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_552.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_552_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_552_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_552_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_552_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_552_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_552_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_552_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 553,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      3,
      4,
      2,
      0,
      3,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->D\nC->E\nD->C\nE->A\nE->D\nF->A\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_553.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_553_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_553_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 554,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      0,
      1,
      2,
      2,
      1,
      2,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->E\nC->A\nC->B\nD->C\nE->C\nF->B\nF->C\nG->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_554.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_554_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_554_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 555,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      6,
      6
    ],
    "target": [
      4,
      2,
      3,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nC->D\nD->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_555.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_555_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_555_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_555_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_555_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_555_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_555_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 556,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      5,
      5,
      6
    ],
    "target": [
      3,
      3,
      0,
      1,
      5,
      1,
      0,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nC->A\nC->B\nC->F\nD->B\nF->A\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_556.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_556_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_556_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_556_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_556_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_556_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_556_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_556_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_556_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_556_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 557,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      4,
      5,
      5,
      5
    ],
    "target": [
      1,
      4,
      3,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nE->D\nF->A\nF->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_557.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_557_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_557_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_557_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_557_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_557_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_557_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 558,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      0,
      1,
      1,
      5,
      1,
      2,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nC->A\nC->B\nD->B\nD->F\nE->B\nE->C\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_558.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_558_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_558_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 559,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      2,
      5,
      0,
      3,
      5,
      1,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->C\nB->F\nC->A\nC->D\nE->F\nF->B\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_559.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_559_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_559_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 560,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      1,
      2,
      4,
      2,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->B\nC->D\nD->B\nD->C\nD->E\nE->C\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_560.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_560_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_560_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_560_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_560_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_560_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_560_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_560_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_560_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 561,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      1,
      0,
      2,
      5,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nD->B\nE->A\nE->C\nE->F\nF->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_561.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_561_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_561_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 562,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      4,
      3,
      0,
      2,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nB->E\nC->E\nE->D\nF->A\nF->C\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_562.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_562_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_562_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 563,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      3,
      3,
      3,
      5,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      4,
      5,
      2,
      4,
      0,
      4,
      5,
      0,
      1,
      3,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->C\nB->E\nD->A\nD->E\nD->F\nF->A\nF->B\nF->D\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_563.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_563_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_563_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 564,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      4,
      5,
      4,
      5,
      2,
      2,
      5,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->F\nC->E\nC->F\nD->C\nE->C\nE->F\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_564.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_564_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_564_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_564_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_564_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_564_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_564_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_564_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_564_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_564_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 565,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      0,
      4,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nC->F\nD->A\nD->E\nE->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_565.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_565_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_565_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_565_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_565_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_565_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_565_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_565_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_565_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 566,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      4,
      4,
      4,
      5
    ],
    "target": [
      5,
      0,
      4,
      2,
      3,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->F\nC->A\nC->E\nE->C\nE->D\nE->F\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_566.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_566_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_566_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_566_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_566_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_566_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_566_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_566_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 567,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      6
    ],
    "target": [
      1,
      3,
      4,
      0,
      3,
      0,
      5,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->E\nC->A\nC->D\nD->A\nD->F\nE->D\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_567.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_567_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_567_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_567_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_567_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_567_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_567_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_567_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_567_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_567_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 568,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      0,
      4,
      3,
      1,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->A\nB->E\nC->D\nD->B\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_568.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_568_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_568_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_568_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_568_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_568_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_568_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_568_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_568_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_568_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 569,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      1,
      5,
      0,
      3,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->A\nD->B\nD->F\nE->A\nE->D\nF->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_569.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_569_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_569_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_569_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_569_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_569_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_569_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_569_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_569_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 570,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      4,
      0,
      2,
      5,
      5,
      0,
      2,
      2,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->C\nB->F\nC->F\nD->A\nD->C\nE->C\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_570.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_570_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_570_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 571,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      1,
      4,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nD->F\nE->B\nF->E\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_571.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_571_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_571_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_571_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_571_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_571_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_571_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_571_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 572,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      2,
      0,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nD->C\nE->A\nF->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_572.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_572_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_572_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_572_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_572_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_572_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_572_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 573,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      3,
      4,
      4,
      6
    ],
    "target": [
      0,
      1,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "D->A\nE->B\nE->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_573.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_573_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_573_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_573_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_573_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 574,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      3,
      3,
      3,
      4,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      1,
      2,
      4,
      5,
      0,
      1,
      5,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->D\nC->F\nD->A\nD->B\nD->C\nD->E\nD->F\nE->A\nE->B\nE->F\nG->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_574.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_574_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_574_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 575,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      4,
      5
    ],
    "target": [
      3,
      1,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->D\nD->B\nE->C\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_575.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_575_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_575_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_575_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_575_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 576,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2
    ],
    "target": [
      5,
      2,
      3,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nB->D\nB->E\nC->A\nC->D\n",
    "averaged_attention_matrix_path": "averaged_id_576.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_576_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_576_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_576_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_576_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_576_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_576_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 577,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      0,
      5,
      1,
      5,
      4,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->A\nC->F\nE->B\nE->F\nF->E\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_577.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_577_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_577_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_577_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_577_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_577_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_577_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_577_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_577_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_577_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 578,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      1,
      0,
      0,
      1,
      1,
      3,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nC->A\nC->B\nD->B\nE->D\nG->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_578.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_578_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_578_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_578_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_578_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_578_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_578_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_578_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_578_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_578_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 579,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      1,
      1,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nE->B\nF->B\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_579.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_579_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_579_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_579_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_579_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_579_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 580,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      4
    ],
    "target": [
      3,
      0,
      3,
      5,
      0,
      4,
      1,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->D\nB->F\nC->A\nC->E\nD->B\nD->F\nE->B\n",
    "averaged_attention_matrix_path": "averaged_id_580.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_580_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_580_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_580_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_580_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_580_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_580_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_580_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_580_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_580_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 581,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      3,
      3,
      4,
      5
    ],
    "target": [
      3,
      0,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nD->A\nD->E\nE->A\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_581.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_581_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_581_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_581_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_581_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_581_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 582,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      4,
      5,
      0,
      4,
      5,
      1,
      5,
      5,
      3,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->A\nC->E\nC->F\nD->B\nD->F\nE->F\nF->D\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_582.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_582_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_582_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 583,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      4,
      5,
      5,
      5
    ],
    "target": [
      2,
      3,
      1,
      2,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nC->D\nD->B\nE->C\nF->B\nF->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_583.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_583_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_583_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_583_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_583_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_583_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_583_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_583_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 584,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      4,
      5,
      0,
      2,
      3,
      4,
      4,
      1,
      2,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->A\nB->C\nC->D\nC->E\nD->E\nE->B\nF->C\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_584.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_584_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_584_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 585,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      1,
      2,
      4,
      5,
      2,
      3,
      2,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nC->D\nD->B\nD->C\nD->E\nD->F\nE->C\nE->D\nF->C\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_585.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_585_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_585_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 586,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      3,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      3,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->D\nD->E\nF->D\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_586.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_586_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_586_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_586_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_586_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_586_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 587,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      3,
      5,
      6
    ],
    "target": [
      3,
      4,
      1,
      4,
      0,
      5,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nC->B\nC->E\nD->A\nD->F\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_587.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_587_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_587_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_587_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_587_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_587_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_587_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_587_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_587_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 588,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      4,
      4,
      6,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      4,
      0,
      2,
      0,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->F\nD->E\nE->A\nE->C\nG->A\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_588.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_588_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_588_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 589,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      1,
      4,
      5,
      0,
      0,
      0,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nC->B\nC->E\nC->F\nD->A\nE->A\nF->A\nF->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_589.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_589_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_589_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 590,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      1,
      2,
      2,
      1,
      1,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nC->B\nD->C\nE->C\nF->B\nG->B\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_590.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_590_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_590_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 591,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 16,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      3,
      2,
      4,
      0,
      1,
      3,
      0,
      2,
      4,
      5,
      0,
      1,
      0,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nB->E\nC->A\nC->B\nC->D\nD->A\nD->C\nD->E\nE->F\nF->A\nF->B\nG->A\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_591.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_591_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_591_15.npy"
    ],
    "num_averaged_samples": 16
  },
  {
    "graph_id": 592,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      2,
      4,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      2,
      3,
      1,
      3,
      1,
      5,
      0,
      2,
      4,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->D\nC->B\nC->D\nE->B\nE->F\nF->A\nF->C\nF->E\nG->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_592.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_592_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_592_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 593,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      4,
      5,
      2,
      5,
      0,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->E\nB->F\nE->C\nE->F\nF->A\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_593.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_593_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_593_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_593_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_593_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_593_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_593_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_593_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_593_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_593_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 594,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      5,
      1,
      4,
      5,
      3,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "C->F\nD->B\nD->E\nD->F\nF->D\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_594.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_594_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_594_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_594_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_594_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_594_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_594_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_594_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 595,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nC->D\nD->F\nE->C\nE->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_595.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_595_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_595_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_595_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_595_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_595_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_595_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_595_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 596,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      5,
      0,
      4,
      5,
      2,
      3,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nD->A\nD->E\nE->F\nF->C\nF->D\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_596.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_596_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_596_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_596_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_596_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_596_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_596_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_596_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_596_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_596_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 597,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      1,
      2,
      5,
      0,
      1,
      2,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nD->B\nE->C\nE->F\nF->A\nF->B\nF->C\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_597.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_597_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_597_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 598,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      0,
      0,
      1,
      3,
      5,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nB->F\nC->A\nD->A\nE->B\nE->D\nE->F\nF->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_598.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_598_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_598_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 599,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      1,
      2,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      4,
      0,
      2,
      4,
      5,
      0,
      1,
      0,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->C\nB->E\nB->F\nC->A\nD->B\nE->A\nG->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_599.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_599_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_599_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 600,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      4,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      3,
      0,
      1,
      0,
      0,
      1,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->D\nC->D\nD->A\nD->B\nE->A\nG->A\nG->B\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_600.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_600_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_600_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 601,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      1,
      5,
      0,
      0,
      1,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->E\nC->B\nC->F\nD->A\nE->A\nE->B\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_601.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_601_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_601_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 602,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      3,
      4,
      0,
      1,
      3,
      0,
      5,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->D\nB->E\nC->A\nC->B\nC->D\nE->A\nE->F\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_602.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_602_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_602_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 603,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      2,
      4,
      3,
      4,
      5,
      1,
      2,
      5,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->C\nB->E\nC->D\nD->E\nD->F\nE->B\nE->C\nE->F\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_603.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_603_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_603_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 604,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      6
    ],
    "target": [
      1,
      2,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_604.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_604_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_604_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_604_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_604_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 605,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      3,
      3
    ],
    "target": [
      1,
      0,
      2,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nB->C\nD->B\nD->C\nD->F\n",
    "averaged_attention_matrix_path": "averaged_id_605.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_605_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_605_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_605_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_605_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_605_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_605_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 606,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      3,
      1,
      2,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->B\nC->D\nD->B\nD->C\nE->A\nE->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_606.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_606_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_606_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_606_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_606_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_606_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_606_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_606_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 607,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      3,
      2,
      5,
      1,
      4,
      5,
      2,
      5,
      1,
      2,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->C\nB->F\nC->B\nC->E\nC->F\nD->C\nD->F\nE->B\nF->C\nG->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_607.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_607_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_607_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 608,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      4,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      4,
      5,
      5,
      2,
      0,
      1,
      2,
      3,
      3,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->E\nB->F\nC->F\nD->C\nE->A\nE->B\nE->C\nE->D\nF->D\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_608.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_608_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_608_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 609,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      4,
      5
    ],
    "target": [
      0,
      0,
      3,
      5,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->A\nC->A\nC->D\nC->F\nE->C\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_609.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_609_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_609_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_609_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_609_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_609_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_609_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 610,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      2,
      3,
      3,
      6
    ],
    "target": [
      1,
      3,
      3,
      0,
      1,
      4,
      5,
      2,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->D\nC->A\nC->B\nC->E\nC->F\nD->C\nD->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_610.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_610_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_610_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 611,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      5,
      6
    ],
    "target": [
      4,
      2,
      2,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nD->C\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_611.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_611_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_611_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_611_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_611_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_611_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 612,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      4,
      5,
      3,
      3,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->F\nC->E\nD->F\nE->D\nF->D\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_612.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_612_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_612_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_612_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_612_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_612_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_612_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_612_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_612_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 613,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      1,
      4,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nF->B\nF->E\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_613.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_613_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_613_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_613_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_613_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_613_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_613_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 614,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      6
    ],
    "target": [
      1,
      5,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nC->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_614.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_614_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_614_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_614_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_614_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 615,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      5,
      0,
      2,
      4,
      5,
      2,
      0,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nC->F\nD->A\nD->C\nD->E\nD->F\nE->C\nF->A\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_615.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_615_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_615_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 616,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      5,
      6
    ],
    "target": [
      2,
      0,
      2,
      3,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->C\nB->D\nC->A\nF->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_616.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_616_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_616_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_616_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_616_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_616_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_616_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_616_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 617,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      5,
      4,
      5,
      1,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nB->F\nC->E\nD->F\nE->B\nF->A\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_617.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_617_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_617_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 618,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      2,
      5,
      0,
      5,
      5,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nC->A\nC->F\nD->F\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_618.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_618_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_618_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_618_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_618_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_618_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_618_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_618_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 619,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      4,
      2,
      4,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nD->C\nD->E\nE->A\nE->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_619.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_619_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_619_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_619_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_619_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_619_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_619_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 620,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      4,
      0,
      3,
      0,
      4,
      4,
      1,
      3,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->E\nB->A\nB->D\nC->A\nC->E\nD->E\nE->B\nE->D\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_620.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_620_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_620_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 621,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      3,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      3,
      5,
      1,
      5,
      0,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nB->D\nB->F\nC->B\nD->F\nF->A\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_621.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_621_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_621_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 622,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      4,
      1,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nC->E\nE->B\nF->A\nF->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_622.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_622_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_622_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_622_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_622_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_622_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_622_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_622_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 623,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      1,
      5,
      2,
      5,
      3,
      0,
      1,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nC->B\nC->F\nD->C\nD->F\nE->D\nF->A\nF->B\nF->C\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_623.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_623_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_623_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 624,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      4,
      0,
      4,
      5,
      0,
      2,
      5,
      1,
      3,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->E\nC->A\nC->E\nD->F\nE->A\nE->C\nE->F\nF->B\nF->D\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_624.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_624_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_624_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 625,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      4,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      4,
      0,
      1,
      1,
      3,
      5,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nB->F\nC->E\nD->A\nD->B\nE->B\nE->D\nE->F\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_625.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_625_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_625_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 626,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      5,
      0,
      3,
      4,
      3,
      0,
      0,
      3,
      4,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->D\nB->E\nC->D\nD->A\nE->A\nE->D\nF->E\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_626.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_626_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_626_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 627,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      5,
      5,
      6
    ],
    "target": [
      2,
      4,
      3,
      4,
      5,
      0,
      3,
      0,
      2,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->D\nB->E\nB->F\nC->A\nC->D\nD->A\nF->C\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_627.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_627_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_627_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 628,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      5,
      5,
      1,
      4,
      5,
      5,
      2,
      3,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->F\nC->B\nC->E\nC->F\nD->F\nE->C\nE->D\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_628.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_628_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_628_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 629,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      4,
      6,
      6,
      6
    ],
    "target": [
      3,
      0,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nE->A\nG->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_629.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_629_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_629_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_629_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_629_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_629_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 630,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      4,
      4,
      4,
      5,
      5
    ],
    "target": [
      4,
      5,
      2,
      1,
      3,
      0,
      2,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->C\nC->B\nC->D\nE->A\nE->C\nE->D\nF->B\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_630.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_630_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_630_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 631,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      4,
      0,
      4,
      0,
      0,
      2,
      1,
      1,
      3,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->E\nC->A\nD->A\nD->C\nE->B\nF->B\nF->D\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_631.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_631_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_631_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 632,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      4,
      4,
      4,
      6
    ],
    "target": [
      2,
      3,
      0,
      5,
      1,
      3,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nD->A\nD->F\nE->B\nE->D\nE->F\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_632.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_632_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_632_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_632_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_632_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_632_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_632_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_632_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_632_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 633,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      5,
      2,
      4,
      1,
      0,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->F\nD->C\nD->E\nE->B\nF->A\nF->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_633.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_633_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_633_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_633_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_633_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_633_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_633_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_633_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_633_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 634,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      0,
      4,
      1,
      2,
      5,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->E\nD->B\nE->C\nE->F\nF->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_634.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_634_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_634_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_634_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_634_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_634_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_634_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_634_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_634_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 635,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      4,
      4,
      5,
      2,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nC->D\nC->E\nD->E\nD->F\nE->C\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_635.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_635_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_635_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_635_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_635_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_635_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_635_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_635_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_635_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 636,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      3,
      0,
      1,
      3,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->F\nC->D\nF->A\nF->B\nF->D\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_636.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_636_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_636_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_636_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_636_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_636_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_636_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_636_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_636_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_636_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 637,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      5,
      2,
      3,
      4,
      5,
      5,
      1,
      2,
      5,
      1,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->C\nB->D\nB->E\nB->F\nC->F\nD->B\nD->C\nE->F\nF->B\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_637.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_637_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_637_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 638,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      3,
      4,
      6
    ],
    "target": [
      2,
      0,
      3,
      0,
      5,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nC->A\nC->D\nD->A\nD->F\nE->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_638.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_638_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_638_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_638_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_638_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_638_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_638_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_638_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 639,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      2,
      0,
      1,
      2,
      3,
      4,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->C\nC->A\nD->B\nE->C\nE->D\nF->E\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_639.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_639_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_639_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 640,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      4,
      5,
      1,
      1,
      2,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nC->E\nD->F\nE->B\nF->B\nF->C\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_640.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_640_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_640_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_640_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_640_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_640_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_640_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_640_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_640_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_640_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 641,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4
    ],
    "target": [
      1,
      0,
      0,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nC->A\nD->B\nD->C\nE->D\n",
    "averaged_attention_matrix_path": "averaged_id_641.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_641_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_641_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_641_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_641_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_641_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_641_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 642,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      5,
      0,
      5,
      0,
      4,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nC->A\nC->F\nF->A\nF->E\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_642.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_642_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_642_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_642_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_642_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_642_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_642_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_642_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_642_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 643,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      1,
      0,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->A\nD->B\nE->A\nF->E\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_643.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_643_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_643_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_643_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_643_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_643_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_643_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 644,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      4,
      3,
      4,
      5,
      2,
      3,
      4,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->E\nC->D\nC->E\nC->F\nE->C\nE->D\nF->E\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_644.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_644_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_644_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 645,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      3,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      0,
      2,
      4,
      0,
      4,
      5,
      2,
      2,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->A\nB->C\nB->E\nD->A\nD->E\nD->F\nE->C\nF->C\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_645.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_645_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_645_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 646,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      3,
      4,
      5,
      3,
      1,
      2,
      1,
      5,
      0,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->E\nB->F\nC->D\nD->B\nD->C\nE->B\nE->F\nF->A\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_646.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_646_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_646_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 647,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      3,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->D\nE->D\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_647.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_647_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_647_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_647_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_647_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_647_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_647_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 648,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      5,
      5
    ],
    "target": [
      1,
      2,
      3,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->D\nC->E\nF->A\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_648.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_648_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_648_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_648_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_648_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_648_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_648_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 649,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      5,
      3,
      5,
      3,
      2,
      5,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->D\nB->F\nC->D\nE->C\nE->F\nF->D\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_649.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_649_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_649_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 650,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      4,
      5,
      4,
      2,
      5,
      0,
      2,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->E\nE->C\nE->F\nF->A\nF->C\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_650.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_650_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_650_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 651,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      0,
      4,
      1,
      1,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->B\nD->A\nD->E\nE->B\nF->B\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_651.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_651_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_651_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_651_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_651_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_651_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_651_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_651_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_651_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 652,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      1,
      5,
      2,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "E->A\nE->B\nE->F\nF->C\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_652.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_652_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_652_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_652_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_652_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_652_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_652_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 653,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      1,
      5,
      0,
      2,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nC->B\nD->F\nF->A\nF->C\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_653.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_653_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_653_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_653_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_653_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_653_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_653_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_653_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 654,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      0,
      0,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->A\nD->A\nE->A\nF->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_654.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_654_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_654_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_654_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_654_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_654_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_654_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 655,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      5,
      5,
      5
    ],
    "target": [
      4,
      3,
      0,
      1,
      5,
      0,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nC->A\nC->B\nC->F\nD->A\nF->A\nF->B\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_655.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_655_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_655_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_655_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_655_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_655_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_655_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_655_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_655_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_655_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 656,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      0,
      4,
      1,
      2,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nD->E\nE->B\nE->C\nE->D\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_656.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_656_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_656_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_656_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_656_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_656_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_656_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_656_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_656_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 657,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      5,
      0,
      5,
      5,
      2,
      3,
      4,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nC->A\nC->F\nD->F\nE->C\nF->D\nF->E\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_657.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_657_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_657_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 658,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      4,
      5
    ],
    "target": [
      5,
      0,
      1,
      4,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->F\nC->A\nC->B\nD->E\nE->C\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_658.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_658_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_658_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_658_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_658_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_658_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_658_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 659,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      5,
      6,
      6
    ],
    "target": [
      4,
      1,
      2,
      0,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nC->B\nD->C\nF->A\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_659.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_659_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_659_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_659_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_659_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_659_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_659_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 660,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      5,
      4,
      5,
      0,
      1,
      2,
      1,
      2,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nB->E\nB->F\nC->A\nC->B\nD->C\nE->B\nE->C\nF->A\nF->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_660.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_660_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_660_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 661,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      1,
      5,
      0,
      3,
      5,
      0,
      1,
      2,
      5,
      0,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->A\nB->D\nC->F\nD->A\nD->B\nE->C\nE->F\nF->A\nF->C\nF->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_661.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_661_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_661_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 662,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      2,
      0,
      5,
      0,
      1,
      2,
      5,
      0,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->C\nC->A\nC->F\nD->A\nD->B\nD->C\nE->F\nF->A\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_662.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_662_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_662_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 663,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      6
    ],
    "target": [
      2,
      4,
      0,
      3,
      2,
      0,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nC->D\nD->C\nE->A\nE->F\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_663.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_663_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_663_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_663_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_663_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_663_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_663_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_663_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_663_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 664,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      5,
      4,
      3,
      5,
      1,
      4,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nB->E\nC->F\nD->E\nE->D\nE->F\nF->B\nF->E\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_664.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_664_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_664_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 665,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      0,
      5,
      3,
      3,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->E\nD->A\nD->F\nE->D\nF->D\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_665.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_665_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_665_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_665_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_665_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_665_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_665_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_665_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 666,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      4,
      5
    ],
    "target": [
      2,
      5,
      1,
      0,
      2,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nC->B\nD->A\nD->C\nE->A\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_666.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_666_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_666_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_666_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_666_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_666_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_666_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_666_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 667,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      2,
      5,
      5,
      0,
      1,
      4,
      2,
      0,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->F\nC->A\nC->B\nC->E\nD->C\nE->A\nE->F\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_667.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_667_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_667_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 668,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      2,
      4,
      1,
      4,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nD->C\nD->E\nF->B\nF->E\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_668.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_668_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_668_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_668_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_668_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_668_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_668_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_668_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_668_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 669,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      5,
      0,
      1,
      4,
      1,
      3,
      0,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->F\nD->A\nD->B\nD->E\nE->B\nE->D\nF->A\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_669.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_669_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_669_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 670,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      1,
      4,
      4,
      5,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nB->E\nC->B\nC->E\nD->E\nE->F\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_670.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_670_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_670_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_670_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_670_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_670_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_670_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_670_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_670_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_670_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 671,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      5,
      0,
      3,
      4,
      4,
      5,
      3,
      3,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->D\nC->E\nD->E\nD->F\nE->D\nF->D\nG->B\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_671.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_671_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_671_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 672,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      4,
      5,
      0,
      1,
      2,
      2,
      5,
      0,
      1,
      2,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nB->F\nC->A\nD->B\nD->C\nE->C\nE->F\nF->A\nF->B\nF->C\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_672.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_672_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_672_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 673,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      4,
      5,
      0,
      0,
      3,
      5,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->A\nB->E\nB->F\nC->A\nE->A\nE->D\nE->F\nF->C\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_673.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_673_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_673_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 674,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      3,
      4,
      4
    ],
    "target": [
      1,
      5,
      5,
      1,
      2,
      4,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->F\nD->B\nD->C\nD->E\nE->B\nE->C\n",
    "averaged_attention_matrix_path": "averaged_id_674.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_674_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_674_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_674_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_674_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_674_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_674_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_674_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_674_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 675,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      5,
      4,
      1,
      4,
      0,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->E\nD->B\nD->E\nE->A\nE->F\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_675.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_675_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_675_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_675_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_675_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_675_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_675_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_675_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_675_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 676,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      4,
      4,
      5
    ],
    "target": [
      4,
      4,
      3,
      5,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nE->D\nE->F\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_676.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_676_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_676_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_676_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_676_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_676_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 677,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      4,
      0,
      2,
      5,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nD->A\nE->C\nE->F\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_677.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_677_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_677_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_677_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_677_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_677_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_677_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 678,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      5,
      6
    ],
    "target": [
      3,
      4,
      5,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nC->E\nC->F\nF->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_678.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_678_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_678_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_678_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_678_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_678_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 679,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      4,
      6
    ],
    "target": [
      2,
      4,
      0,
      4,
      4,
      4,
      1,
      2,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nB->E\nC->E\nD->E\nE->B\nE->C\nE->F\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_679.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_679_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_679_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 680,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      5,
      3,
      4,
      3,
      4,
      1,
      5,
      4,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nA->F\nB->D\nB->E\nC->D\nC->E\nE->B\nE->F\nF->E\nG->A\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_680.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_680_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_680_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 681,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      5
    ],
    "target": [
      4,
      5,
      0,
      1,
      4,
      0,
      3,
      5,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->A\nC->B\nD->E\nE->A\nE->D\nE->F\nF->A\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_681.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_681_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_681_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 682,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      2,
      4,
      4,
      4,
      6
    ],
    "target": [
      1,
      3,
      0,
      4,
      5,
      0,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nC->A\nC->E\nC->F\nE->A\nE->B\nE->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_682.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_682_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_682_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_682_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_682_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_682_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_682_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_682_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_682_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_682_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 683,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      4,
      5,
      5
    ],
    "target": [
      4,
      0,
      1,
      1,
      2,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nC->A\nC->B\nD->B\nD->C\nE->C\nF->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_683.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_683_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_683_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_683_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_683_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_683_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_683_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_683_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_683_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 684,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      0,
      5,
      4,
      0,
      1,
      2,
      0,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nB->F\nD->E\nE->A\nE->B\nE->C\nF->A\nF->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_684.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_684_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_684_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 685,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      2,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      0,
      3,
      4,
      5,
      1,
      3,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->A\nC->D\nC->E\nC->F\nE->B\nE->D\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_685.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_685_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_685_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 686,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      5,
      6
    ],
    "target": [
      1,
      5,
      0,
      2,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->B\nC->F\nD->A\nD->C\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_686.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_686_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_686_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_686_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_686_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_686_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_686_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 687,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      4,
      5,
      5
    ],
    "target": [
      1,
      2,
      5,
      0,
      0,
      2,
      4,
      0,
      2,
      5,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->F\nC->A\nD->A\nD->C\nD->E\nE->A\nE->C\nE->F\nF->B\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_687.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_687_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_687_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 688,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      2,
      0,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nD->C\nF->A\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_688.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_688_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_688_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_688_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_688_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_688_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_688_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 689,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      4,
      4,
      4,
      5
    ],
    "target": [
      0,
      4,
      1,
      3,
      0,
      2,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->E\nC->B\nC->D\nE->A\nE->C\nE->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_689.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_689_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_689_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_689_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_689_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_689_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_689_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_689_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_689_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 690,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      3,
      3,
      3,
      3,
      4,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      0,
      2,
      4,
      5,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nA->F\nD->A\nD->C\nD->E\nD->F\nE->F\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_690.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_690_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_690_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 691,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      5,
      1,
      2,
      2,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->D\nB->F\nC->A\nC->F\nD->B\nD->C\nE->C\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_691.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_691_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_691_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_691_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_691_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_691_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_691_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_691_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_691_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_691_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 692,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      5
    ],
    "target": [
      0,
      2,
      5,
      3,
      5,
      0,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->F\nC->D\nC->F\nD->A\nD->F\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_692.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_692_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_692_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_692_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_692_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_692_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_692_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_692_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_692_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 693,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      1,
      3,
      1,
      3,
      4,
      5,
      5,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nC->B\nC->D\nC->E\nD->F\nE->F\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_693.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_693_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_693_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_693_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_693_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_693_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_693_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_693_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_693_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_693_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 694,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      0,
      3,
      4,
      5,
      1,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->D\nC->A\nC->D\nC->E\nD->F\nF->B\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_694.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_694_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_694_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_694_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_694_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_694_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_694_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_694_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_694_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_694_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 695,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      0,
      3,
      1,
      4,
      1,
      2,
      4,
      5,
      2,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->D\nC->B\nC->E\nD->B\nD->C\nD->E\nE->F\nF->C\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_695.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_695_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_695_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 696,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 3,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      3,
      4,
      5
    ],
    "target": [
      1,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "D->B\nE->F\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_696.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_696_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_696_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_696_2.npy"
    ],
    "num_averaged_samples": 3
  },
  {
    "graph_id": 697,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      4,
      5,
      4,
      5,
      0,
      5,
      0,
      1,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->A\nB->E\nC->F\nD->E\nD->F\nE->A\nE->F\nF->A\nF->B\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_697.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_697_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_697_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 698,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      2,
      3,
      4,
      4,
      5
    ],
    "target": [
      2,
      0,
      3,
      4,
      5,
      4,
      0,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->C\nC->A\nC->D\nC->E\nC->F\nD->E\nE->A\nE->C\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_698.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_698_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_698_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_698_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_698_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_698_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_698_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_698_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_698_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_698_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 699,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 16,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      4,
      2,
      4,
      0,
      5,
      0,
      1,
      3,
      0,
      1,
      2,
      4,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->C\nB->E\nC->A\nD->F\nE->A\nE->B\nE->D\nF->A\nF->B\nF->C\nF->E\nG->A\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_699.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_699_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_699_15.npy"
    ],
    "num_averaged_samples": 16
  },
  {
    "graph_id": 700,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      0,
      1,
      4,
      1,
      3,
      5,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nC->B\nC->E\nE->B\nE->D\nE->F\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_700.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_700_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_700_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_700_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_700_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_700_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_700_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_700_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_700_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_700_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 701,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      0,
      3,
      1,
      3,
      5,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nD->B\nE->D\nE->F\nF->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_701.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_701_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_701_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_701_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_701_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_701_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_701_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_701_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 702,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      3,
      3,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      0,
      3,
      4,
      5,
      0,
      2,
      4,
      5,
      3,
      2,
      3,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nC->D\nC->E\nC->F\nD->A\nD->C\nD->E\nD->F\nE->D\nF->C\nF->D\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_702.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_702_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_702_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 703,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      5,
      3,
      4,
      3,
      2,
      0,
      1,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->D\nB->E\nC->D\nE->C\nF->A\nF->B\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_703.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_703_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_703_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 704,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      5,
      0,
      0,
      1,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nC->F\nE->A\nF->A\nF->B\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_704.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_704_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_704_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_704_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_704_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_704_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_704_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 705,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      4,
      4,
      4,
      5,
      5,
      5
    ],
    "target": [
      4,
      0,
      0,
      0,
      2,
      5,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nC->A\nE->A\nE->C\nE->F\nF->B\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_705.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_705_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_705_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_705_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_705_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_705_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_705_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_705_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_705_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_705_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 706,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      2,
      5,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->D\nE->C\nE->F\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_706.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_706_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_706_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_706_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_706_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_706_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 707,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      3,
      3,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      5,
      1,
      5,
      2,
      0,
      1,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->F\nD->B\nD->F\nE->C\nF->A\nF->B\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_707.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_707_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_707_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 708,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      5,
      5,
      6
    ],
    "target": [
      3,
      4,
      3,
      2,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nC->D\nD->C\nF->A\nF->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_708.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_708_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_708_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_708_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_708_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_708_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_708_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_708_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 709,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      4,
      3,
      4,
      1,
      0,
      2,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->D\nB->E\nC->B\nE->A\nE->C\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_709.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_709_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_709_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_709_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_709_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_709_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_709_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_709_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_709_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_709_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 710,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      5,
      1,
      4,
      1,
      2,
      4,
      0,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nC->B\nC->E\nD->B\nD->C\nD->E\nE->A\nG->A\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_710.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_710_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_710_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 711,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      1,
      4,
      0,
      5,
      0,
      1,
      4,
      0,
      1,
      2,
      3,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nC->F\nD->A\nD->B\nD->E\nE->A\nE->B\nF->C\nF->D\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_711.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_711_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_711_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 712,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      0,
      0,
      0,
      3,
      0,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nC->A\nF->A\nF->D\nG->A\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_712.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_712_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_712_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 713,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      5,
      3,
      1,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nE->F\nF->D\nG->B\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_713.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_713_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_713_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_713_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_713_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_713_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_713_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 714,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      2,
      5,
      2,
      2,
      3,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->F\nD->A\nD->C\nD->F\nE->C\nF->C\nF->D\nF->E\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_714.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_714_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_714_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 715,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      4,
      2,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nB->E\nD->C\nE->A\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_715.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_715_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_715_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_715_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_715_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_715_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_715_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_715_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 716,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      4,
      4,
      5
    ],
    "target": [
      5,
      3,
      4,
      5,
      0,
      0,
      1,
      2,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->F\nC->D\nC->E\nC->F\nD->A\nE->A\nE->B\nE->C\nE->D\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_716.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_716_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_716_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 717,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      5,
      5,
      5,
      6
    ],
    "target": [
      1,
      3,
      5,
      3,
      1,
      1,
      2,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->F\nB->D\nC->B\nF->B\nF->C\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_717.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_717_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_717_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_717_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_717_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_717_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_717_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_717_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_717_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_717_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 718,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      5,
      6
    ],
    "target": [
      1,
      2,
      1,
      1,
      4,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nC->B\nD->B\nD->E\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_718.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_718_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_718_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_718_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_718_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_718_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_718_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_718_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 719,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      5,
      2,
      4,
      3,
      5,
      2,
      4,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->E\nB->F\nD->C\nD->E\nE->D\nE->F\nF->C\nF->E\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_719.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_719_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_719_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 720,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      6
    ],
    "target": [
      2,
      0,
      1,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nC->B\nD->F\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_720.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_720_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_720_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_720_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_720_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_720_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 721,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      3,
      3,
      3,
      5,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      3,
      0,
      1,
      2,
      0,
      2,
      3,
      0,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->F\nB->D\nD->A\nD->B\nD->C\nF->A\nF->C\nF->D\nG->A\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_721.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_721_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_721_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 722,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      4,
      4,
      5,
      5
    ],
    "target": [
      2,
      3,
      2,
      1,
      1,
      3,
      5,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->C\nC->B\nE->B\nE->D\nE->F\nF->A\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_722.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_722_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_722_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_722_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_722_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_722_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_722_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_722_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_722_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_722_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 723,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      4,
      0,
      5,
      0,
      5,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nB->A\nC->F\nE->A\nE->F\nF->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_723.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_723_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_723_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_723_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_723_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_723_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_723_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_723_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_723_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_723_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 724,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      3,
      6
    ],
    "target": [
      1,
      2,
      0,
      3,
      5,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nB->D\nB->F\nD->F\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_724.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_724_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_724_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_724_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_724_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_724_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_724_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_724_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 725,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      3,
      3,
      3,
      4,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      4,
      0,
      2,
      4,
      2,
      3,
      5,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->E\nD->A\nD->C\nD->E\nE->C\nE->D\nE->F\nF->C\nF->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_725.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_725_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_725_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 726,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      4,
      5,
      5
    ],
    "target": [
      3,
      0,
      1,
      2,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nC->A\nC->B\nE->C\nF->B\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_726.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_726_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_726_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_726_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_726_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_726_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_726_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 727,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      6,
      6
    ],
    "target": [
      4,
      2,
      3,
      5,
      3,
      5,
      1,
      2,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->D\nB->F\nC->D\nC->F\nD->B\nD->C\nE->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_727.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_727_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_727_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 728,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      4,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      0,
      2,
      5,
      1,
      2,
      3,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nB->F\nC->A\nD->C\nD->F\nE->B\nE->C\nE->D\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_728.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_728_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_728_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 729,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      2,
      5,
      1,
      3,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->C\nB->F\nC->B\nC->D\nF->C\nF->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_729.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_729_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_729_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_729_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_729_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_729_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_729_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_729_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_729_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_729_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 730,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      0,
      4,
      5,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->A\nC->E\nD->F\nE->B\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_730.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_730_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_730_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_730_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_730_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_730_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_730_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 731,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      4,
      5,
      3,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "C->E\nD->F\nE->D\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_731.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_731_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_731_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_731_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_731_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_731_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 732,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      6,
      6
    ],
    "target": [
      4,
      2,
      4,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->E\nD->C\nD->E\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_732.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_732_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_732_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_732_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_732_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_732_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 733,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      3,
      6
    ],
    "target": [
      2,
      5,
      5,
      0,
      3,
      0,
      2,
      4,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->F\nC->A\nC->D\nD->A\nD->C\nD->E\nD->F\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_733.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_733_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_733_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 734,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      4,
      0,
      5,
      2,
      4,
      2,
      3,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->E\nC->A\nC->F\nD->C\nD->E\nF->C\nF->D\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_734.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_734_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_734_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 735,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      1,
      4,
      2,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nB->F\nC->B\nC->E\nE->C\nF->A\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_735.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_735_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_735_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_735_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_735_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_735_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_735_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_735_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_735_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_735_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 736,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      1,
      5,
      3,
      4,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nD->C\nE->B\nE->F\nF->D\nF->E\nG->A\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_736.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_736_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_736_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_736_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_736_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_736_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_736_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_736_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_736_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_736_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 737,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      5
    ],
    "target": [
      2,
      3,
      3,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nC->D\nD->A\nD->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_737.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_737_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_737_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_737_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_737_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_737_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_737_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 738,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      4,
      6
    ],
    "target": [
      1,
      5,
      4,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "C->B\nC->F\nD->E\nE->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_738.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_738_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_738_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_738_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_738_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_738_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 739,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      4,
      4,
      5,
      5
    ],
    "target": [
      5,
      4,
      3,
      5,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nB->E\nE->D\nE->F\nF->B\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_739.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_739_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_739_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_739_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_739_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_739_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_739_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 740,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      5,
      5,
      6
    ],
    "target": [
      0,
      4,
      1,
      3,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->E\nC->B\nC->D\nF->C\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_740.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_740_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_740_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_740_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_740_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_740_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_740_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_740_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 741,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      3,
      1,
      5,
      3,
      1,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nC->D\nD->B\nD->F\nE->D\nF->B\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_741.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_741_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_741_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_741_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_741_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_741_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_741_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_741_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_741_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 742,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      1,
      2,
      1,
      2,
      1,
      4,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->F\nC->A\nD->B\nD->C\nE->B\nE->C\nF->B\nF->E\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_742.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_742_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_742_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 743,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      5,
      3,
      1,
      3,
      5,
      5,
      1,
      2,
      1,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->D\nC->B\nC->D\nC->F\nD->F\nE->B\nE->C\nF->B\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_743.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_743_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_743_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 744,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      3,
      4
    ],
    "target": [
      2,
      3,
      0,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nD->A\nD->F\nE->B\n",
    "averaged_attention_matrix_path": "averaged_id_744.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_744_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_744_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_744_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_744_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_744_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 745,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      6,
      6
    ],
    "target": [
      0,
      0,
      5,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nC->A\nE->F\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_745.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_745_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_745_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_745_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_745_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_745_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 746,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      2,
      3,
      4,
      1,
      2,
      4,
      3,
      5,
      2,
      3,
      4,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nB->D\nB->E\nD->B\nD->C\nD->E\nE->D\nE->F\nF->C\nF->D\nF->E\nG->A\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_746.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_746_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_746_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 747,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      4,
      0,
      4,
      5,
      0,
      1,
      2,
      3,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nC->E\nD->F\nE->A\nE->B\nE->C\nE->D\nF->A\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_747.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_747_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_747_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 748,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      4,
      5
    ],
    "target": [
      4,
      5,
      4,
      5,
      5,
      1,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->E\nB->F\nC->F\nE->B\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_748.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_748_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_748_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_748_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_748_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_748_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_748_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_748_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 749,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      4,
      0,
      1,
      4,
      5,
      3,
      3,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nB->E\nC->A\nD->B\nD->E\nD->F\nE->D\nF->D\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_749.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_749_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_749_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 750,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      2,
      4,
      5,
      0,
      3,
      0,
      2,
      4,
      5,
      0,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nB->F\nC->A\nC->D\nD->A\nD->C\nD->E\nD->F\nE->A\nE->F\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_750.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_750_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_750_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 751,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      5,
      4,
      5,
      1,
      2,
      2,
      3,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->F\nC->E\nC->F\nD->B\nD->C\nE->C\nE->D\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_751.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_751_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_751_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 752,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      4,
      0,
      4,
      5,
      4,
      5,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->E\nC->A\nC->E\nC->F\nD->E\nE->F\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_752.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_752_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_752_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_752_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_752_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_752_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_752_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_752_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_752_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 753,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      6,
      6,
      6
    ],
    "target": [
      0,
      3,
      0,
      5,
      5,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nC->A\nC->F\nD->F\nG->A\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_753.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_753_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_753_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_753_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_753_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_753_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_753_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_753_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_753_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 754,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      5
    ],
    "target": [
      5,
      4,
      1,
      5,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->F\nC->E\nD->B\nD->F\nE->D\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_754.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_754_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_754_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_754_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_754_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_754_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_754_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 755,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      4,
      5,
      5,
      0,
      4,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->A\nC->E\nD->F\nE->F\nF->A\nF->E\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_755.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_755_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_755_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_755_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_755_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_755_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_755_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_755_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_755_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 756,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      0,
      1,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->F\nC->A\nE->B\nG->A\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_756.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_756_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_756_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_756_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_756_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_756_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_756_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_756_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_756_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 757,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      5,
      1,
      3,
      5,
      5,
      2,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nC->B\nC->D\nC->F\nD->F\nE->C\nF->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_757.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_757_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_757_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_757_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_757_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_757_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_757_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_757_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_757_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 758,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      4,
      5
    ],
    "target": [
      2,
      4,
      5,
      0,
      3,
      5,
      4,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nB->F\nC->A\nC->D\nC->F\nD->E\nE->D\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_758.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_758_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_758_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_758_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_758_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_758_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_758_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_758_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_758_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_758_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 759,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      6,
      6
    ],
    "target": [
      5,
      2,
      0,
      4,
      5,
      2,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nC->A\nC->E\nC->F\nD->C\nE->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_759.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_759_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_759_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_759_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_759_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_759_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_759_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_759_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_759_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_759_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 760,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      6,
      6
    ],
    "target": [
      0,
      3,
      5,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nD->F\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_760.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_760_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_760_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_760_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_760_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_760_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 761,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      4
    ],
    "target": [
      3,
      5,
      4,
      1,
      4,
      5,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->E\nC->B\nC->E\nC->F\nE->C\n",
    "averaged_attention_matrix_path": "averaged_id_761.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_761_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_761_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_761_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_761_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_761_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_761_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_761_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 762,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      4,
      4,
      5,
      3,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nB->E\nB->F\nE->D\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_762.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_762_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_762_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_762_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_762_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_762_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_762_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_762_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_762_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 763,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      4,
      4,
      6
    ],
    "target": [
      1,
      2,
      4,
      0,
      1,
      2,
      5,
      0,
      1,
      2,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->E\nC->A\nD->B\nD->C\nD->F\nE->A\nE->B\nE->C\nE->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_763.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_763_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_763_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 764,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      0,
      4,
      5,
      2,
      4,
      5,
      2,
      3,
      2,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->E\nC->A\nC->E\nC->F\nD->C\nD->E\nD->F\nE->C\nE->D\nF->C\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_764.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_764_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_764_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 765,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      3,
      5,
      4,
      3,
      0,
      1,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->D\nC->F\nD->E\nE->D\nF->A\nF->B\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_765.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_765_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_765_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 766,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      4,
      5
    ],
    "target": [
      2,
      5,
      1,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nC->B\nE->A\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_766.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_766_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_766_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_766_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_766_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_766_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 767,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      2,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      2,
      0,
      1,
      3,
      4,
      5,
      5,
      3,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nC->A\nC->B\nC->D\nC->E\nC->F\nE->F\nF->D\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_767.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_767_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_767_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 768,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      3,
      6
    ],
    "target": [
      5,
      0,
      2,
      3,
      3,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->C\nB->D\nC->D\nD->F\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_768.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_768_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_768_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_768_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_768_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_768_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_768_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_768_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 769,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      4,
      2,
      1,
      4,
      4,
      5,
      1,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->C\nC->B\nC->E\nD->E\nE->F\nG->B\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_769.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_769_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_769_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 770,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      3,
      1,
      3,
      4,
      5,
      1,
      2,
      1,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nC->B\nC->D\nC->E\nC->F\nD->B\nD->C\nE->B\nE->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_770.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_770_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_770_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 771,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      5,
      2,
      1,
      3,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nD->C\nE->B\nE->D\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_771.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_771_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_771_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_771_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_771_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_771_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_771_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_771_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 772,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      4,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      3,
      3,
      4,
      0,
      2,
      0,
      3,
      4,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->D\nC->D\nC->E\nE->A\nE->C\nF->A\nF->D\nF->E\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_772.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_772_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_772_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 773,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4
    ],
    "target": [
      4,
      0,
      0,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nC->A\nD->A\nD->E\nE->B\n",
    "averaged_attention_matrix_path": "averaged_id_773.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_773_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_773_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_773_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_773_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_773_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 774,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      4,
      4,
      5,
      6
    ],
    "target": [
      4,
      4,
      5,
      5,
      0,
      5,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nB->F\nC->F\nE->A\nE->F\nF->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_774.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_774_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_774_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_774_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_774_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_774_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_774_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_774_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_774_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 775,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      3,
      5,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->F\nC->D\nE->F\nF->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_775.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_775_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_775_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_775_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_775_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_775_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_775_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 776,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3
    ],
    "target": [
      3,
      4,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->E\nC->D\nD->C\n",
    "averaged_attention_matrix_path": "averaged_id_776.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_776_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_776_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_776_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_776_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 777,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      4,
      4,
      5
    ],
    "target": [
      3,
      0,
      4,
      1,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nC->A\nC->E\nE->B\nE->C\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_777.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_777_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_777_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_777_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_777_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_777_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_777_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 778,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      3,
      4,
      1,
      0,
      1,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->D\nB->E\nC->B\nD->A\nE->B\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_778.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_778_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_778_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 779,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      5,
      1,
      5,
      3,
      4,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->B\nC->F\nE->B\nE->F\nF->D\nF->E\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_779.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_779_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_779_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_779_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_779_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_779_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_779_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_779_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_779_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_779_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 780,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      2,
      2,
      5,
      5,
      5,
      6
    ],
    "target": [
      0,
      1,
      3,
      5,
      0,
      1,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->A\nC->B\nC->D\nC->F\nF->A\nF->B\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_780.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_780_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_780_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_780_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_780_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_780_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_780_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_780_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_780_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 781,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      5
    ],
    "target": [
      2,
      0,
      5,
      4,
      2,
      1,
      5,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->F\nC->E\nD->C\nE->B\nE->F\nF->A\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_781.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_781_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_781_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_781_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_781_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_781_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_781_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_781_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_781_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_781_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 782,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      3,
      0,
      1,
      5,
      4,
      5,
      2,
      4,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nC->A\nC->B\nC->F\nD->E\nE->F\nF->C\nF->E\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_782.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_782_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_782_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 783,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      5,
      0,
      0,
      3,
      1,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->A\nC->A\nC->D\nF->B\nG->A\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_783.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_783_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_783_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_783_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_783_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_783_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_783_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_783_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_783_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_783_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 784,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4
    ],
    "target": [
      5,
      0,
      4,
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nC->E\nD->F\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_784.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_784_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_784_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_784_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_784_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_784_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 785,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      2,
      4,
      4,
      2,
      1,
      2,
      0,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->E\nC->E\nD->C\nE->B\nE->C\nF->A\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_785.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_785_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_785_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 786,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      4,
      6
    ],
    "target": [
      0,
      1,
      3,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nC->B\nC->D\nE->F\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_786.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_786_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_786_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_786_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_786_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_786_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 787,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      3,
      1,
      2,
      4,
      5,
      0,
      2,
      3,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nD->B\nD->C\nD->E\nE->F\nF->A\nF->C\nF->D\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_787.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_787_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_787_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 788,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      1,
      1,
      2,
      0,
      2,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->D\nB->F\nC->B\nD->B\nE->C\nF->A\nF->C\nF->E\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_788.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_788_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_788_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 789,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 3,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      4,
      5
    ],
    "target": [
      3,
      0,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->D\nE->A\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_789.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_789_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_789_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_789_2.npy"
    ],
    "num_averaged_samples": 3
  },
  {
    "graph_id": 790,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      0,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nB->E\nB->F\nF->A\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_790.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_790_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_790_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_790_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_790_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_790_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_790_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_790_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 791,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      3,
      4,
      2,
      5,
      2,
      0,
      0,
      1,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->E\nB->C\nC->F\nD->C\nE->A\nF->A\nF->B\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_791.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_791_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_791_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 792,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      1,
      4,
      0,
      1,
      4,
      1,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->E\nC->A\nC->B\nC->E\nD->B\nF->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_792.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_792_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_792_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_792_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_792_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_792_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_792_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_792_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_792_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 793,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      4,
      1,
      3,
      4,
      5,
      4,
      0,
      1,
      0,
      3,
      0,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nC->B\nC->D\nC->E\nC->F\nD->E\nE->A\nE->B\nF->A\nF->D\nG->A\nG->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_793.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_793_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_793_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 794,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      3,
      3,
      5
    ],
    "target": [
      3,
      4,
      0,
      2,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->E\nD->A\nD->C\nD->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_794.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_794_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_794_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_794_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_794_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_794_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_794_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 795,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      2,
      2,
      4,
      6,
      6
    ],
    "target": [
      3,
      0,
      1,
      4,
      5,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nC->A\nC->B\nC->E\nC->F\nE->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_795.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_795_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_795_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_795_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_795_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_795_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_795_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_795_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_795_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 796,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      5,
      2,
      0,
      0,
      1,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->C\nD->A\nE->A\nF->B\nG->C\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_796.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_796_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_796_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_796_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_796_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_796_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_796_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_796_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_796_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_796_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 797,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      5,
      0,
      4,
      2,
      2,
      3,
      5,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->F\nC->A\nC->E\nD->C\nE->C\nE->D\nE->F\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_797.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_797_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_797_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 798,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      4,
      5,
      0,
      4,
      3,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nA->F\nB->E\nB->F\nC->A\nD->E\nE->D\nF->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_798.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_798_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_798_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 799,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      0,
      3,
      4,
      5,
      1,
      2,
      0,
      1,
      2,
      3,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->D\nC->E\nC->F\nD->B\nE->C\nF->A\nF->B\nF->C\nF->D\nG->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_799.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_799_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_799_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 800,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      5,
      0,
      1,
      0,
      2,
      3,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->F\nC->A\nC->B\nF->A\nF->C\nF->D\nG->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_800.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_800_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_800_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_800_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_800_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_800_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_800_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_800_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_800_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_800_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 801,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      4,
      5,
      1,
      5,
      4,
      1,
      3,
      5,
      0,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nA->F\nC->B\nC->F\nD->E\nE->B\nE->D\nE->F\nF->A\nF->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_801.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_801_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_801_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 802,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      2,
      3,
      0,
      4,
      0,
      2,
      5,
      0,
      2,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nA->F\nB->C\nB->D\nC->A\nC->E\nE->A\nE->C\nE->F\nF->A\nF->C\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_802.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_802_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_802_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 803,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      5,
      0,
      0,
      1,
      0,
      4,
      1,
      5,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->A\nC->A\nC->B\nD->A\nD->E\nE->B\nE->F\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_803.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_803_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_803_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 804,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      2,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      4,
      0,
      5,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nB->E\nC->A\nC->F\nF->C\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_804.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_804_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_804_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_804_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_804_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_804_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_804_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_804_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_804_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 805,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      4,
      5,
      6,
      6,
      6,
      6,
      6
    ],
    "target": [
      0,
      5,
      0,
      0,
      0,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->A\nC->F\nE->A\nF->A\nG->A\nG->B\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_805.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_805_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_805_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_805_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_805_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_805_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_805_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_805_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_805_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_805_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 806,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      4,
      2,
      3,
      4,
      0,
      1,
      0,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->D\nB->E\nC->A\nC->B\nD->A\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_806.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_806_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_806_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_806_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_806_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_806_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_806_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_806_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_806_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_806_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 807,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      5
    ],
    "target": [
      2,
      2,
      3,
      5,
      0,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nB->D\nB->F\nC->A\nC->B\nC->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_807.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_807_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_807_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_807_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_807_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_807_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_807_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_807_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_807_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 808,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      0,
      5,
      0,
      4,
      5,
      0,
      1,
      0,
      1,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->A\nB->F\nC->A\nC->E\nC->F\nD->A\nD->B\nE->A\nF->B\nF->D\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_808.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_808_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_808_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 809,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      3,
      5,
      5,
      5,
      6
    ],
    "target": [
      4,
      5,
      2,
      3,
      3,
      1,
      2,
      4,
      0,
      1,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->C\nB->D\nC->D\nD->B\nD->C\nD->E\nF->A\nF->B\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_809.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_809_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_809_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 810,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      5,
      2,
      3,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->F\nD->A\nD->F\nE->C\nF->D\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_810.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_810_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_810_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_810_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_810_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_810_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_810_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_810_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 811,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      4,
      0,
      4,
      5,
      5,
      0,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->E\nC->A\nC->E\nD->F\nE->F\nF->A\nG->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_811.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_811_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_811_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 812,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      5
    ],
    "target": [
      1,
      3,
      5,
      2,
      1,
      2,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nC->D\nC->F\nD->C\nE->B\nE->C\nF->A\nF->C\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_812.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_812_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_812_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_812_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_812_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_812_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_812_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_812_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_812_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_812_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 813,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      0,
      1,
      0,
      4,
      5,
      3,
      1,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->F\nC->A\nC->B\nD->A\nD->E\nD->F\nE->D\nF->B\nF->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_813.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_813_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_813_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 814,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      4,
      5,
      4,
      5,
      3,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nB->F\nD->E\nD->F\nE->D\nE->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_814.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_814_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_814_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_814_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_814_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_814_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_814_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_814_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 815,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      4,
      5,
      0,
      2,
      3,
      1,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nA->E\nA->F\nC->A\nD->C\nE->D\nF->B\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_815.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_815_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_815_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_815_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_815_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_815_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_815_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_815_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_815_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_815_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 816,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      1,
      4,
      1,
      4,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nC->B\nD->E\nE->B\nF->E\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_816.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_816_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_816_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_816_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_816_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_816_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_816_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_816_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 817,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      4,
      0,
      1,
      0,
      0,
      0,
      2,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->E\nC->A\nC->B\nD->A\nE->A\nF->A\nF->C\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_817.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_817_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_817_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 818,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      4,
      5,
      0,
      0,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nB->E\nC->E\nD->F\nE->A\nF->A\nF->B\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_818.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_818_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_818_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_818_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_818_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_818_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_818_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_818_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_818_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_818_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 819,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      3,
      3,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      5,
      0,
      4,
      1,
      2,
      5,
      0,
      2,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nC->A\nC->E\nD->B\nD->C\nD->F\nF->A\nF->C\nF->E\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_819.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_819_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_819_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 820,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      3,
      5,
      6
    ],
    "target": [
      0,
      2,
      1,
      4,
      5,
      1,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nD->B\nD->E\nD->F\nF->B\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_820.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_820_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_820_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_820_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_820_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_820_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_820_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_820_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 821,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      4,
      4,
      4,
      0,
      2,
      5,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nC->E\nD->A\nD->C\nD->F\nE->B\nE->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_821.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_821_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_821_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_821_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_821_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_821_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_821_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_821_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_821_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_821_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 822,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      3,
      5,
      0,
      5,
      0,
      0,
      2,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nB->F\nC->A\nC->F\nD->A\nE->A\nE->C\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_822.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_822_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_822_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 823,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      4,
      1,
      3,
      5,
      1,
      5,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->E\nC->B\nC->D\nD->F\nE->B\nE->F\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_823.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_823_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_823_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 824,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      6
    ],
    "target": [
      1,
      5,
      3,
      5,
      4,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->D\nC->F\nD->E\nE->D\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_824.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_824_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_824_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_824_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_824_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_824_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_824_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_824_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 825,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      6
    ],
    "target": [
      2,
      0,
      5,
      1,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nC->A\nC->F\nD->B\nE->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_825.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_825_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_825_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_825_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_825_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_825_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_825_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 826,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      2,
      2,
      3,
      3,
      3,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      4,
      5,
      0,
      2,
      5,
      0,
      1,
      3,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->A\nC->E\nC->F\nD->A\nD->C\nD->F\nF->A\nF->B\nF->D\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_826.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_826_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_826_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 827,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      5,
      5,
      6
    ],
    "target": [
      3,
      5,
      1,
      0,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->D\nB->F\nD->B\nF->A\nF->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_827.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_827_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_827_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_827_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_827_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_827_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_827_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 828,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      5,
      0,
      1,
      2,
      2,
      3,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->F\nD->A\nD->B\nD->C\nE->C\nE->D\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_828.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_828_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_828_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_828_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_828_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_828_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_828_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_828_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_828_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 829,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      4,
      5
    ],
    "target": [
      4,
      0,
      3,
      5,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nC->A\nC->D\nD->F\nE->D\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_829.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_829_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_829_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_829_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_829_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_829_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_829_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 830,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      3,
      4,
      5,
      1,
      2,
      5,
      1,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->A\nC->D\nC->E\nD->F\nE->B\nE->C\nE->F\nF->B\nG->B\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_830.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_830_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_830_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 831,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      3,
      4,
      4,
      5
    ],
    "target": [
      1,
      5,
      1,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nD->B\nE->A\nE->B\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_831.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_831_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_831_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_831_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_831_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_831_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_831_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 832,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      3,
      0,
      2,
      0,
      1,
      2,
      3,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nC->A\nC->D\nD->A\nD->C\nE->A\nF->B\nF->C\nF->D\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_832.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_832_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_832_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 833,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      4
    ],
    "target": [
      1,
      3,
      0,
      5,
      0,
      5,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nC->A\nC->F\nD->A\nD->F\nE->B\nE->C\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_833.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_833_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_833_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_833_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_833_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_833_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_833_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_833_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_833_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_833_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 834,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      4,
      5,
      1,
      2,
      0,
      2,
      3,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->A\nB->E\nC->F\nD->B\nD->C\nE->A\nE->C\nE->D\nF->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_834.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_834_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_834_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 835,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      5,
      0,
      1,
      4,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nD->F\nE->A\nE->B\nF->E\nG->A\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_835.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_835_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_835_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_835_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_835_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_835_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_835_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_835_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_835_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 836,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      4,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      1,
      3,
      0,
      1,
      4,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nC->E\nC->F\nE->B\nE->D\nF->A\nF->B\nF->E\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_836.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_836_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_836_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 837,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      5
    ],
    "target": [
      2,
      5,
      4,
      3,
      5,
      5,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->E\nC->D\nD->F\nE->F\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_837.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_837_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_837_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_837_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_837_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_837_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_837_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_837_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 838,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      4,
      4,
      5,
      5
    ],
    "target": [
      2,
      3,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "E->C\nE->D\nF->B\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_838.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_838_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_838_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_838_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_838_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 839,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      0,
      4,
      5,
      0,
      3,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nC->E\nC->F\nD->A\nE->D\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_839.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_839_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_839_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_839_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_839_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_839_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_839_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_839_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 840,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      5,
      5,
      5
    ],
    "target": [
      1,
      2,
      3,
      4,
      5,
      3,
      5,
      2,
      4,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nB->C\nB->D\nB->E\nB->F\nC->D\nC->F\nD->C\nD->E\nF->B\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_840.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_840_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_840_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 841,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      0,
      4,
      1,
      3,
      5,
      0,
      1,
      3,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->A\nB->E\nC->B\nC->D\nC->F\nD->A\nE->B\nF->D\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_841.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_841_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_841_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 842,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      2,
      3,
      5,
      0,
      0,
      1,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nC->D\nC->F\nD->A\nF->A\nF->B\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_842.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_842_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_842_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_842_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_842_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_842_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_842_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_842_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_842_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_842_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 843,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      5,
      5
    ],
    "target": [
      2,
      5,
      2,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nC->F\nD->C\nF->C\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_843.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_843_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_843_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_843_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_843_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_843_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 844,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      2,
      3,
      2,
      0,
      3,
      4,
      2,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->C\nC->A\nC->D\nC->E\nD->C\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_844.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_844_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_844_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_844_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_844_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_844_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_844_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_844_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_844_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_844_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 845,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      5,
      3,
      0,
      5,
      0,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->F\nC->D\nD->A\nD->F\nE->A\nF->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_845.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_845_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_845_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_845_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_845_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_845_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_845_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_845_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_845_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_845_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 846,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      4,
      5,
      0,
      3,
      5,
      0,
      3,
      1,
      0,
      1,
      2,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->E\nA->F\nB->A\nB->D\nB->F\nC->A\nC->D\nD->B\nE->A\nE->B\nE->C\nF->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_846.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_846_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_846_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 847,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      4,
      5,
      0,
      0,
      4,
      0,
      4,
      5,
      1,
      5,
      0,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->A\nC->A\nC->E\nD->A\nD->E\nD->F\nE->B\nE->F\nF->A\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_847.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_847_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_847_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 848,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      4,
      4,
      4,
      5,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      2,
      3,
      1,
      2,
      5,
      0,
      1,
      3,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nB->D\nE->B\nE->C\nE->F\nF->A\nF->B\nF->D\nF->E\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_848.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_848_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_848_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 849,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      2,
      1,
      3,
      0,
      4,
      0,
      5,
      3,
      4,
      0,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nC->B\nC->D\nD->A\nD->E\nE->A\nE->F\nF->D\nF->E\nG->A\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_849.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_849_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_849_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 850,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      5,
      5
    ],
    "target": [
      1,
      4,
      3,
      0,
      1,
      4,
      0,
      1,
      2,
      4,
      2,
      5,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->D\nC->A\nC->B\nC->E\nD->A\nD->B\nD->C\nD->E\nE->C\nE->F\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_850.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_850_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_850_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 851,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      5
    ],
    "target": [
      4,
      5,
      2,
      3,
      0,
      2,
      5,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->C\nC->D\nD->A\nD->C\nD->F\nE->C\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_851.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_851_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_851_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_851_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_851_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_851_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_851_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_851_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_851_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_851_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 852,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      3,
      0,
      0,
      1,
      4,
      5,
      0,
      0,
      2,
      1,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->A\nC->A\nC->B\nC->E\nC->F\nD->A\nE->A\nE->C\nF->B\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_852.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_852_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_852_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 853,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      2,
      4,
      5,
      0,
      5,
      3,
      0,
      3,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nB->E\nB->F\nC->A\nC->F\nE->D\nF->A\nF->D\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_853.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_853_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_853_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 854,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      0,
      3,
      1,
      5,
      0,
      1,
      3,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nC->A\nC->D\nD->B\nD->F\nE->A\nF->B\nF->D\nG->A\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_854.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_854_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_854_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 855,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      3,
      5,
      4,
      1,
      3,
      0,
      2,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->E\nC->B\nE->D\nF->A\nF->C\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_855.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_855_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_855_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_855_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_855_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_855_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_855_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_855_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_855_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_855_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 856,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      3,
      5,
      1,
      2,
      5,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nC->F\nD->B\nD->C\nE->F\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_856.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_856_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_856_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_856_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_856_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_856_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_856_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_856_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_856_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 857,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      2,
      3,
      4,
      0,
      4,
      2,
      2,
      2,
      4,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nB->C\nB->D\nB->E\nC->A\nC->E\nD->C\nE->C\nF->C\nF->E\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_857.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_857_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_857_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 858,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      3,
      4,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nE->A\nE->D\nF->E\nG->A\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_858.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_858_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_858_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_858_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_858_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_858_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_858_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_858_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_858_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 859,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      3,
      5,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      5,
      0,
      4,
      5,
      0,
      2,
      3,
      4,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nC->F\nD->A\nD->E\nD->F\nF->A\nF->C\nF->D\nF->E\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_859.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_859_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_859_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 860,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      5,
      6
    ],
    "target": [
      2,
      2,
      0,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nD->A\nF->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_860.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_860_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_860_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_860_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_860_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_860_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 861,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      4,
      0,
      5,
      0,
      4,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->E\nC->E\nD->A\nD->F\nE->A\nF->E\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_861.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_861_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_861_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_861_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_861_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_861_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_861_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_861_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_861_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 862,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      2,
      3,
      5,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->C\nB->D\nC->F\nF->E\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_862.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_862_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_862_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_862_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_862_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_862_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_862_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_862_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_862_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 863,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      0,
      5,
      3,
      1,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nC->A\nC->F\nE->D\nF->B\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_863.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_863_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_863_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_863_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_863_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_863_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_863_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_863_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_863_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 864,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      4,
      4,
      1,
      2,
      0,
      3,
      4,
      0,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nB->F\nC->E\nD->E\nE->B\nE->C\nF->A\nF->D\nF->E\nG->A\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_864.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_864_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_864_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 865,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4
    ],
    "target": [
      3,
      5,
      5,
      0,
      5,
      0,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->F\nC->A\nC->F\nD->A\nD->C\nE->C\n",
    "averaged_attention_matrix_path": "averaged_id_865.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_865_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_865_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_865_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_865_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_865_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_865_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_865_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_865_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 866,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      6
    ],
    "target": [
      3,
      5,
      1,
      3,
      5,
      0,
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->D\nB->F\nC->B\nC->D\nC->F\nD->A\nD->F\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_866.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_866_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_866_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_866_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_866_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_866_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_866_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_866_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_866_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 867,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      5,
      5,
      0,
      2,
      1,
      1,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nC->F\nD->A\nD->C\nE->B\nF->B\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_867.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_867_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_867_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 868,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      3,
      4,
      6,
      6,
      6
    ],
    "target": [
      4,
      0,
      0,
      1,
      2,
      2,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nC->A\nD->A\nD->B\nD->C\nE->C\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_868.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_868_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_868_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_868_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_868_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_868_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_868_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_868_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_868_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_868_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 869,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      0,
      2,
      0,
      3,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nC->A\nD->C\nF->A\nF->D\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_869.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_869_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_869_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_869_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_869_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_869_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_869_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_869_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 870,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      3,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      5,
      3,
      3,
      5,
      4,
      0,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nA->F\nB->D\nC->D\nC->F\nD->E\nF->A\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_870.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_870_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_870_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 871,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 16,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      3,
      4,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      0,
      2,
      5,
      0,
      3,
      4,
      1,
      2,
      5,
      2,
      0,
      4,
      1,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->F\nC->A\nC->D\nC->E\nD->B\nD->C\nD->F\nE->C\nF->A\nF->E\nG->B\nG->C\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_871.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_871_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_871_15.npy"
    ],
    "num_averaged_samples": 16
  },
  {
    "graph_id": 872,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      3,
      3,
      4,
      4,
      5,
      5
    ],
    "target": [
      1,
      5,
      0,
      1,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "D->B\nD->F\nE->A\nE->B\nF->C\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_872.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_872_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_872_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_872_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_872_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_872_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_872_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 873,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      1,
      1,
      3,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      5,
      0,
      2,
      4,
      2,
      1,
      3,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->F\nB->A\nB->C\nB->E\nD->C\nF->B\nF->D\nG->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_873.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_873_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_873_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 874,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      1,
      4,
      5,
      0,
      1,
      2,
      4,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nC->B\nC->E\nC->F\nD->A\nF->B\nF->C\nF->E\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_874.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_874_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_874_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 875,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      3,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      3,
      4,
      3,
      4,
      5,
      5,
      3,
      5,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nB->D\nB->E\nB->F\nD->F\nE->D\nE->F\nG->A\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_875.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_875_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_875_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 876,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      3,
      6
    ],
    "target": [
      5,
      5,
      0,
      3,
      1,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->F\nB->F\nC->A\nC->D\nD->B\nD->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_876.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_876_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_876_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_876_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_876_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_876_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_876_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_876_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 877,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      4,
      4,
      4,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      2,
      3,
      5,
      1,
      0,
      2,
      5,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->C\nB->D\nB->F\nC->B\nE->A\nE->C\nE->F\nG->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_877.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_877_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_877_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 878,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      5,
      5,
      6
    ],
    "target": [
      3,
      3,
      0,
      2,
      1,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nC->D\nD->A\nD->C\nF->B\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_878.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_878_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_878_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_878_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_878_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_878_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_878_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_878_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 879,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      4,
      0,
      1,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->E\nF->A\nF->B\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_879.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_879_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_879_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_879_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_879_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_879_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_879_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 880,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      3,
      4,
      2,
      0,
      3,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nC->A\nC->D\nC->E\nD->C\nE->A\nE->D\nF->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_880.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_880_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_880_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_880_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_880_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_880_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_880_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_880_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_880_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_880_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 881,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      4,
      4,
      4,
      5
    ],
    "target": [
      4,
      1,
      1,
      2,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nC->B\nE->B\nE->C\nE->D\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_881.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_881_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_881_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_881_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_881_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_881_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_881_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 882,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      3,
      4,
      4,
      6
    ],
    "target": [
      1,
      1,
      5,
      1,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "C->B\nD->B\nD->F\nE->B\nE->F\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_882.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_882_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_882_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_882_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_882_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_882_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_882_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 883,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      3,
      4
    ],
    "target": [
      1,
      5,
      3,
      5,
      0,
      1,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->D\nC->F\nD->A\nD->B\nE->B\n",
    "averaged_attention_matrix_path": "averaged_id_883.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_883_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_883_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_883_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_883_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_883_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_883_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_883_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 884,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      3,
      4,
      6
    ],
    "target": [
      0,
      3,
      5,
      4,
      1,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nB->F\nC->E\nD->B\nE->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_884.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_884_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_884_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_884_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_884_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_884_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_884_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_884_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 885,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      5,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      4,
      0,
      4,
      5,
      1,
      5,
      0,
      1,
      2,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nC->A\nC->E\nC->F\nD->B\nE->F\nF->A\nF->B\nF->C\nG->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_885.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_885_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_885_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 886,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      3,
      4,
      5,
      6
    ],
    "target": [
      2,
      3,
      0,
      5,
      1,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nC->A\nC->F\nD->B\nE->A\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_886.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_886_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_886_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_886_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_886_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_886_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_886_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_886_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_886_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 887,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      1,
      3,
      3,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nC->E\nD->B\nE->D\nF->D\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_887.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_887_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_887_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_887_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_887_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_887_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_887_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_887_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 888,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      3,
      4,
      4,
      5
    ],
    "target": [
      2,
      3,
      4,
      5,
      2,
      3,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->E\nC->F\nD->C\nE->D\nE->F\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_888.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_888_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_888_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_888_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_888_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_888_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_888_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_888_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_888_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 889,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      4,
      6,
      6
    ],
    "target": [
      5,
      0,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nE->A\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_889.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_889_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_889_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_889_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_889_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 890,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      4,
      5,
      1,
      4,
      5,
      0,
      2,
      1,
      2,
      2,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->E\nB->F\nC->B\nC->E\nC->F\nD->A\nD->C\nE->B\nE->C\nF->C\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_890.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_890_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_890_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 891,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      3,
      1,
      5,
      2,
      2,
      5,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nC->B\nC->F\nD->C\nE->C\nE->F\nF->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_891.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_891_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_891_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_891_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_891_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_891_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_891_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_891_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_891_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_891_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 892,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      5,
      2,
      3,
      0,
      4,
      0,
      3,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nB->C\nC->D\nD->A\nD->E\nE->A\nF->D\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_892.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_892_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_892_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_892_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_892_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_892_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_892_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_892_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_892_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_892_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 893,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      1,
      5,
      0,
      1,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nD->B\nE->F\nF->A\nF->B\nF->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_893.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_893_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_893_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_893_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_893_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_893_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_893_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_893_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_893_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_893_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 894,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      5,
      6
    ],
    "target": [
      4,
      5,
      3,
      3,
      5,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nB->D\nC->D\nE->F\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_894.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_894_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_894_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_894_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_894_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_894_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_894_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_894_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 895,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      5,
      4,
      1,
      2,
      3,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->F\nD->E\nE->B\nE->C\nF->D\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_895.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_895_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_895_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_895_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_895_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_895_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_895_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_895_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_895_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 896,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      5,
      0,
      2,
      1,
      4,
      5,
      1,
      3,
      2,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->A\nB->C\nC->B\nD->E\nD->F\nE->B\nE->D\nF->C\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_896.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_896_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_896_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 897,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      4
    ],
    "target": [
      5,
      3,
      4,
      1,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->F\nC->D\nC->E\nD->B\nE->B\nE->D\n",
    "averaged_attention_matrix_path": "averaged_id_897.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_897_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_897_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_897_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_897_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_897_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_897_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 898,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      5,
      5,
      6
    ],
    "target": [
      2,
      4,
      1,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nF->B\nF->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_898.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_898_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_898_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_898_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_898_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_898_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 899,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      2,
      4,
      5,
      3,
      1,
      0,
      1,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->C\nB->E\nB->F\nC->D\nD->B\nE->A\nF->B\nG->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_899.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_899_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_899_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 900,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      5,
      0,
      3,
      0,
      0,
      1,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->F\nC->A\nC->D\nD->A\nE->A\nF->B\nF->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_900.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_900_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_900_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_900_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_900_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_900_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_900_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_900_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_900_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_900_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 901,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      2,
      3,
      3,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      1,
      3,
      1,
      4,
      3,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nC->A\nC->B\nC->D\nD->B\nD->E\nE->D\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_901.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_901_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_901_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_901_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_901_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_901_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_901_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_901_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_901_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_901_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 902,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      2,
      0,
      0,
      2,
      4,
      5,
      2,
      3,
      0,
      2,
      4,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nC->A\nD->A\nD->C\nD->E\nD->F\nE->C\nE->D\nF->A\nF->C\nF->E\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_902.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_902_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_902_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 903,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      4,
      5
    ],
    "target": [
      3,
      4,
      5,
      0,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nC->F\nD->A\nE->C\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_903.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_903_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_903_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_903_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_903_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_903_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_903_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 904,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      5,
      3,
      5,
      1,
      5,
      0,
      4,
      0,
      5,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nB->F\nC->B\nC->F\nD->A\nD->E\nE->A\nE->F\nF->B\n",
    "averaged_attention_matrix_path": "averaged_id_904.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_904_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_904_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 905,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      4,
      4,
      5
    ],
    "target": [
      4,
      4,
      2,
      1,
      2,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nD->C\nE->B\nE->C\nE->D\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_905.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_905_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_905_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_905_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_905_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_905_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_905_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_905_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 906,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      4,
      2,
      3,
      0,
      1,
      4,
      2,
      2,
      5,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->C\nB->D\nC->A\nC->B\nC->E\nD->C\nE->C\nE->F\nF->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_906.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_906_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_906_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 907,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      2,
      4,
      0,
      1,
      4,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->C\nB->E\nD->A\nE->B\nF->E\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_907.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_907_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_907_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_907_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_907_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_907_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_907_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_907_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_907_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_907_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 908,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      5,
      0,
      0,
      2,
      3,
      5,
      3,
      4,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->F\nC->A\nD->A\nD->C\nE->D\nE->F\nF->D\nF->E\nG->A\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_908.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_908_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_908_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 909,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      2,
      4,
      5
    ],
    "target": [
      1,
      2,
      3,
      5,
      0,
      4,
      0,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nA->F\nB->A\nB->E\nC->A\nE->F\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_909.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_909_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_909_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_909_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_909_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_909_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_909_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_909_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_909_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_909_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 910,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      5,
      5,
      6
    ],
    "target": [
      0,
      3,
      0,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nF->A\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_910.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_910_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_910_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_910_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_910_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_910_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 911,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      5,
      2,
      3,
      4,
      5,
      2,
      0,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->C\nC->D\nC->E\nC->F\nD->C\nE->A\nE->D\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_911.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_911_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_911_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 912,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      4,
      4,
      5
    ],
    "target": [
      3,
      5,
      5,
      1,
      3,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->F\nC->B\nC->D\nE->C\nE->D\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_912.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_912_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_912_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_912_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_912_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_912_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_912_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_912_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_912_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 913,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3,
      4,
      4,
      4,
      5,
      5,
      5,
      6
    ],
    "target": [
      1,
      5,
      1,
      2,
      1,
      2,
      5,
      1,
      2,
      4,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nC->F\nD->B\nD->C\nE->B\nE->C\nE->F\nF->B\nF->C\nF->E\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_913.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_913_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_913_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 914,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 19,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      2,
      3,
      3,
      4,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      4,
      0,
      3,
      4,
      0,
      1,
      3,
      5,
      0,
      1,
      5,
      3,
      2,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nA->E\nB->A\nB->D\nB->E\nC->A\nC->B\nC->D\nC->F\nD->A\nD->B\nE->F\nF->D\nG->C\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_914.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_914_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_15.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_16.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_17.npy",
      "attention_matrices/no_args_7_1b/avg_attn_914_18.npy"
    ],
    "num_averaged_samples": 19
  },
  {
    "graph_id": 915,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      0,
      3,
      4,
      0,
      1,
      4,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nB->E\nC->A\nC->B\nD->E\nF->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_915.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_915_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_915_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_915_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_915_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_915_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_915_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_915_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_915_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 916,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      0,
      4,
      5,
      0,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nC->A\nC->E\nC->F\nF->A\nF->B\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_916.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_916_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_916_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_916_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_916_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_916_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_916_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_916_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_916_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 917,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      5,
      6
    ],
    "target": [
      2,
      2,
      5,
      4,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nB->F\nC->E\nF->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_917.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_917_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_917_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_917_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_917_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_917_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_917_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 918,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      1,
      2,
      2,
      3,
      3,
      3,
      5,
      6
    ],
    "target": [
      3,
      5,
      0,
      2,
      4,
      5,
      3,
      4,
      1,
      2,
      4,
      1,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nB->C\nB->E\nB->F\nC->D\nC->E\nD->B\nD->C\nD->E\nF->B\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_918.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_918_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_918_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 919,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 14,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      4,
      0,
      1,
      4,
      0,
      5,
      0,
      1,
      2,
      5,
      0,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nC->A\nC->B\nC->E\nD->A\nD->F\nE->A\nE->B\nE->C\nE->F\nF->A\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_919.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_919_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_919_13.npy"
    ],
    "num_averaged_samples": 14
  },
  {
    "graph_id": 920,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      2,
      2,
      3,
      3,
      3,
      4,
      5
    ],
    "target": [
      1,
      3,
      4,
      0,
      3,
      4,
      0,
      1,
      4,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->E\nC->A\nC->D\nC->E\nD->A\nD->B\nD->E\nE->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_920.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_920_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_920_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 921,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      0,
      1,
      0,
      5,
      1,
      5,
      0,
      2,
      4,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->A\nC->A\nC->B\nD->A\nD->F\nE->B\nE->F\nF->A\nF->C\nF->E\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_921.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_921_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_921_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 922,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4
    ],
    "target": [
      1,
      3,
      5,
      1,
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nB->F\nC->B\nD->F\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_922.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_922_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_922_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_922_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_922_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_922_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_922_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 923,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      3,
      3,
      4,
      4,
      4,
      5
    ],
    "target": [
      1,
      3,
      5,
      4,
      4,
      5,
      0,
      1,
      5,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->F\nB->E\nD->E\nD->F\nE->A\nE->B\nE->F\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_923.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_923_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_923_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 924,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      4,
      4,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      5,
      2,
      4,
      0,
      2,
      5,
      1,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nB->C\nC->E\nE->A\nE->C\nE->F\nF->B\nF->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_924.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_924_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_924_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 925,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 16,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      4,
      4,
      4,
      4,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      2,
      4,
      5,
      0,
      3,
      5,
      0,
      1,
      3,
      5,
      0,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->E\nB->F\nC->A\nC->D\nC->F\nE->A\nE->B\nE->D\nE->F\nF->A\nF->B\nF->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_925.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_925_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_925_15.npy"
    ],
    "num_averaged_samples": 16
  },
  {
    "graph_id": 926,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      4,
      6,
      6
    ],
    "target": [
      1,
      3,
      5,
      1,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->F\nC->B\nE->C\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_926.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_926_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_926_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_926_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_926_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_926_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_926_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_926_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 927,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      2,
      5,
      4,
      2,
      3,
      2,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nC->F\nD->E\nE->C\nE->D\nF->C\nF->D\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_927.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_927_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_927_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_927_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_927_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_927_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_927_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_927_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_927_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_927_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 928,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      5,
      4,
      5,
      4,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->F\nD->E\nE->F\nF->E\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_928.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_928_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_928_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_928_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_928_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_928_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_928_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_928_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 929,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      4,
      4,
      6
    ],
    "target": [
      4,
      2,
      3,
      3,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nB->D\nC->D\nE->C\nE->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_929.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_929_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_929_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_929_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_929_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_929_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_929_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_929_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 930,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      3,
      1,
      3,
      0,
      2,
      0,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->D\nC->B\nC->D\nD->A\nE->C\nF->A\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_930.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_930_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_930_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 931,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 16,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      2,
      2,
      3,
      3,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      1,
      4,
      0,
      2,
      5,
      1,
      4,
      5,
      0,
      1,
      2,
      4,
      1,
      5,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nB->C\nB->F\nC->B\nC->E\nC->F\nD->A\nD->B\nD->C\nD->E\nE->B\nE->F\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_931.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_931_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_931_15.npy"
    ],
    "num_averaged_samples": 16
  },
  {
    "graph_id": 932,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      3,
      5,
      3,
      5,
      0,
      1,
      0,
      2,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nB->F\nC->D\nC->F\nD->A\nD->B\nE->A\nE->C\nF->E\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_932.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_932_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_932_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 933,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      4,
      0,
      3,
      0,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nC->A\nC->D\nD->A\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_933.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_933_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_933_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_933_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_933_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_933_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_933_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 934,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      4,
      4,
      5,
      5
    ],
    "target": [
      1,
      3,
      1,
      1,
      3,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nD->B\nE->B\nE->D\nF->A\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_934.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_934_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_934_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_934_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_934_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_934_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_934_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_934_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 935,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      0,
      2,
      5,
      4,
      0,
      4,
      1,
      3,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nB->A\nB->C\nB->F\nC->E\nD->A\nD->E\nE->B\nF->D\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_935.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_935_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_935_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 936,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      3,
      3,
      4,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      0,
      3,
      5,
      1,
      4,
      3,
      0,
      1,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nB->D\nB->F\nD->B\nD->E\nE->D\nF->A\nF->B\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_936.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_936_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_936_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 937,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      4,
      5,
      6
    ],
    "target": [
      3,
      2,
      4,
      0,
      4,
      4,
      0,
      1,
      5,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nB->C\nB->E\nC->A\nC->E\nD->E\nE->A\nE->B\nE->F\nF->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_937.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_937_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_937_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 938,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      0,
      4,
      3,
      2,
      5,
      2,
      1,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->A\nB->E\nC->D\nD->C\nD->F\nE->C\nF->B\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_938.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_938_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_938_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 939,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      4,
      5
    ],
    "target": [
      5,
      3,
      3,
      4,
      5,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->F\nB->D\nC->D\nC->E\nC->F\nE->D\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_939.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_939_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_939_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_939_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_939_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_939_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_939_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_939_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 940,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      2,
      4,
      4,
      2,
      3,
      4,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nC->E\nD->E\nF->C\nF->D\nF->E\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_940.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_940_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_940_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_940_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_940_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_940_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_940_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_940_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_940_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 941,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      0,
      3,
      1,
      5,
      1,
      3,
      0,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->D\nC->B\nD->F\nE->B\nE->D\nF->A\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_941.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_941_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_941_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_941_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_941_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_941_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_941_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_941_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_941_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_941_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 942,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      3,
      5,
      1,
      2,
      1,
      1,
      2,
      1,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nC->F\nD->B\nD->C\nE->B\nF->B\nF->C\nG->B\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_942.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_942_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_942_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 943,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      4,
      4,
      4,
      5,
      5,
      5
    ],
    "target": [
      4,
      2,
      0,
      0,
      5,
      0,
      2,
      3,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nC->A\nD->A\nD->F\nE->A\nE->C\nE->D\nF->A\nF->C\nF->E\n",
    "averaged_attention_matrix_path": "averaged_id_943.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_943_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_943_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 944,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      5,
      2,
      5,
      0,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nB->F\nD->C\nD->F\nE->A\nE->B\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_944.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_944_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_944_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_944_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_944_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_944_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_944_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_944_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_944_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 945,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      3,
      3,
      4,
      1,
      1,
      2,
      0,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nA->D\nB->D\nC->D\nC->E\nD->B\nE->B\nF->C\nG->A\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_945.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_945_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_945_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 946,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      1,
      2,
      3,
      6,
      6
    ],
    "target": [
      3,
      5,
      0,
      2,
      4,
      1,
      0,
      0,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nB->C\nB->E\nC->B\nD->A\nG->A\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_946.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_946_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_946_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_946_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_946_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_946_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_946_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_946_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_946_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_946_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 947,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      3,
      5,
      5,
      5,
      6
    ],
    "target": [
      4,
      2,
      1,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->E\nD->C\nF->B\nF->D\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_947.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_947_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_947_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_947_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_947_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_947_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_947_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 948,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      4,
      2,
      0,
      1,
      4,
      0,
      1,
      2,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->E\nB->C\nC->A\nC->B\nC->E\nE->A\nE->B\nF->C\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_948.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_948_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_948_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 949,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6
    ],
    "target": [
      2,
      0,
      4,
      5,
      4,
      5,
      2,
      3,
      0,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->C\nB->A\nB->E\nB->F\nC->E\nC->F\nD->C\nE->D\nF->A\nF->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_949.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_949_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_949_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 950,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 15,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      2,
      2,
      3,
      3,
      4,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      1,
      3,
      4,
      5,
      4,
      0,
      1,
      1,
      4,
      1,
      2,
      5,
      0,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nA->E\nA->F\nB->E\nC->A\nC->B\nD->B\nD->E\nE->B\nE->C\nE->F\nF->A\nF->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_950.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_950_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_950_14.npy"
    ],
    "num_averaged_samples": 15
  },
  {
    "graph_id": 951,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      2,
      3,
      6
    ],
    "target": [
      4,
      5,
      3,
      4,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nC->D\nC->E\nD->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_951.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_951_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_951_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_951_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_951_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_951_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_951_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 952,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      2,
      4,
      4,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      5,
      0,
      3,
      5,
      1,
      2,
      1,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->A\nC->F\nE->A\nE->D\nE->F\nF->B\nF->C\nG->B\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_952.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_952_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_952_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 953,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      4,
      5,
      6
    ],
    "target": [
      4,
      3,
      3,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->E\nE->D\nF->D\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_953.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_953_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_953_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_953_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_953_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 954,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      1,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      0,
      2,
      4,
      5,
      4,
      5,
      0,
      1,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->E\nB->F\nD->E\nD->F\nE->A\nE->B\nF->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_954.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_954_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_954_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 955,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      1,
      2,
      2,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      3,
      4,
      5,
      4,
      0,
      4,
      5,
      1,
      4,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->D\nA->E\nA->F\nB->E\nC->A\nC->E\nC->F\nE->B\nF->E\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_955.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_955_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_955_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 956,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 17,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      3,
      4,
      5,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      1,
      2,
      3,
      5,
      0,
      5,
      1,
      5,
      0,
      1,
      0,
      1,
      2,
      3,
      4,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->D\nA->F\nB->A\nB->F\nC->B\nC->F\nD->A\nD->B\nE->A\nF->B\nF->C\nF->D\nF->E\nG->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_956.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_956_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_12.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_13.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_14.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_15.npy",
      "attention_matrices/no_args_7_1b/avg_attn_956_16.npy"
    ],
    "num_averaged_samples": 17
  },
  {
    "graph_id": 957,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 3,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      2,
      3,
      6
    ],
    "target": [
      0,
      0,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "C->A\nD->A\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_957.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_957_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_957_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_957_2.npy"
    ],
    "num_averaged_samples": 3
  },
  {
    "graph_id": 958,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      2,
      3,
      4,
      5
    ],
    "target": [
      4,
      4,
      5,
      1,
      0,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nB->F\nC->B\nD->A\nE->D\nF->A\n",
    "averaged_attention_matrix_path": "averaged_id_958.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_958_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_958_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_958_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_958_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_958_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_958_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_958_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 959,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 3,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2
    ],
    "target": [
      1,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nB->D\nC->B\n",
    "averaged_attention_matrix_path": "averaged_id_959.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_959_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_959_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_959_2.npy"
    ],
    "num_averaged_samples": 3
  },
  {
    "graph_id": 960,
    "max_nodes": 7,
    "num_nodes": 3,
    "num_edges": 3,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1
    ],
    "target": [
      1,
      4,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->E\n",
    "averaged_attention_matrix_path": "averaged_id_960.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_960_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_960_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_960_2.npy"
    ],
    "num_averaged_samples": 3
  },
  {
    "graph_id": 961,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      2,
      4,
      5,
      6,
      6
    ],
    "target": [
      2,
      3,
      4,
      0,
      2,
      0,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->C\nB->D\nB->E\nC->A\nE->C\nF->A\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_961.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_961_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_961_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_961_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_961_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_961_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_961_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_961_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_961_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 962,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        1,
        0
      ]
    ],
    "source": [
      1,
      1,
      1,
      1,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      0,
      2,
      4,
      5,
      2,
      0,
      3,
      2,
      3,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "B->A\nB->C\nB->E\nB->F\nD->C\nE->A\nE->D\nF->C\nG->D\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_962.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_962_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_962_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 963,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 6,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      5,
      6,
      6
    ],
    "target": [
      3,
      3,
      5,
      4,
      0,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->D\nB->D\nB->F\nF->E\nG->A\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_963.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_963_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_963_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_963_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_963_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_963_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_963_5.npy"
    ],
    "num_averaged_samples": 6
  },
  {
    "graph_id": 964,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3
    ],
    "target": [
      2,
      4,
      0,
      5,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nB->E\nC->A\nC->F\nD->A\n",
    "averaged_attention_matrix_path": "averaged_id_964.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_964_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_964_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_964_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_964_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_964_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 965,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      4,
      0,
      2,
      4,
      0,
      1,
      5,
      1,
      5,
      3,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nB->C\nB->E\nC->A\nD->B\nD->F\nE->B\nE->F\nF->D\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_965.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_965_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_965_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 966,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      2,
      2,
      3,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      0,
      1,
      3,
      5,
      2,
      5,
      0,
      2,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->A\nC->B\nC->D\nC->F\nD->C\nD->F\nF->A\nF->C\nG->B\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_966.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_966_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_966_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 967,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        1,
        1,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      2,
      3,
      4,
      4,
      5,
      5,
      5,
      5,
      5,
      6
    ],
    "target": [
      1,
      2,
      4,
      5,
      1,
      1,
      3,
      0,
      1,
      2,
      3,
      4,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->B\nA->C\nA->E\nC->F\nD->B\nE->B\nE->D\nF->A\nF->B\nF->C\nF->D\nF->E\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_967.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_967_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_967_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 968,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 5,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      6,
      6
    ],
    "target": [
      2,
      4,
      4,
      1,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nD->E\nG->B\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_968.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_968_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_968_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_968_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_968_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_968_4.npy"
    ],
    "num_averaged_samples": 5
  },
  {
    "graph_id": 969,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      0,
      0,
      4,
      1,
      2,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nB->A\nC->A\nD->E\nF->B\nF->C\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_969.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_969_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_969_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_969_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_969_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_969_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_969_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_969_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_969_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 970,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      5,
      6
    ],
    "target": [
      3,
      5,
      0,
      3,
      4,
      5,
      0,
      1,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->A\nC->D\nC->E\nD->F\nE->A\nE->B\nF->B\nF->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_970.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_970_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_970_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 971,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        1,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      4,
      4,
      2,
      0,
      2,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nB->E\nC->E\nF->C\nG->A\nG->C\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_971.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_971_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_971_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_971_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_971_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_971_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_971_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_971_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 972,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      4,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      5,
      2,
      5,
      5,
      4,
      0,
      1,
      3,
      1,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->C\nB->F\nC->F\nD->E\nE->A\nE->B\nE->D\nF->B\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_972.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_972_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_972_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 973,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6,
      6
    ],
    "target": [
      2,
      2,
      0,
      3,
      4,
      3,
      2,
      3,
      0,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nB->C\nC->A\nC->D\nD->E\nE->D\nF->C\nF->D\nG->A\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_973.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_973_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_973_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 974,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      0,
      4,
      5,
      1,
      5,
      0,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "C->A\nC->E\nD->F\nE->B\nE->F\nG->A\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_974.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_974_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_974_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_974_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_974_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_974_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_974_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_974_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 975,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      4,
      4,
      5,
      0,
      2,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->E\nC->E\nD->F\nE->A\nE->C\nF->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_975.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_975_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_975_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_975_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_975_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_975_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_975_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_975_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 976,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      2,
      2,
      3,
      3,
      3,
      4,
      6
    ],
    "target": [
      5,
      0,
      4,
      1,
      2,
      4,
      5,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->F\nC->A\nC->E\nD->B\nD->C\nD->E\nE->F\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_976.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_976_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_976_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_976_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_976_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_976_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_976_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_976_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_976_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 977,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      2,
      2,
      2,
      2,
      3,
      3,
      6
    ],
    "target": [
      0,
      4,
      0,
      1,
      3,
      4,
      2,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->A\nB->E\nC->A\nC->B\nC->D\nC->E\nD->C\nD->F\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_977.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_977_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_977_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_977_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_977_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_977_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_977_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_977_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_977_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_977_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 978,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      2,
      5,
      5,
      6
    ],
    "target": [
      2,
      3,
      0,
      1,
      3,
      1,
      3,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "A->C\nB->D\nC->A\nC->B\nC->D\nF->B\nF->D\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_978.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_978_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_978_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_978_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_978_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_978_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_978_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_978_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_978_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 979,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ]
    ],
    "source": [
      1,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      3,
      0,
      1,
      3,
      0,
      1,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "B->D\nE->A\nF->B\nF->D\nG->A\nG->B\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_979.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_979_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_979_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_979_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_979_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_979_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_979_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_979_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 980,
    "max_nodes": 7,
    "num_nodes": 5,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      4,
      5,
      1,
      5,
      3,
      5,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "C->E\nC->F\nD->B\nD->F\nE->D\nE->F\nF->C\n",
    "averaged_attention_matrix_path": "averaged_id_980.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_980_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_980_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_980_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_980_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_980_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_980_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_980_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 981,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      2,
      3,
      3
    ],
    "target": [
      3,
      3,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->D\nC->D\nD->C\nD->F\n",
    "averaged_attention_matrix_path": "averaged_id_981.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_981_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_981_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_981_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_981_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 982,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      4,
      4,
      5,
      6,
      6
    ],
    "target": [
      1,
      4,
      0,
      5,
      0,
      3,
      0,
      1,
      2,
      2,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nB->A\nB->F\nC->A\nC->D\nD->A\nE->B\nE->C\nF->C\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_982.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_982_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_982_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 983,
    "max_nodes": 7,
    "num_nodes": 4,
    "num_edges": 3,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      2,
      2,
      5
    ],
    "target": [
      4,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "C->E\nC->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_983.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_983_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_983_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_983_2.npy"
    ],
    "num_averaged_samples": 3
  },
  {
    "graph_id": 984,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      4,
      5,
      5,
      6
    ],
    "target": [
      4,
      4,
      4,
      5,
      3,
      0,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nC->E\nC->F\nE->D\nF->A\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_984.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_984_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_984_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_984_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_984_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_984_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_984_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_984_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_984_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 985,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        1,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      2,
      5,
      3,
      2,
      0,
      1,
      2,
      3,
      4
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a"
    ],
    "prompt": "A->C\nA->F\nC->D\nD->C\nF->A\nF->B\nG->C\nG->D\nG->E\n",
    "averaged_attention_matrix_path": "averaged_id_985.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_985_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_985_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_985_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_985_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_985_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_985_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_985_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_985_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_985_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 986,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      3,
      3,
      3,
      4,
      4
    ],
    "target": [
      4,
      4,
      5,
      1,
      2,
      4,
      1,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->E\nB->E\nC->F\nD->B\nD->C\nD->E\nE->B\nE->D\n",
    "averaged_attention_matrix_path": "averaged_id_986.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_986_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_986_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_986_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_986_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_986_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_986_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_986_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_986_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 987,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 13,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        1,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      3,
      3,
      4,
      4,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      5,
      4,
      5,
      0,
      4,
      5,
      2,
      3,
      4,
      0,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->F\nB->E\nB->F\nC->A\nD->E\nD->F\nE->C\nE->D\nF->E\nG->A\nG->D\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_987.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_987_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_11.npy",
      "attention_matrices/no_args_7_1b/avg_attn_987_12.npy"
    ],
    "num_averaged_samples": 13
  },
  {
    "graph_id": 988,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        1,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      1,
      3,
      3,
      4,
      4,
      6,
      6
    ],
    "target": [
      2,
      4,
      0,
      4,
      2,
      5,
      2,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "B->C\nB->E\nD->A\nD->E\nE->C\nE->F\nG->C\nG->D\n",
    "averaged_attention_matrix_path": "averaged_id_988.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_988_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_988_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_988_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_988_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_988_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_988_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_988_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_988_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 989,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      4,
      4,
      5
    ],
    "target": [
      1,
      3,
      3,
      0,
      4,
      0,
      5,
      3
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "A",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nC->D\nD->A\nD->E\nE->A\nE->F\nF->D\n",
    "averaged_attention_matrix_path": "averaged_id_989.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_989_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_989_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_989_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_989_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_989_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_989_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_989_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_989_7.npy"
    ],
    "num_averaged_samples": 8
  },
  {
    "graph_id": 990,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 4,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      4,
      5,
      6
    ],
    "target": [
      2,
      2,
      2,
      0
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "A",
      "\u010a"
    ],
    "prompt": "B->C\nE->C\nF->C\nG->A\n",
    "averaged_attention_matrix_path": "averaged_id_990.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_990_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_990_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_990_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_990_3.npy"
    ],
    "num_averaged_samples": 4
  },
  {
    "graph_id": 991,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      2,
      2,
      3,
      5,
      6
    ],
    "target": [
      4,
      5,
      0,
      5,
      1,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->E\nB->F\nC->A\nC->F\nD->B\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_991.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_991_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_991_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_991_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_991_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_991_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_991_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_991_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 992,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      1,
      2,
      2,
      3,
      5,
      5,
      6
    ],
    "target": [
      2,
      4,
      0,
      4,
      3,
      4,
      4,
      1,
      2,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "D",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nB->E\nC->D\nC->E\nD->E\nF->B\nF->C\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_992.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_992_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_992_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 993,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      5,
      5,
      6
    ],
    "target": [
      3,
      5,
      4,
      0,
      4,
      5,
      1,
      4,
      2
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "B",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "C",
      "\u010a"
    ],
    "prompt": "A->D\nA->F\nB->E\nC->A\nC->E\nD->F\nF->B\nF->E\nG->C\n",
    "averaged_attention_matrix_path": "averaged_id_993.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_993_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_993_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_993_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_993_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_993_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_993_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_993_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_993_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_993_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 994,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 12,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      3,
      4,
      5,
      5,
      6,
      6,
      6
    ],
    "target": [
      1,
      3,
      5,
      1,
      5,
      1,
      5,
      0,
      1,
      1,
      4,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->B\nA->D\nB->F\nC->B\nC->F\nD->B\nE->F\nF->A\nF->B\nG->B\nG->E\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_994.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_994_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_10.npy",
      "attention_matrices/no_args_7_1b/avg_attn_994_11.npy"
    ],
    "num_averaged_samples": 12
  },
  {
    "graph_id": 995,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 7,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      1,
      1,
      3,
      4,
      5,
      6
    ],
    "target": [
      3,
      0,
      5,
      5,
      1,
      3,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "D",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "B",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "D",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->D\nB->A\nB->F\nD->F\nE->B\nF->D\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_995.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_995_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_995_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_995_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_995_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_995_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_995_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_995_6.npy"
    ],
    "num_averaged_samples": 7
  },
  {
    "graph_id": 996,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 10,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      1,
      2,
      2,
      2,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      2,
      1,
      4,
      5,
      0,
      5,
      1,
      5,
      1,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "B",
      "->",
      "C",
      "\u010a",
      "C",
      "->",
      "B",
      "\u010a",
      "C",
      "->",
      "E",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "B->C\nC->B\nC->E\nC->F\nD->A\nD->F\nE->B\nE->F\nF->B\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_996.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_996_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_996_9.npy"
    ],
    "num_averaged_samples": 10
  },
  {
    "graph_id": 997,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 9,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        1,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        1,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      0,
      3,
      3,
      4,
      4,
      5,
      6
    ],
    "target": [
      1,
      4,
      5,
      1,
      4,
      2,
      5,
      2,
      1
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "B",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "B",
      "\u010a",
      "D",
      "->",
      "E",
      "\u010a",
      "E",
      "->",
      "C",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "C",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a"
    ],
    "prompt": "A->B\nA->E\nA->F\nD->B\nD->E\nE->C\nE->F\nF->C\nG->B\n",
    "averaged_attention_matrix_path": "averaged_id_997.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_997_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_997_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_997_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_997_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_997_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_997_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_997_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_997_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_997_8.npy"
    ],
    "num_averaged_samples": 9
  },
  {
    "graph_id": 998,
    "max_nodes": 7,
    "num_nodes": 7,
    "num_edges": 11,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        0,
        0,
        1,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        1,
        0,
        1,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        1,
        0,
        0,
        1,
        0,
        0
      ],
      [
        0,
        1,
        0,
        0,
        0,
        1,
        0
      ]
    ],
    "source": [
      0,
      0,
      2,
      3,
      3,
      3,
      5,
      5,
      5,
      6,
      6
    ],
    "target": [
      4,
      5,
      5,
      0,
      2,
      5,
      0,
      1,
      4,
      1,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "E",
      "\u010a",
      "A",
      "->",
      "F",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "D",
      "->",
      "A",
      "\u010a",
      "D",
      "->",
      "C",
      "\u010a",
      "D",
      "->",
      "F",
      "\u010a",
      "F",
      "->",
      "A",
      "\u010a",
      "F",
      "->",
      "B",
      "\u010a",
      "F",
      "->",
      "E",
      "\u010a",
      "G",
      "->",
      "B",
      "\u010a",
      "G",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->E\nA->F\nC->F\nD->A\nD->C\nD->F\nF->A\nF->B\nF->E\nG->B\nG->F\n",
    "averaged_attention_matrix_path": "averaged_id_998.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_998_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_7.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_8.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_9.npy",
      "attention_matrices/no_args_7_1b/avg_attn_998_10.npy"
    ],
    "num_averaged_samples": 11
  },
  {
    "graph_id": 999,
    "max_nodes": 7,
    "num_nodes": 6,
    "num_edges": 8,
    "connection_probability": 0.25,
    "layer": "0",
    "head": "all",
    "gt_adjacency": [
      [
        0,
        0,
        1,
        0,
        1,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        1,
        0,
        0,
        0,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        1,
        0,
        1,
        0,
        1,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      [
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ]
    ],
    "source": [
      0,
      0,
      1,
      2,
      2,
      4,
      4,
      4
    ],
    "target": [
      2,
      4,
      0,
      0,
      5,
      1,
      3,
      5
    ],
    "tokens": [
      "<|begin_of_text|>",
      "A",
      "->",
      "C",
      "\u010a",
      "A",
      "->",
      "E",
      "\u010a",
      "B",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "A",
      "\u010a",
      "C",
      "->",
      "F",
      "\u010a",
      "E",
      "->",
      "B",
      "\u010a",
      "E",
      "->",
      "D",
      "\u010a",
      "E",
      "->",
      "F",
      "\u010a"
    ],
    "prompt": "A->C\nA->E\nB->A\nC->A\nC->F\nE->B\nE->D\nE->F\n",
    "averaged_attention_matrix_path": "averaged_id_999.pt",
    "original_attention_matrix_paths": [
      "attention_matrices/no_args_7_1b/avg_attn_999_0.npy",
      "attention_matrices/no_args_7_1b/avg_attn_999_1.npy",
      "attention_matrices/no_args_7_1b/avg_attn_999_2.npy",
      "attention_matrices/no_args_7_1b/avg_attn_999_3.npy",
      "attention_matrices/no_args_7_1b/avg_attn_999_4.npy",
      "attention_matrices/no_args_7_1b/avg_attn_999_5.npy",
      "attention_matrices/no_args_7_1b/avg_attn_999_6.npy",
      "attention_matrices/no_args_7_1b/avg_attn_999_7.npy"
    ],
    "num_averaged_samples": 8
  }
]