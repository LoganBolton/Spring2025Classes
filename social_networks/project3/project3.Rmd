---
title: "project3"
output: pdf_document
author: "Logan Bolton"
date: "2025-02-21"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
library(DirectedClustering)
```

# Network Structure Analysis
Since the graph is NOT strongly connected, we have to find the diameter and radius using the largest strongly connected sub component.

The dataset also does not have duplicate sender -> receiver pairs, so we will analyze the dataset as an unweighted graph.

```{r overall}
# Read the text file into a dataframe
df <- read.table("email-Eu-core.txt", header = FALSE, sep = " ")
colnames(df) <- c("From", "To")
# The dataset does not hav
# df_weighted <- aggregate(weight ~ From + To, data = transform(df, weight = 1), FUN = sum)

g <- graph_from_data_frame(df, directed = TRUE)
# g <- graph_from_data_frame(df_weighted, directed = TRUE)

num_nodes = vcount(g)
num_edges = ecount(g)

# Check strong connectivity
components <- components(g, mode="strong")

# Extract the vertices belonging to the largest strongly connected component
largest_comp_vertices <- V(g)[components$membership == which.max(components$csize)]
g_largest <- induced_subgraph(g, largest_comp_vertices)

# Calculate diameter and radius on the largest SCC
diameter_largest <- diameter(g_largest, directed = TRUE)
radius_largest <- radius(g_largest, mode = "out")


output <- paste(
  "Graph Summary",
  paste("Number of nodes:", num_nodes),
  paste("Number of edges:", num_edges),
  paste("Density:", round(edge_density(g), 6)),
  paste(""),
  "Connectivity:",
  paste("Number of strongly connected components:", components$no),
  paste("Size of largest strongly connected component:", max(components$csize)),
  paste("fraction of elements belonging to the largest strong subcomponent: ", max(components$csize)/num_nodes),
  "The graph is NOT strongly connected",
  paste("Largest diameter:", diameter_largest),
  paste("Largest radius:", radius_largest),
  "-------------------------------------------------------------------",
  
  sep = "\n"
)
cat(output)

```
```{r}
adj_matrix <- as_adjacency_matrix(g, sparse = FALSE)

# Compute clustering coefficients (cycle type)
clustering_coeff <- ClustF(adj_matrix, type = "cycle")

# Print the global cycle clustering coefficient
print(clustering_coeff$GlobalcycleCC)

print(paste("Global out-clustering coefficient:", clustering_coeff$GlobaloutCC))
```


# Degree Distribution Analysis

```{r degree_distribution, echo=TRUE, fig.width=10, fig.height=4}
# Calculate in-degree, out-degree, and total degree
in_degree <- degree(g, mode = "in")
out_degree <- degree(g, mode = "out")
total_degree <- degree(g, mode = "all")

# Set up a 1x3 plotting layout
par(mfrow = c(1, 3))

# Plot histogram for in-degree
hist(in_degree, breaks = 50, main = "In-Degree Distribution", 
     xlab = "In-Degree", ylab = "Frequency", col = "skyblue", border = "black")

# Plot histogram for out-degree
hist(out_degree, breaks = 50, main = "Out-Degree Distribution", 
     xlab = "Out-Degree", ylab = "Frequency", col = "salmon", border = "black")

# Plot histogram for total degree
hist(total_degree, breaks = 50, main = "Total Degree Distribution", 
     xlab = "Total Degree", ylab = "Frequency", col = "lightgreen", border = "black")

# Reset plotting layout
par(mfrow = c(1, 1))

# Summary statistics
cat("In-Degree Summary:\n")
print(summary(in_degree))
cat("\nOut-Degree Summary:\n")
print(summary(out_degree))
cat("\nTotal Degree Summary:\n")
print(summary(total_degree))
```

# Community Detection
```{r}
eb_communities <- cluster_edge_betweenness(g)
eb_membership <- membership(eb_communities)
eb_modularity <- modularity(eb_communities)
eb_sizes <- sizes(eb_communities)

# Walktrap Community Detection
wt_communities <- cluster_walktrap(g)
wt_membership <- membership(wt_communities)
wt_modularity <- modularity(wt_communities)
wt_sizes <- sizes(wt_communities)

# Print summary statistics for both algorithms
cat("Edge Betweenness Community Detection:\n")
cat("Number of communities:", length(unique(eb_membership)), "\n")
cat("Modularity:", round(eb_modularity, 4), "\n")
cat("Community sizes:\n")
print(sort(table(eb_membership), decreasing = TRUE)[1:10])
cat("\n")

cat("Walktrap Community Detection:\n")
cat("Number of communities:", length(unique(wt_membership)), "\n")
cat("Modularity:", round(wt_modularity, 4), "\n")
cat("Community sizes:\n")
print(sort(table(wt_membership), decreasing = TRUE)[1:10])

# Visualize the communities
# Function to plot communities with layout optimization
plot_communities <- function(graph, membership, title) {
  # Create color palette for communities
  num_communities <- length(unique(membership))
  colors <- rainbow(num_communities)
  
  # Set vertex colors based on community membership
  V(graph)$color <- colors[membership]
  
  # Calculate layout (using Fruchterman-Reingold algorithm)
  layout <- layout_with_fr(graph)
  
  # Plot the graph
  plot(graph,
       layout = layout,
       vertex.size = 3,
       vertex.label = NA,
       edge.arrow.size = 0.2,
       main = title)
}

# Set up plotting area for side-by-side comparison
par(mfrow = c(1, 2))

# Plot both community structures
plot_communities(g, eb_membership, "Edge Betweenness Communities")
plot_communities(g, wt_membership, "Walktrap Communities")

# Reset plotting parameters
par(mfrow = c(1, 1))
```

# Triad Census Analysis
```{r}
# Function to analyze triads in relation to communities
analyze_triads_communities <- function(g, communities) {
  # Initialize counters for different triad types
  triad_counts <- list(
    same_comm = c(type0 = 0, type1 = 0, type2 = 0, type3 = 0),
    diff_comm = c(type0 = 0, type1 = 0, type2 = 0, type3 = 0)
  )
  
  # Get all possible triads
  node_combinations <- combn(V(g), 3)
  
  for(i in 1:ncol(node_combinations)) {
    nodes <- node_combinations[,i]
    
    # Count edges in triad
    subg <- induced_subgraph(g, nodes)
    edge_count <- ecount(subg)
    
    # Check if all nodes are in same community
    comm_memberships <- membership(communities)[nodes]
    same_community <- length(unique(comm_memberships)) == 1
    
    # Update counts
    if(same_community) {
      triad_counts$same_comm[edge_count + 1] <- triad_counts$same_comm[edge_count + 1] + 1
    } else {
      triad_counts$diff_comm[edge_count + 1] <- triad_counts$diff_comm[edge_count + 1] + 1
    }
  }
  
  return(triad_counts)
}

# Analyze triads for Walktrap communities
triad_analysis <- analyze_triads_communities(g, wt_communities)

# Calculate percentages
total_by_type <- mapply('+', triad_analysis$same_comm, triad_analysis$diff_comm)
percent_same_comm <- (triad_analysis$same_comm / total_by_type) * 100

# Print results
cat("Triad Census Analysis Results:\n")
cat("----------------------------------------\n")
for(i in 1:4) {
  cat(sprintf("Triads with %d edges:\n", i-1))
  cat(sprintf("  Within same community: %.2f%%\n", percent_same_comm[i]))
  cat(sprintf("  Total count: %d\n", total_by_type[i]))
  cat("----------------------------------------\n")
}

# Visualize results
barplot(rbind(triad_analysis$same_comm, triad_analysis$diff_comm),
        beside = TRUE,
        names.arg = c("0 edges", "1 edge", "2 edges", "3 edges"),
        col = c("lightblue", "salmon"),
        main = "Triad Distribution by Community Structure",
        legend.text = c("Same Community", "Different Communities"),
        args.legend = list(x = "topright"))
```