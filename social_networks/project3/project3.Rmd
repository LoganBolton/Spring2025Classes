---
title: "project3"
output: pdf_document
author: "Logan Bolton"
date: "2025-02-21"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
library(DirectedClustering)
library(aricode)

```

# Network Structure Analysis
Since the graph is NOT strongly connected, we have to find the diameter and radius using the largest strongly connected sub component.

The dataset also does not have duplicate sender -> receiver pairs, so we will analyze the dataset as an unweighted graph.

```{r overall}
# Read the text file into a dataframe
df <- read.table("email-Eu-core.txt", header = FALSE, sep = " ")
colnames(df) <- c("From", "To")
# The dataset does not hav
# df_weighted <- aggregate(weight ~ From + To, data = transform(df, weight = 1), FUN = sum)

g <- graph_from_data_frame(df, directed = TRUE)
# g <- graph_from_data_frame(df_weighted, directed = TRUE)

num_nodes = vcount(g)
num_edges = ecount(g)

# Check strong connectivity
components <- components(g, mode="strong")

# Extract the vertices belonging to the largest strongly connected component
largest_comp_vertices <- V(g)[components$membership == which.max(components$csize)]
g_largest <- induced_subgraph(g, largest_comp_vertices)

# Calculate diameter and radius on the largest SCC
diameter_largest <- diameter(g_largest, directed = TRUE)
radius_largest <- radius(g_largest, mode = "out")


output <- paste(
  "Graph Summary",
  paste("Number of nodes:", num_nodes),
  paste("Number of edges:", num_edges),
  paste("Density:", round(edge_density(g), 6)),
  paste(""),
  "Connectivity:",
  paste("Number of strongly connected components:", components$no),
  paste("Size of largest strongly connected component:", max(components$csize)),
  paste("fraction of elements belonging to the largest strong subcomponent: ", max(components$csize)/num_nodes),
  "The graph is NOT strongly connected",
  paste("Largest diameter:", diameter_largest),
  paste("Largest radius:", radius_largest),
  "-------------------------------------------------------------------",
  
  sep = "\n"
)
cat(output)

```
```{r coefficient}
adj_matrix <- as_adjacency_matrix(g, sparse = FALSE)

# Compute clustering coefficients (cycle type)
clustering_coeff <- ClustF(adj_matrix, type = "cycle")

# Print the global cycle clustering coefficient
print(clustering_coeff$GlobalcycleCC)

print(paste("Global out-clustering coefficient:", clustering_coeff$GlobaloutCC))
```


# Degree Distribution Analysis

```{r degree_distribution, echo=TRUE, fig.width=10, fig.height=4}
# Calculate in-degree, out-degree, and total degree
in_degree <- degree(g, mode = "in")
out_degree <- degree(g, mode = "out")
total_degree <- degree(g, mode = "all")

# Set up a 1x3 plotting layout
par(mfrow = c(1, 3))

# Plot histogram for in-degree
hist(in_degree, breaks = 50, main = "In-Degree Distribution", 
     xlab = "In-Degree", ylab = "Frequency", col = "skyblue", border = "black")

# Plot histogram for out-degree
hist(out_degree, breaks = 50, main = "Out-Degree Distribution", 
     xlab = "Out-Degree", ylab = "Frequency", col = "salmon", border = "black")

# Plot histogram for total degree
hist(total_degree, breaks = 50, main = "Total Degree Distribution", 
     xlab = "Total Degree", ylab = "Frequency", col = "lightgreen", border = "black")

# Reset plotting layout
par(mfrow = c(1, 1))

# Summary statistics
cat("In-Degree Summary:\n")
print(summary(in_degree))
cat("\nOut-Degree Summary:\n")
print(summary(out_degree))
cat("\nTotal Degree Summary:\n")
print(summary(total_degree))
```

# Community Detection
```{r community detection, cache=TRUE} 
eb_communities <- cluster_edge_betweenness(g)
eb_membership <- membership(eb_communities)
eb_modularity <- modularity(eb_communities)
eb_sizes <- sizes(eb_communities)

# Walktrap Community Detection
wt_communities <- cluster_walktrap(g)
wt_membership <- membership(wt_communities)
wt_modularity <- modularity(wt_communities)
wt_sizes <- sizes(wt_communities)

# Print summary statistics for both algorithms
cat("Edge Betweenness Community Detection:\n")
cat("Number of communities:", length(unique(eb_membership)), "\n")
cat("Modularity:", round(eb_modularity, 4), "\n")
cat("Community sizes:\n")
print(sort(table(eb_membership), decreasing = TRUE)[1:10])
cat("\n")

cat("Walktrap Community Detection:\n")
cat("Number of communities:", length(unique(wt_membership)), "\n")
cat("Modularity:", round(wt_modularity, 4), "\n")
cat("Community sizes:\n")
print(sort(table(wt_membership), decreasing = TRUE)[1:10])

# Visualize the communities
# Function to plot communities with layout optimization
plot_communities <- function(graph, membership, title) {
  # Create color palette for communities
  num_communities <- length(unique(membership))
  colors <- rainbow(num_communities)
  
  # Set vertex colors based on community membership
  V(graph)$color <- colors[membership]
  
  # Calculate layout (using Fruchterman-Reingold algorithm)
  layout <- layout_with_fr(graph)
  
  # Plot the graph
  plot(graph,
       layout = layout,
       vertex.size = 3,
       vertex.label = NA,
       edge.arrow.size = 0.2,
       main = title)
}

# Set up plotting area for side-by-side comparison
par(mfrow = c(1, 2))

# Plot both community structures
plot_communities(g, eb_membership, "Edge Betweenness Communities")
plot_communities(g, wt_membership, "Walktrap Communities")

# Reset plotting parameters
par(mfrow = c(1, 1))
```

# Triad Census Analysis
```{r triad}
# print(wt_communities)
# Function to analyze triads in relation to communities
analyze_triads_communities <- function(g, communities) {
  # Initialize counters for different triad types
  triad_counts <- list(
    same_comm = c(type0 = 0, type1 = 0, type2 = 0, type3 = 0),
    diff_comm = c(type0 = 0, type1 = 0, type2 = 0, type3 = 0)
  )
  # Get all possible triads
  node_combinations <- combn(V(g), 3)
  # print(node_combinations)
  total_triads <- ncol(node_combinations)
  print(total_triads)

  # Add progress monitoring
  pb <- txtProgressBar(min = 0, max = total_triads, style = 3)

  # Add timing
  start_time <- Sys.time()

  for(i in 1:total_triads) {
    nodes <- node_combinations[,i]

    # Count edges in triad
    subg <- induced_subgraph(g, nodes)
    edge_count <- ecount(subg)

    # Check if all nodes are in same community
    comm_memberships <- membership(communities)[nodes]
    same_community <- length(unique(comm_memberships)) == 1

    # Update counts
    if(same_community) {
      triad_counts$same_comm[edge_count + 1] <- triad_counts$same_comm[edge_count + 1] + 1
    } else {
      triad_counts$diff_comm[edge_count + 1] <- triad_counts$diff_comm[edge_count + 1] + 1
    }

    # Update progress bar every 1000 iterations
    if(i %% 1000 == 0) {
      setTxtProgressBar(pb, i)
    }
  }

  close(pb)
  end_time <- Sys.time()

  # Calculate additional statistics
  total_same_comm <- sum(triad_counts$same_comm)
  total_diff_comm <- sum(triad_counts$diff_comm)

  # Add proportions and timing to results
  results <- list(
    counts = triad_counts,
    summary = list(
      total_triads = total_triads,
      same_comm_prop = triad_counts$same_comm / total_same_comm,
      diff_comm_prop = triad_counts$diff_comm / total_diff_comm,
      execution_time = difftime(end_time, start_time, units = "mins")
    )
  )

  return(results)
}

# Analyze triads for Walktrap communities
triad_analysis <- analyze_triads_communities(g, wt_communities)

# Calculate percentages
total_by_type <- mapply('+', triad_analysis$same_comm, triad_analysis$diff_comm)
percent_same_comm <- (triad_analysis$same_comm / total_by_type) * 100

# Print results
cat("Triad Census Analysis Results:\n")
cat("----------------------------------------\n")
for(i in 1:4) {
  cat(sprintf("Triads with %d edges:\n", i-1))
  cat(sprintf("  Within same community: %.2f%%\n", percent_same_comm[i]))
  cat(sprintf("  Total count: %d\n", total_by_type[i]))
  cat("----------------------------------------\n")
}

# Visualize results
barplot(rbind(triad_analysis$same_comm, triad_analysis$diff_comm),
        beside = TRUE,
        names.arg = c("0 edges", "1 edge", "2 edges", "3 edges"),
        col = c("lightblue", "salmon"),
        main = "Triad Distribution by Community Structure",
        legend.text = c("Same Community", "Different Communities"),
        args.legend = list(x = "topright"))
```

# Modularity Analysis
```{r}
wt_mod_value <- modularity(g, wt_membership)
eb_mod_value <- modularity(g, eb_membership)

cat("Walktrap Modularity: ", wt_mod_value, "\n")
cat("Edge Betweenness Modularity: ", eb_mod_value, "\n")
```

# Evaluation
Based off this analysis, neither algorithm did very well at determining the correct communities. The edge betweenness algorithm did better than the walktrap algorithm in terms of NMI (0.444 vs 0.181), however both algorithms scored blose to zero at in ARI. In face, the edge betweenness ARI score of (-0.002) indicates that the algorithm may actually be worse than random. 
```{r}
gt_communities <- read.table("email-Eu-core-department-labels.txt", header=FALSE)
colnames(gt_communities) <- c("Node", "Community")

# Convert memberships to vectors ensuring they use the same node ordering
gt_membership <- gt_communities$Community
wt_membership_ordered <- membership(wt_communities)[order(as.numeric(V(g)))]
eb_membership_ordered <- membership(eb_communities)[order(as.numeric(V(g)))]

# Calculate NMI
nmi_wt <- NMI(gt_membership, wt_membership_ordered)
nmi_eb <- NMI(gt_membership, eb_membership_ordered)

# Calculate ARI
ari_wt <- ARI(gt_membership, wt_membership_ordered)
ari_eb <- ARI(gt_membership, eb_membership_ordered)

# Print results
cat("Comparison with Ground Truth:\n")
cat("Walktrap Algorithm:\n")
cat("  NMI:", nmi_wt, "\n")
cat("  ARI:", ari_wt, "\n")
cat("\nEdge Betweenness Algorithm:\n")
cat("  NMI:", nmi_eb, "\n")
cat("  ARI:", ari_eb, "\n")

# Create visualization comparing community sizes
par(mfrow=c(1,3))

# Ground Truth distribution
barplot(table(gt_membership), 
        main="Ground Truth Community Sizes",
        xlab="Community ID", 
        ylab="Size")

# Walktrap distribution
barplot(table(wt_membership), 
        main="Walktrap Community Sizes",
        xlab="Community ID", 
        ylab="Size")

# Edge Betweenness distribution
barplot(table(eb_membership), 
        main="Edge Betweenness Community Sizes",
        xlab="Community ID", 
        ylab="Size")


```
